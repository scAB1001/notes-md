Thursday 09/10/2025

---
#### Module Objectives
- Understand the different ways on how to view the organisation of a distributed system.
- Organisation of the distributed systems is mostly about the software components that constitute the system
- The software architectures tell us how the various software components are to be organized
- Goal: separate applications from underlying platforms by providing the middleware layer
- The instantiation of a software architecture (placement of software components on real machines) is referred to as a system architecture.
### Architectural Styles for Distributed Systems
Architecture is formulated in terms of:
- (replaceable) components with well-defined interfaces
- the way that components are connected to each other
- the data exchanged between components
- how these components and connectors are jointly configured into a system.
![[machine-interfaces.png]]
Component A has B’s interface.  Component B has C’s. C has E’s. D has B’s.
##### Styles
1. Layered architectures
2. Object-based architectures
3. Resource-centred architectures
4. Event-based architectures - Publish-subscribe
Note: in (2) and (3), each entity encapsulates a service, object or microservice. 
More in lecture on Service oriented Architectures.
#### Layered Architectures
The basic idea for the layered style is simple: components are organized in a layered fashion where a component at layer Lj can make a downcall to a component at a lower-level layer Li (with i < j) and generally expects a response. Only in exceptional cases will an upcall be made to a higher-level component.
![[layered-architectures.png]](a) Pure layered organisation
(b) Mixed layered organisation
(c) Layered organisation with upcalls
##### Layered communication protocol
A well-known and ubiquitously applied layered architecture is that of so-called communication-protocol stacks.
- In these stacks, each layer implements one or several communication services allowing data to be sent from a destination to one or several targets. 
- To this end, each layer offers an interface specifying the functions that can be called. 
- In principle, the interface should completely hide the actual implementation of a service. 

Another important concept in the case of communication is that of a (communication) protocol, which describes the rules that parties will follow in order to exchange information. 
![[layered-communication-protocol-ex.png]]
_A layered communication protocol stack, showing the difference between a service, its interface, and the protocol it deploys._

It is important to understand the difference between a service offered by a layer, the interface by which that service is made available, and the protocol that a layer implements to establish communication.
###### Example: TCP
To make this distinction clear, consider a reliable, connection-oriented service, which is provided by many communication systems. 

In this case, a communicating party first needs to set up a connection to another party before the two can send and receive messages. 
- Being reliable means that strong guarantees will be given that sent messages will indeed be delivered to the other side, even when there is a high risk that messages may be lost (as, for example, may be the case when using a wireless medium). 
- In addition, such services generally also ensure that messages are delivered in the same order as that they were sent. 

This kind of service is realized in the Internet by the **Transmission Control Protocol (TCP).** 
- The protocol specifies which messages are to be exchanged for setting up or tearing down a connection, what needs to be done to preserve the ordering of transferred data, and what both parties need to do to detect and correct data that was lost during transmission. 
- The service is made available in the form of a relatively simple programming interface, containing calls to set up a connection, send and receive messages, and to tear down the connection again. In fact, there are different interfaces available, often dependent on operating system or programming language used. 
- Likewise, there are many different implementations of the protocol and its interfaces
##### Application Layering: the PAD Model
Many client-server applications are constructed logically from three different layers of software
1. **Presentation layer**: application-interface
	 Contains everything required to interface with user of the system

1. **Application layer**: processing
	A processing layer, containing core functionality of the system

1. **Data layer**: data
	Responsible for persistent storage of the data on which application layer operates 
	Can map these layers onto a physical client-server architecture in various ways

![[pad-search-engine-ex.png]]*The general organisation of an Internet search engine into three different layers*

**A Search on Google Cloud: How it is Handled**
- load balancer: application-layer routing
![[cloud-search-ex.png]]
Search for: “Jay Kelly”
- receives external client requests
- directs workload within data centre
- returns results to external client (hiding data centre internals from client)
#### Object-based and service-oriented architectures 
In essence, each object corresponds to what we have defined as a **component**, and these components are connected through a **procedure call mechanism**. 
In the case of distributed systems, a procedure call can also take place over a network, that is, the calling object need not be executed on the same machine as the called object. E.g. RMI.

Object-based architectures are attractive because they provide a natural way of **encapsulating** data (called an _object’s state_) and the operations that can be performed on that data (which are referred to as an _object’s methods_) into a single entity. 

The **interface** offered by an object conceals implementation details, essentially meaning that we, in principle, can consider an object completely independent of its environment. 

As with components, this also means that if the interface is clearly defined and left otherwise untouched, an object should be replaceable with one having exactly the same interface. 
- This separation between interfaces and the objects implementing these interfaces allows us to place an interface at one machine, while the object itself resides on another machine. 
- This organization is commonly referred to as a **distributed object**. 

When a client **binds** to a distributed object, an implementation of the object’s interface, called a **proxy**, is then loaded into the client’s address space. 
- A proxy is analogous to a client stub in RPC systems. 
- The only thing it does is marshal method invocations into messages and unmarshal reply messages to return the result of the method invocation to the client. 
- The actual object resides at a server machine, where it offers the same interface as it does on the client machine. 
- The proxy only handles communication and marshalling - it doesn't cache or preserve the object's state locally.
- Incoming invocation requests are first passed to a server stub, which unmarshals them to make method invocations at the object’s interface at the server. 
- The server stub is also responsible for marshaling replies and forwarding reply messages to the client-side proxy.
![[object-based-arch-remote-obj-client-side-proxy.png]]
The server-side stub is often referred to as a skeleton as it provides the bare means for letting the server middleware access the user-defined objects. 

In practice, it often contains incomplete code in the form of a language-specific class that needs to be further specialized by the developer. 

A characteristic, but somewhat counterintuitive feature of most distributed objects is that their state is not distributed: 
- it resides at a single machine.
- Only the interfaces implemented by the object are made available on other machines.  
- Such objects are also referred to as remote objects. 

In a general distributed object, the state itself may be physically distributed across multiple machines, but this distribution is also hidden from clients behind the object’s interfaces. 

One could argue that object-based architectures form the foundation of encapsulating services into independent units. 
Encapsulation is the keyword here: 
- the service as a whole is realized as a self-contained entity, although it can possibly make use of other services. 
- By clearly separating various services such that they can operate independently, we are paving the road toward service-oriented architectures, generally abbreviated as SOAs. 

In a service-oriented architecture, a distributed application or system is essentially constructed as a composition of many different services. 
- Not all of these services may belong to the same administrative organization. 
- It may very well be that an organization running its business application makes use of storage services offered by a cloud provider. 
- These storage services are logically completely encapsulated into a single unit, of which an interface is made available to customers. 
- Of course, storage is a rather basic service, but more sophisticated situa- tions easily come to mind. Consider, for example, a Web shop selling goods such as e-books. 
###### Example
A simple implementation following the application layering we discussed previously, may consist of an application for processing orders, which, in turn, operates on a local database containing the e-books.

Order processing typically involves selecting items, registering and checking the delivery channel (perhaps by making use of e-mail), but also making sure that a payment takes place. 

The latter can be handled by a separate service, run by a different organization, to which a purchasing customer is redirected for the payment, after which the e-book organization is notified so that it can complete the transaction. 

In this way, we see that the problem of developing a distributed system is partly one of service composition, and making sure that those services operate in harmony. 

Indeed, this problem is completely analogous to enterprise application integration issues. Crucial is, and remains, that each service offers a well-defined (programming) interface. 

In practice, this also means that each service offers its own interface, in turn, possibly making the composition of services far from trivial.
#### Resource-based architectures
As an increasing number of services became available over the Web and the development of distributed systems through service composition became more important, researchers started to rethink the architecture of mostly Web-based distributed systems. 

One of the problems with service composition is that connecting various components can easily turn into an integration nightmare. 
 - As an alternative, one can also view a distributed system as a huge collection of resources that are individually managed by components. 
 - Resources may be added or removed by (remote) applications, and likewise can be retrieved or modified. 
 - All services offer the same interface
- Messages sent to or from a service are fully self-described
- After executing an operation at a service, that component forgets everything about the caller

This approach has now been widely adopted for the Web and is known as **Representational State Transfer (REST)** [Fielding, 2000]. 

There are four key characteristics of what are known as RESTful architectures:
1. Resources are identified through a single naming scheme
2. All services offer the same interface, consisting of at most four operations
3. Messages sent to or from a service are fully self-described
4. After executing an operation at a service, that component forgets everything about the caller (**stateless execution**)
##### CRUD operations used in RESTful architectures

| Operation | Description                                                 |
| --------- | ----------------------------------------------------------- |
| `POST`    | **C**reate a new resource                                   |
| `GET`     | **R**etrieve the state of a resource in some representation |
| `PUT`     | **U**pdate (modify) a resource by transferring a new state  |
| `DELETE`  | **D**elete a resource                                       |
##### Example: Amazon’s Simple Storage Service (Amazon S3)
To illustrate how RESTful can work in practice, consider a cloud storage service.
Amazon S3, described in [Murty, 2008] supports only two resources: 
1. objects, which are essentially the equivalent of files, and 
2. buckets, the equivalent of directories. 

There is no concept of placing buckets into buckets. 
An object named `ObjectName` contained in bucket `BucketName` is referred to by the following **Uniform Resource Identifier (URI)**: http://BucketName.s3.amazonaws.com/ObjectName 

To create a bucket, or an object for that matter, an application would essentially 
- send a PUT request with the URI of the bucket/object. 
	- In principle, the protocol that is used with the service is HTTP. 
	- This is just another HTTP request to be interpreted by S3. 
- If the bucket or object already exists, an HTTP error message is returned. 

In a similar fashion, to know which objects are contained in a bucket, an application would 
- send a GET request with the URI of that bucket. 
- S3 will return a list of object names, again as an ordinary HTTP response. 
###### Advantages and Disadvantages
In particular, the simplicity of RESTful architectures can easily prohibit easy solutions to intricate communication schemes. 
- One example is where distributed transactions are needed, which generally requires that services keep track of the state of execution. 
- On the other hand, there are many examples in which RESTful architectures perfectly match a simple integration scheme of services, yet where the myriad of service interfaces will complicate matters
#### Publish-subscribe (event-based) architectures
As systems continue to grow and processes can more easily join or leave, it becomes important to have an architecture in which dependencies between processes become as loose as possible. 
##### General
A large class of distributed systems have adopted an architecture in which there is a strong separation between _processing_ and _coordination_. 
- The idea is to view a system as a collection of _autonomously operating processes_. 
- In this model, **coordination** encompasses the communication and cooperation between processes. 
- It forms the glue that binds the activities performed by processes into a whole [Gelernter and Carriero, 1992]. 

Slightly adapting the terminology from Cabri et al. [2000], we make a distinction between models along two different dimensions, temporal and referential.

|                             | **Temporally coupled** | **Temporally decoupled** |
| --------------------------- | ---------------------- | ------------------------ |
| **Referentially coupled**   | Direct                 | Mailbox                  |
| **Referentially decoupled** | Event-based            | Shared data space        |
##### Types of coordination
**Temporally and referentially coupled processes**
Coordination takes place in a direct way, referred to as **direct coordination**. 
###### Referential coupling
Appears in the form of explicit referencing in communication. 
- For example, a process can communicate only if it knows the name or identifier of the other processes it wants to exchange information with. 
###### Temporal coupling 
Processes that are communicating will both have to be up and running. 
- In real life, talking over cell phones (and assuming that a cell phone has only one owner), is an example of direct communication.
###### Temporally decoupled, but referentially coupled processes
Referred to as **mailbox coordination**. 
- In this case, there is no need for two communicating processes to be executing at the same time in order to let communication take place. 
- Instead, communication takes place by putting messages in a (possibly shared) mail-box. Because it is necessary to explicitly address the mailbox that will hold the messages that are to be exchanged, there is a referential coupling. 
###### Referentially decoupled and temporally coupled processes (systems) 
Form the group of models for **event-based coordination**. 
- In referentially decoupled systems, processes do not know each other explicitly. 
- The only thing a process can do is **publish** a **notification** describing the occurrence of an event (e.g., that it wants to coordinate activities, or that it just produced some interesting results). 
- Assuming that notifications come in all sorts and kinds, processes may **subscribe** to a specific kind of notification (see also [Mühl et al., 2006]). 
	- In an ideal event-based coordination model, a published notification will be delivered _exactly_ to those processes that have subscribed to it. 
	- However, it is generally required that the subscriber is _up-and-running_ at the time the notification was published. 
###### Referentially and temporally decoupled processes
Known as a **shared data space**. 
- The key idea is that processes communicate entirely through **tuples**, which are structured data records consisting of a number of fields, very similar to a row in a database table. 
- Processes can put any type of tuple into the shared data space. 
- In order to retrieve a tuple, a process provides a **search pattern** that is matched against the tuples with any matches being returned.

Shared data spaces are thus seen to implement an associative search mechanism for tuples.
- When a process wants to extract a tuple from the data space, it specifies (some of) the values of the fields it is interested in. 
	- Any tuple that matches that specification is then removed from the data space and passed to the process 
- Shared data spaces are often combined with event-based coordination: 
	- a process subscribes to certain tuples by providing a search pattern; when a process inserts a tuple into the data space, matching subscribers are notified. 
	- In both cases, we are dealing with a **publish-subscribe** architecture, and indeed, the key characteristic feature is that processes have no explicit reference to each other. 
- We have also shown an abstraction of the mechanism by which publishers and subscribers are matched, known as an **event bus**.

![[event-based-vs-shared-data-space-arch-ex.png]]
_The difference between a pure event-based architectural style, and that of a shared data space._
##### Extra
An important aspect of publish-subscribe systems is that communication takes place by describing the events that a subscriber is interested in. 
- As a consequence, naming plays a crucial role. 
The important issue is that in many cases, data items are not explicitly identified by senders and receivers. 
- Let us first assume that events are described by a series of attributes. 
- A notification describing an event is said to be published when it is made available for other processes to read.
- To that end, a subscription needs to be passed to the middleware, containing a description of the event that the subscriber is interested in. 
	- Typically consists of some (attribute, value) pairs, which is common for so-called topic-based publish-subscribe systems. 
	- As an alternative, in content-based publish-subscribe systems, a subscription may also consist of (attribute, range) pairs. 
	- In this case, the specified attribute is expected to take on values within a specified range. Descriptions can sometimes be given using all kinds of predicates formulated over the attributes, very similar in nature to SQL-like queries in the case of relational databases. Obviously, the more complex a description is, the more difficult it will be to test whether an event matches a description. 
- We are now confronted with a situation in which subscriptions need to be matched against notifications. 
	- In many cases, an event actually corresponds to data becoming available. 
	- In that case, when matching succeeds, there are two possible scenarios. 
		- In the first case, the middleware may decide to forward the published notification, along with the associated data, to its current set of subscribers, that is, processes with a matching subscription. 
		- As an alternative, the middleware can also forward only a notification at which point subscribers can execute a read operation to retrieve the associated data item. 
	- In those cases in which data associated with an event are immediately forwarded to subscribers, the middleware will generally not offer storage of data. 

Storage is either explicitly handled by a separate service, or is the responsibility of subscribers. 
- In other words, we have a referentially decoupled, but temporally coupled system. 
- This situation is different when notifications are sent so that subscribers need to explicitly read the associated data. 
- Necessarily, the middleware will have to store data items. 
	- In these situations there are additional operations for data management. 
	- It is also possible to attach a lease to a data item such that when the lease expires that the data item is automatically deleted. 
	
Events can easily complicate the processing of subscriptions. 
###### Example subscription
To illustrate, consider a subscription such as “notify when room ZI.1060 is unoccupied and the door is unlocked.” 
- Typically, a distributed system supporting such subscriptions can be implemented by placing independent sensors for monitoring room occupancy (e.g., motion sensors) and those for registering the status of a door lock. 
- Following the approach sketched so far, we would need to compose such primitive events into a publishable data item to which processes can then subscribe. 

Event composition turns out to be a difficult task, notably when the primitive events are generated from sources dispersed across the distributed system. 
- Clearly, in publish-subscribe systems such as these, the crucial issue is the efficient and scalable implementation of matching subscriptions to notifica- tions. 
- From the outside, the publish-subscribe architecture provides lots of potential for building very large-scale distributed systems due to the strong decoupling of processes. 
- On the other hand, devising scalable implementations without losing this independence is not a trivial exercise, notably in the case of content-based publish-subscribe systems. 
### System Architectures
Deciding on software components, their interaction, and their placement leads to an instance of a software architecture, also known as a system architecture [Bass et al., 2003]. 
There are centralized and decentralized organizations, as well as various hybrid forms.
#### Centralised Organisations
Basic Client-Server Model
- There are processes offering services (servers)
- There are processes that use services (clients)
- Clients and servers can be on different machines
- Clients follow request/reply model with respect to using services
![[centralised-org-arch-ex.png]]
#### 2-Tiered Architecture
Alternative client-server organisations (a) – (e).
![[2-tiered-arch-ex.png]]
#### 3-Tiered Architecture
A better DS: 3-Tier Client-Server Architecture
- an example of a server acting as a client.
When distinguishing only client and server machines as we did so far, we miss the point that a server may sometimes need to act as a client, leading to a (physically) three-tiered architecture.
![[3-tier-arch-ex.png]]
#### Request/Response Messages
- Client/Server Example: the Web
- View all of the HTTP and SSL / HTTPS traffic between your machine and the Internet, https://www.charlesproxy.com/
#### Decentralized organizations: peer-to-peer systems
Processes are all equal: the functions that need to be carried out are represented by every process
- Each process will act as a client and a server at the same time (i.e. acting as a **servant**)
##### Unstructured P2P 
Structured peer-to-peer systems attempt to maintain a specific, deterministic overlay network. 
In contrast, in an unstructured peer-to-peer system each node maintains an ad hoc list of neighbors. 

The resulting overlay resembles what is known as a random graph: 
- a graph in which an edge $\langle{u,v}\rangle$, between two nodes `u` and `v` exists only with a certain probability $P[\langle{u,v}\rangle]$. 
- Ideally, this probability is the same for all pairs of nodes, but in practice a wide range of distributions is observed. 

In an unstructured peer-to-peer system, when a node joins it often contacts a well-known node to obtain a starting list of other peers in the system. 
This list can then be used to find more peers, and perhaps ignore others, and so on. 

In practice, a node generally changes its local list almost continuously. 
For example, a node may discover that a neighbor is no longer responsive and that it needs to be replaced. 

Unlike structured peer-to-peer systems, looking up data cannot follow a predetermined route when lists of neighbors are constructed in an ad hoc fashion. 
Instead, in an unstructured peer-to-peer systems we really need to resort to searching for data [Risson and Moors, 2006]. 

Let us look at two extremes and consider the case in which we are requested to search for specific data (e.g., identified by keywords). 
###### Flooding
- In the case of flooding, an issuing node `u` simply passes a request for a data item to all its neighbors. 
- A request will be ignored when its receiving node, say `v`, had seen it before. 
- Otherwise, `v` searches locally for the requested data item. 
	- If `v` has the required data, it can either respond directly to the issuing node `u`, or send it back to the original forwarder, who will then return it to its original forwarder, and so on.
	- If `v` does not have the requested data, it forwards the request to all of its own neighbors. 
- Obviously, flooding can be very expensive, for which reason a request often has an associated **time-to-live (TTL)** value, giving the maximum number of hops a request is allowed to be forwarded. 
	- Choosing the right TTL value is crucial: 
		- too small means that a request will stay close to the issuer and may thus not reach a node having the data. 
		- Too large incurs high communication costs. 
	- As an alternative to setting TTL values, a node can also start a search with an initial TTL value of 1, meaning that it will first query only its neighbors. 
		- If no, or not enough results are returned, the TTL is increased and a new search is initiated. 
###### Random walks
- At the other end of the search spectrum, an issuing node `u` can simply try to find a data item by asking a randomly chosen neighbor, say `v`. 
- If `v` does not have the data, it forwards the request to one of its randomly chosen neighbors, and so on. 
	- The result is known as a random walk [Gkantsidis et al., 2006; Lv et al., 2002]. 
	- Obviously, a random walk imposes much less network traffic, yet it may take much longer before a node is reached that has the requested data. 
	- To decrease the waiting time, an issuer can simply start `n` random walks simultaneously. 
	- Indeed, studies show that in this case, the time it takes before reaching a node that has the data drops approximately by a factor `n`. 
		- Lv et al. [2002] report that relatively small values of `n`, such as 16 or 64, turn out to be effective. 
	- A random walk also needs to be stopped. 
	- To this end, we can either again use a TTL, or alternatively, when a node receives a lookup request, check with the issuer whether forwarding the request to another randomly selected neighbor is still needed. 
		- Note that neither method relies on a specific comparison technique to decide when requested data has been found. 
	- For structured peer-to-peer systems, we assumed the use of keys for comparison; for the two approaches just described, any comparison technique would suffice. 
	- Between flooding and random walks lie policy-based search methods. 
		- For example, a node may decide to keep track of peers who responded positively, effectively turning them into preferred neighbors for succeeding queries. 
		- Likewise, we may want to restrict flooding to fewer neighbors, but in any case give preference to neighbors having many neighbors themselves.
##### Structured P2P
- Nodes (processes) are organised in an overlay that adheres to a specific, deterministic topology used to look up data
- Make use of a semantic-free index: each data item is uniquely associated with a key, in turn used as an index. 
	- Common practice: use a hash function: `key(data item) = hash(data item's value)`
- P2P system now responsible for storing (key,value) pairs.
###### Example: 4-dimensional Hypercube 
![[p2p-arch-as-4d-hyper-cube-ex.png]]
Made of 2 Hypercubes, each Hypercube has 8 vertices and 12 edges
- Looking up data **d** with key **in** {0,1, 2,…24-1} means **routing** request to node with **identifier** k
- Question: what happens when node with identifier **0111** is requested to look up the data having key **14**?
#### Hybrid Architectures
An important class of distributed systems that is organized according to a hybrid architecture is formed by **edge-server systems**. 

These systems are deployed on the Internet where servers are placed “at the edge” of the network. 
- This edge is formed by the boundary between enterprise networks and the actual Internet, for example, as provided by an **Internet Service Provider** **(ISP).** 
- Likewise, where end users at home connect to the Internet through their ISP, the ISP can be considered as residing at the edge of the Internet.

- Specific class of distributed systems in which client server solutions are combined with decentralised architectures
###### Example
Edge-server systems deployed on the Internet where servers are placed at the **edge** of the network: the boundary between enterprise networks and the actual Internet, e.g. as provided by **Internet Service providers** **(ISPs)**
![[internet-as-edge-servers-ex.png]]
_Viewing the Internet as consisting of a collection of edge servers._

- **End-users** connect to the Internet by means of an edge server
- **Edger servers** serve content; a collection of edge servers can be used to optimise content and application distribution.

End users, or clients in general, connect to the Internet by means of an edge server. 
- The edge server’s main purpose is to serve content, possibly after applying filtering and transcoding functions. 
- More interesting is the fact that a collection of edge servers can be used to optimize content and application distribution. 
- The basic model is that for a specific organization, one edge server acts as an origin server from which all content originates. 
	- That server can use other edge servers for replicating Web pages and such [Leff and Rayfield, 2004; Nayate et al., 2004; Rabinovich and Spastscheck, 2002]. 
- This concept of edge-server systems is now often taken a step further: 
	- taking cloud computing as implemented in a data center as the core, additional servers at the edge of the network are used to assist in computations and storage, essentially leading to distributed cloud systems. 
	- In the case of fog computing, even end-user devices form part of the system and are (partly) controlled by a cloud-service provider [Yi et al., 2015].