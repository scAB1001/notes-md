Monday 06/10/2025

---
#### Module Objectives
Three types of distributed systems
1. High performance distributed computing systems
2. Distributed information systems
3. Distributed systems for pervasive computing
### 1. High Performance Distributed Computing System
High-performance distributed computing started with parallel computing
- Multiprocessor and multi-core versus multi-computer 
#### Distributed Shared Memory systems 
Multiprocessors are relatively easy to program in comparison to multi-computers, yet have problems when increasing the number of processors (or cores). 

**Problem**
Performance of distributed shared memory could never compete with that of multiprocessors, and failed to meet the expectations of programmers. 
- It has been widely abandoned by now.
- Roughly speaking, one can make a distinction between two subgroups of DS for high-performance computing tasks.

**Solution** 
Try to implement a shared-memory model on top of a multi-computer. 
Example through virtual-memory techniques. 
- Map all main-memory pages (from different processors) into one single virtual address space. 
- If a process at processor A addresses a page P located at processor B, the OS at A traps and fetches P from B, just as it would if P had been located on local disk. 
#### Cluster Computing
Cluster computing systems became popular when the price/performance ratio of personal computers and workstations improved. 

- It then became financially and technically attractive to build a supercomputer using off-the-shelf technology by simply hooking up a collection of relatively simple computers in a high-speed network. 
- In virtually all cases, cluster computing is used for parallel programming in which a single (compute intensive) program is run in parallel on multiple machines.
##### Linux-based Beowulf clusters
![[cluster-computing-system-ex.png]]
- Each cluster consists of a collection of compute nodes that are controlled and accessed by means of a single master node. 
	- This node typically handles the allocation of nodes to a particular parallel program, maintains a batch queue of submitted jobs, and provides an interface for the users of the system. 
	- As such, the master node actually runs the middleware needed for the execution of programs and management of the cluster, while the compute nodes are equipped with a standard OS extended with typical middleware functions for communication, storage, fault tolerance, and so on. 
	- Apart from the master node, the compute nodes are thus seen to be highly identical.
##### MOSIX system [Amar et al., 2004] 
MOSIX takes a more symmetric approach; it attempts to provide a single-system image of a cluster, meaning that to a process a cluster computer offers the ultimate distribution transparency by appearing to be a single computer. 

As we mentioned, providing such an image under all circumstances is impossible. 
With MOSIX, the high degree of transparency is provided by allowing processes to dynamically and preemptively migrate between the nodes that make up the cluster. 

Process migration allows a user to start an application on any node (referred to as the home node), after which it can transparently move to other nodes, for example, to make efficient use of resources.

However, several modern cluster computers have been moving away from these symmetric architectures to more hybrid solutions in which the middleware is functionally partitioned across different nodes, as explained by En- gelmann et al. [2007]. 

The advantage of such a separation is obvious: 
- having compute nodes with dedicated, lightweight operating systems will most likely provide optimal performance for compute-intensive applications. 
- Likewise, storage functionality can most likely be optimally handled by other specially configured nodes such as file and directory servers. 
- The same holds for other dedicated middleware services, including job management, database services, and perhaps general Internet access to external services.
##### Summary
- Essentially a group of high-end systems connected
- through a Local Area Network (LAN)
- Homogeneous: same OS, near-identical hardware
- Single managing node running the OS
#### Grid Computing
Comprising DSs that are often constructed as a federation of computer systems, where each system may fall under a different administrative domain, and may be very different when it comes to hardware, software, and deployed network technology.

We've noted the emerging trend of a more hybrid architecture whereby nodes are configured specifically for certain tasks. This is even more prevelant in grid computing. 

A key issue in a grid-computing system is that resources from different organizations are brought together to allow the collaboration of a group of people from different institutions, forming a federation of systems. This becomes a form of virtual organization. 
- The processes belonging to the same virtual organization have access rights to the resources that are provided to that organization. 
- Typically, resources consist of compute servers (including supercomputers, possibly implemented as cluster computers), storage facilities, and databases. 
- In addition, special networked devices such as telescopes, sensors, etc., can be provided as well.

Given its nature, much of the software for realizing grid computing evolves around providing access to resources from different administrative domains, and to only those users and applications that belong to a specific virtual organization. For this reason, focus is often on architectural issues.
##### Proposed Architecture for grid computing systems Foster et al. [2001]
![[grid-computing-systems-proposed-arch-ex.png]]
The architecture consists of four layers. 
###### Fabric layer (0)
The lowest layer provides interfaces to local resources at a specific site. 
Note: _These interfaces are tailored to allow sharing of resources within a virtual organization._ 

Typically, they will provide functions for querying the state and capabilities of a resource, along with functions for actual resource management (e.g., locking resources). 
###### Connectivity layer (1)
Consists of communication protocols for supporting grid transactions that span the usage of multiple resources. 
- For example, protocols are needed to transfer data between resources, or access remote ones.
- In addition, this layer contains security protocols to authenticate users and resources. 
Note: _in many cases human users are not authenticated; instead, programs acting on behalf of the users are authenticated._ 

In this sense, delegating rights from a user to programs is an important function that needs to be supported in the connectivity layer. 
###### Resource layer (1)
Responsible for managing a single resource. 
It uses the functions provided by the connectivity layer and calls directly the interfaces made available by the fabric layer. 

For example, this layer will offer functions for obtaining configuration information on a specific resource, or, in general, to perform specific operations such as creating a process or reading data. 

This layer is responsible for access control, and hence will rely on the authentication performed as part of the connectivity layer.
###### Collective layer (2)
It deals with handling access to multiple resources and typically consists of services for resource discovery, allocation and scheduling of tasks onto multiple resources, data replication, and so on. 

Unlike the connectivity and resource layer, each consisting of a relatively small, standard collection of protocols, the collective layer may consist of many different protocols reflecting the broad spectrum of services it may offer to a virtual organization. 
###### Application layer
Consists of the applications that operate within a virtual organization and which make use of the grid computing environment. 

Typically the collective, connectivity, and resource layer form the heart of what could be called a **grid middleware layer**. 

These layers jointly provide access to and management of resources that are potentially dispersed across multiple sites.
##### Open Grid Services Architecture (OGSA) [Foster et al., 2006].
An important observation from a middleware perspective is that in grid computing the notion of a site (or administrative unit) is common. 

This prevalence is emphasized by the gradual shift toward a service-oriented architecture in which sites offer access to the various layers through a collection of Web services [Joseph et al., 2004]. 

This leads to the definition of an alternative architecture known as the Open Grid Services Architecture (OGSA). OGSA is based upon the original ideas as formulated by Foster et al. [2001], yet having gone through a standardization process makes it complex, to say the least. 
OGSA implementations generally follow Web service standards. 
#### Cloud Computing
From the perspective of grid computing, a next logical step is to simply outsource the entire infrastructure that is needed for compute-intensive applications. 

In essence, this is what cloud computing is all about: 
- providing the facilities to dynamically construct an infrastructure and compose what is needed from available services. 

Unlike grid computing, which is strongly associated with high-performance computing, cloud computing is much more than just providing lots of resources.
##### Definitions
Cloud computing is an information technology infrastructure in which computing resources are virtualised and accessed as a service.

Following Vaquero et al. [2008], cloud computing is characterized by an easily usable and accessible pool of _virtualized_ resources. 
- Which and how resources are used can be configured dynamically, providing the basis for scalability: 
	- if more work needs to be done, a customer can simply acquire more resources. 
	- The link to utility computing is formed by the fact that cloud computing is generally based on a pay-per-use model in which guarantees are offered by means of customized service level agreements (SLAs).

The next step: lots of nodes from everywhere
- Flexible, secure, coordinated resource sharing among dynamic collections of individuals, institutions, and resources
- Enable communities “Virtual Organisations” to share geographically distributed resources as they pursue common goals
##### Utility Computing
While researchers were pondering on how to organize computational grids that were easily accessible, organizations in charge of running data centers were facing the problem of opening up their resources to customers. 

This lead to the concept of utility computing by which a customer could upload tasks to a data center and be charged on a per-resource basis. This then formed the basis of cloud computing
##### Organisation
The organization of clouds (adapted from Zhang et al. [2010]). Four layers.
![[the-organisation-of-clouds.png]]

Distinction between four layers:
1. **Hardware**
	The lowest layer is formed by the means to manage the necessary hardware: processors, routers, but also power and cooling systems. It is generally implemented at data centers.
	- Processors, routers, power and cooling systems.
	- Customers normally never get to see these
2. **Infrastructure** 
	Provides customers an infrastructure consisting of virtual storage and computing resources.
	- Deploys virtualisation techniques. 
	- Evolves around allocating and managing virtual storage devices and virtual servers
3. **Platform** 
	One could argue that the platform layer provides to a cloud-computing customer what an operating system provides to application developers, namely the means to easily develop and deploy applications that need to run in a cloud. 
	- In practice, an application developer is offered a vendor-specific API, which includes calls to uploading and executing a program in that vendor’s cloud. 
	- In a sense, this is comparable  to the Unix exec family of system calls, which take an executable file as parameter and pass it to the operating system to be executed. 
	- Also like operating systems, the platform layer provides higher-level abstractions for storage and such. 
		- The Amazon S3 storage system [Murty, 2008] is offered to the application developer in the form of an API allowing (locally created) files to be organized and stored in buckets. 
		- A bucket is somewhat comparable to a directory. By storing a file in a bucket, that file is automatically uploaded to the Amazon cloud.
4. **Application** 
	Actual applications, such as office suites (text processors, spreadsheet applications, presentation applications) run here. 
	- It is important to realize that these applica- tions are again executed in the vendor’s cloud.
	- Comparable to the suite of apps shipped with OSes.
##### How these layers are provided
Cloud-computing providers offer these layers to their customers through various interfaces (including command-line tools, programming interfaces, and Web interfaces), leading to three different types of services:
- **Infrastructure-as-a-Service** (IaaS) covering the hardware and infrastructure layer
- **Platform-as-a-Service** (PaaS) covering the platform layer
- **Software-as-a-Service** (SaaS) in which their applications are covered

As of now, making use of clouds is relatively easy, and we discuss in later chapters more concrete examples of interfaces to cloud providers. 
As a consequence, cloud computing as a means for outsourcing local computing infrastructures has become a serious option for many enterprises. However, there are still a number of serious obstacles including provider lock-in, security and privacy issues, and dependency on the availability of services, to mention a few (see also Armbrust et al. [2010]). 

Also, because the details on how specific cloud computations are actually carried out are generally hidden, and even perhaps unknown or unpredictable, meeting performance demands may be impossible to arrange in advance. 
On top of this, Li et al. [2010] have shown that different providers may easily show very different performance profiles. 

Cloud computing is no longer a hype, and certainly a serious alternative to maintaining huge local infrastructures, yet there is still a lot of room for improvement.
### 2. Distributed Information Systems
Context: Integrating applications
Situation: organisations confronted with many networked applications, but achieving interoperability was painful.

Basic approach: a networked application is one that runs on a server making its services available to remote clients. Simple integration: clients combine requests for (different) applications; send that off; collect responses, and present a coherent result to the user. 

Next step: allow direct application-to-application communication, leading to Enterprise Application Integration (EAI).
  
Example: Distributed Transaction Processing
Context: Database applications where operations are carried out in the form of transactions

##### Transaction

| Primitive           | Description                                     |
| ------------------- | ----------------------------------------------- |
| `BEGIN_TRANSACTION` | Mark the start of a transaction                 |
| `END_TRANSACTION`   | Terminate the transaction and try to commit     |
| `ABORT_TRANSACTION` | Kill the transaction and restore the old values |
| `READ`              | Read data from a file, a table, or otherwise    |
| `WRITE`             | Write data from a file, a table, or otherwise   |
##### All or Nothing Property
Atomic: happens indivisibly (seemingly)
Consistent: does not violate system in-variants
Isolated: not mutual interference between concurrent transactions
Durable: commit means changes are permanent
 
**TPM: Transaction Processing Monitor**
In many cases, the data involved in a transaction is distributed across several servers. A TP Monitor is responsible for coordinating the execution of a transaction. 
  
**Middleware and EAI**
Middleware offers communication facilities for application integration Remote Procedure Call (RPC): Requests are sent through local procedure call, packaged as message, processed, responded through message, and result returned as return from call.

Message Oriented Middleware (MOM): Messages are sent to logical contact
point (published), and forwarded to subscribed applications
### 3. Distributed Pervasive Systems
Emerging next-generation of distributed systems in which nodes are small, mobile, and often embedded in a larger system, characterised by the fact that the system naturally blends into the user's environment

- Often coined as the Internet of Things (IoT)
- Three (overlapping) sub-types:
	1. Ubiquitous computing systems: pervasive and continuously present, i.e., there is a continuous interaction between system and user.
	2. Mobile computing systems: pervasive, but emphasis is on the fact that devices are inherently mobile.
	3. Sensor (and actuator) networks: pervasive, with emphasis on the actual (collaborative) sensing and actuation of the environment.

**Mobile Computing Systems**
**Features**
- A myriad of different mobile devices (smartphones, tablets, GPS devices, remote controls)
- Mobile implies that a device's location is expected to change over time, change of local services, reachability

Keyword: **discovery**
- Communication may become more difficult: no stable route, (possibly) no guaranteed connectivity 
- disruption-tolerant networking.

**Bottom line**
Mobile devices set up connections to stationary servers, essentially bringing mobile computing in the position of clients of cloud-based services.
- Mobile cloud computing
- Mobile edge computing

