Monday 06/10/2025

---
#### Module Objectives
Three types of distributed systems
1. High performance distributed computing systems
2. Distributed information systems
3. Distributed systems for pervasive computing
### 1. High Performance Distributed Computing System (HPDCS)
High-performance distributed computing started with parallel computing
- Multiprocessor and multi-core versus multi-computer 
#### Distributed Shared Memory systems 
Multiprocessors are relatively easy to program in comparison to multi-computers, yet have problems when increasing the number of processors (or cores). 

**Problem**
Performance of distributed shared memory could never compete with that of multiprocessors, and failed to meet the expectations of programmers. 
- It has been widely abandoned by now.
- Roughly speaking, one can make a distinction between two subgroups of DS for high-performance computing tasks.

**Solution** 
Try to implement a shared-memory model on top of a multi-computer. 
Example through virtual-memory techniques. 
- Map all main-memory pages (from different processors) into one single virtual address space. 
- If a process at processor A addresses a page P located at processor B, the OS at A traps and fetches P from B, just as it would if P had been located on local disk. 
#### Cluster Computing
Cluster computing systems became popular when the price/performance ratio of personal computers and workstations improved. 

- It then became financially and technically attractive to build a supercomputer using off-the-shelf technology by simply hooking up a collection of relatively simple computers in a high-speed network. 
- In virtually all cases, cluster computing is used for parallel programming in which a single (compute intensive) program is run in parallel on multiple machines.
##### Linux-based Beowulf clusters
![[cluster-computing-system-ex.png]]
- Each cluster consists of a collection of compute nodes that are controlled and accessed by means of a single master node. 
	- This node typically handles the allocation of nodes to a particular parallel program, maintains a batch queue of submitted jobs, and provides an interface for the users of the system. 
	- As such, the master node actually runs the middleware needed for the execution of programs and management of the cluster, while the compute nodes are equipped with a standard OS extended with typical middleware functions for communication, storage, fault tolerance, and so on. 
	- Apart from the master node, the compute nodes are thus seen to be highly identical.
##### MOSIX system [Amar et al., 2004] 
MOSIX takes a more symmetric approach; it attempts to provide a single-system image of a cluster, meaning that to a process a cluster computer offers the ultimate distribution transparency by appearing to be a single computer. 

As we mentioned, providing such an image under all circumstances is impossible. 
With MOSIX, the high degree of transparency is provided by allowing processes to dynamically and preemptively migrate between the nodes that make up the cluster. 

Process migration allows a user to start an application on any node (referred to as the home node), after which it can transparently move to other nodes, for example, to make efficient use of resources.

However, several modern cluster computers have been moving away from these symmetric architectures to more hybrid solutions in which the middleware is functionally partitioned across different nodes, as explained by En- gelmann et al. [2007]. 

The advantage of such a separation is obvious: 
- having compute nodes with dedicated, lightweight operating systems will most likely provide optimal performance for compute-intensive applications. 
- Likewise, storage functionality can most likely be optimally handled by other specially configured nodes such as file and directory servers. 
- The same holds for other dedicated middleware services, including job management, database services, and perhaps general Internet access to external services.
##### Summary
- Essentially a group of high-end systems connected
- through a Local Area Network (LAN)
- Homogeneous: same OS, near-identical hardware
- Single managing node running the OS
#### Grid Computing
Comprising DSs that are often constructed as a federation of computer systems, where each system may fall under a different administrative domain, and may be very different when it comes to hardware, software, and deployed network technology.

We've noted the emerging trend of a more hybrid architecture whereby nodes are configured specifically for certain tasks. This is even more prevelant in grid computing. 

A key issue in a grid-computing system is that resources from different organizations are brought together to allow the collaboration of a group of people from different institutions, forming a federation of systems. This becomes a form of virtual organization. 
- The processes belonging to the same virtual organization have access rights to the resources that are provided to that organization. 
- Typically, resources consist of compute servers (including supercomputers, possibly implemented as cluster computers), storage facilities, and databases. 
- In addition, special networked devices such as telescopes, sensors, etc., can be provided as well.

Given its nature, much of the software for realizing grid computing evolves around providing access to resources from different administrative domains, and to only those users and applications that belong to a specific virtual organization. For this reason, focus is often on architectural issues.
##### Proposed Architecture for grid computing systems Foster et al. [2001]
![[grid-computing-systems-proposed-arch-ex.png]]
The architecture consists of four layers. 
###### Fabric layer (0)
The lowest layer provides interfaces to local resources at a specific site. 
Note: _These interfaces are tailored to allow sharing of resources within a virtual organization._ 

Typically, they will provide functions for querying the state and capabilities of a resource, along with functions for actual resource management (e.g., locking resources). 
###### Connectivity layer (1)
Consists of communication protocols for supporting grid transactions that span the usage of multiple resources. 
- For example, protocols are needed to transfer data between resources, or access remote ones.
- In addition, this layer contains security protocols to authenticate users and resources. 
Note: _in many cases human users are not authenticated; instead, programs acting on behalf of the users are authenticated._ 

In this sense, delegating rights from a user to programs is an important function that needs to be supported in the connectivity layer. 
###### Resource layer (1)
Responsible for managing a single resource. 
It uses the functions provided by the connectivity layer and calls directly the interfaces made available by the fabric layer. 

For example, this layer will offer functions for obtaining configuration information on a specific resource, or, in general, to perform specific operations such as creating a process or reading data. 

This layer is responsible for access control, and hence will rely on the authentication performed as part of the connectivity layer.
###### Collective layer (2)
It deals with handling access to multiple resources and typically consists of services for resource discovery, allocation and scheduling of tasks onto multiple resources, data replication, and so on. 

Unlike the connectivity and resource layer, each consisting of a relatively small, standard collection of protocols, the collective layer may consist of many different protocols reflecting the broad spectrum of services it may offer to a virtual organization. 
###### Application layer
Consists of the applications that operate within a virtual organization and which make use of the grid computing environment. 

Typically the collective, connectivity, and resource layer form the heart of what could be called a **grid middleware layer**. 

These layers jointly provide access to and management of resources that are potentially dispersed across multiple sites.
##### Open Grid Services Architecture (OGSA) [Foster et al., 2006].
An important observation from a middleware perspective is that in grid computing the notion of a site (or administrative unit) is common. 

This prevalence is emphasized by the gradual shift toward a service-oriented architecture in which sites offer access to the various layers through a collection of Web services [Joseph et al., 2004]. 

This leads to the definition of an alternative architecture known as the Open Grid Services Architecture (OGSA). OGSA is based upon the original ideas as formulated by Foster et al. [2001], yet having gone through a standardization process makes it complex, to say the least. 
OGSA implementations generally follow Web service standards. 
#### Cloud Computing
From the perspective of grid computing, a next logical step is to simply outsource the entire infrastructure that is needed for compute-intensive applications. 

In essence, this is what cloud computing is all about: 
- providing the facilities to dynamically construct an infrastructure and compose what is needed from available services. 

Unlike grid computing, which is strongly associated with high-performance computing, cloud computing is much more than just providing lots of resources.
##### Definitions
Cloud computing is an information technology infrastructure in which computing resources are virtualised and accessed as a service.

Following Vaquero et al. [2008], cloud computing is characterized by an easily usable and accessible pool of _virtualized_ resources. 
- Which and how resources are used can be configured dynamically, providing the basis for scalability: 
	- if more work needs to be done, a customer can simply acquire more resources. 
	- The link to utility computing is formed by the fact that cloud computing is generally based on a pay-per-use model in which guarantees are offered by means of customized service level agreements (SLAs).

The next step: lots of nodes from everywhere
- Flexible, secure, coordinated resource sharing among dynamic collections of individuals, institutions, and resources
- Enable communities “Virtual Organisations” to share geographically distributed resources as they pursue common goals
##### Utility Computing
While researchers were pondering on how to organize computational grids that were easily accessible, organizations in charge of running data centers were facing the problem of opening up their resources to customers. 

This lead to the concept of utility computing by which a customer could upload tasks to a data center and be charged on a per-resource basis. This then formed the basis of cloud computing
##### Organisation
The organization of clouds (adapted from Zhang et al. [2010]). Four layers.
![[the-organisation-of-clouds.png]]

Distinction between four layers:
1. **Hardware**
	The lowest layer is formed by the means to manage the necessary hardware: processors, routers, but also power and cooling systems. It is generally implemented at data centers.
	- Processors, routers, power and cooling systems.
	- Customers normally never get to see these
2. **Infrastructure** 
	Provides customers an infrastructure consisting of virtual storage and computing resources.
	- Deploys virtualisation techniques. 
	- Evolves around allocating and managing virtual storage devices and virtual servers
3. **Platform** 
	One could argue that the platform layer provides to a cloud-computing customer what an operating system provides to application developers, namely the means to easily develop and deploy applications that need to run in a cloud. 
	- In practice, an application developer is offered a vendor-specific API, which includes calls to uploading and executing a program in that vendor’s cloud. 
	- In a sense, this is comparable  to the Unix exec family of system calls, which take an executable file as parameter and pass it to the operating system to be executed. 
	- Also like operating systems, the platform layer provides higher-level abstractions for storage and such. 
		- The Amazon S3 storage system [Murty, 2008] is offered to the application developer in the form of an API allowing (locally created) files to be organized and stored in buckets. 
		- A bucket is somewhat comparable to a directory. By storing a file in a bucket, that file is automatically uploaded to the Amazon cloud.
4. **Application** 
	Actual applications, such as office suites (text processors, spreadsheet applications, presentation applications) run here. 
	- It is important to realize that these applica- tions are again executed in the vendor’s cloud.
	- Comparable to the suite of apps shipped with OSes.
##### How these layers are provided
Cloud-computing providers offer these layers to their customers through various interfaces (including command-line tools, programming interfaces, and Web interfaces), leading to three different types of services:
- **Infrastructure-as-a-Service** (IaaS) covering the hardware and infrastructure layer
- **Platform-as-a-Service** (PaaS) covering the platform layer
- **Software-as-a-Service** (SaaS) in which their applications are covered

As of now, making use of clouds is relatively easy, and we discuss in later chapters more concrete examples of interfaces to cloud providers. 
As a consequence, cloud computing as a means for outsourcing local computing infrastructures has become a serious option for many enterprises. However, there are still a number of serious obstacles including provider lock-in, security and privacy issues, and dependency on the availability of services, to mention a few (see also Armbrust et al. [2010]). 

Also, because the details on how specific cloud computations are actually carried out are generally hidden, and even perhaps unknown or unpredictable, meeting performance demands may be impossible to arrange in advance. 
On top of this, Li et al. [2010] have shown that different providers may easily show very different performance profiles. 

Cloud computing is no longer a hype, and certainly a serious alternative to maintaining huge local infrastructures, yet there is still a lot of room for improvement.
### 2. Distributed Information Systems (DIS)
##### Context: Integrating applications
Many of the existing middleware solutions are the result of working with an infrastructure in which it was easier to integrate applications into an enterprise-wide information system [Alonso et al., 2004; Bernstein, 1996; Hohpe and Woolf, 2004]. 

##### Situation: organisations confronted with many networked applications, but achieving interoperability was painful.
We can distinguish several levels at which integration can take place. In many cases, a networked application simply consists of a server running that application (often including a database) and making it available to remote programs, called **clients**. 
- Such clients send a request to the server for executing a specific operation, after which a response is sent back. 
- Integration at the lowest level allows clients to wrap a number of requests, possibly for different servers, into a single larger request and have it executed as a distributed transaction.

The key idea is that all, or none of the requests are executed. 
##### Basic approach: a networked application is one that runs on a server making its services available to remote clients. 
Simple integration: clients combine requests for (different) applications; send that off; collect responses, and present a coherent result to the user. 

As applications became more sophisticated and were gradually separated into independent components (notably distinguishing database components from processing components), it became clear that integration should also take place by letting applications communicate directly with each other. 

This has now lead to a huge industry that concentrates on **Enterprise Application Integration (EAI)**.
##### Example: Distributed Transaction Processing
Context: Database applications where operations are carried out in the form of transactions.
- In a mail system, there might be primitives to send, receive, and forward mail. 
- In an accounting system, they might be quite different. READ and WRITE are typical examples, however. Ordinary statements, procedure calls, and so on, are also allowed inside a transaction. 
- In particular, **remote procedure calls (RPCs)**, that is, procedure calls to remote servers, are often also encapsulated in a transaction, leading to what is known as a **transactional RPC**.
##### Transaction primitives

| Primitive           | Description                                     |
| ------------------- | ----------------------------------------------- |
| `BEGIN_TRANSACTION` | Mark the start of a transaction                 |
| `END_TRANSACTION`   | Terminate the transaction and try to commit     |
| `ABORT_TRANSACTION` | Kill the transaction and restore the old values |
| `READ`              | Read data from a file, a table, or otherwise    |
| `WRITE`             | Write data from a file, a table, or otherwise   |
##### All or Nothing Property
`BEGIN_TRANSACTION` and `END_TRANSACTION` are used to delimit the scope of a transaction. 
- The operations between them form the body of the transaction. 
- The characteristic feature of a transaction is _either all of these operations are executed or none are executed_. 
	- These may be system calls, library procedures, or bracketing statements in a language, depending on the implementation. 
- This all-or-nothing property of transactions is one of the four characteristic properties that transactions have. 

More specifically, transactions adhere to the so-called ACID properties:
	**Atomic**: happens indivisibly (seemingly)
	**Consistent**: does not violate system in-variants
	**Isolated**: not mutual interference between concurrent transactions
	**Durable**: commit means changes are permanent

In DS, transactions are often constructed as a number of **subtransactions**, jointly forming a nested transaction. 
- The top-level transaction may fork off children that run in parallel with one another, on different machines, to gain performance or simplify programming. 
- Each of these children may also execute one or more subtransactions, or fork off its own children. 
##### Subtransaction issues
Imagine that a transaction starts several subtransactions in parallel, and one of these commits, making its results visible to the parent transaction. 
- After further computation, the parent aborts, restoring the entire system to the state it had before the top-level transaction started. 
- Consequently, the results of the subtransaction that committed must nevertheless be undone. Thus the permanence referred to above applies only to top-level transactions.

Since transactions can be nested arbitrarily deep, considerable administration is needed to get everything right. The semantics are clear, however. 
- When any transaction or subtransaction starts, it is conceptually _given a private copy of all data in the entire system for it to manipulate_ as it wishes. 
	- If it aborts, its private universe just vanishes, as if it had never existed. 
	- If it commits, its private universe replaces the parent’s universe. 
- Thus if a subtransaction commits and then later a new subtransaction is started, the second one sees the results produced by the first one. 
- Likewise, if an enclosing (higher level) transaction aborts, all its underlying subtransactions have to be aborted as well. 
- And if several transactions are started concurrently, the result is as if they ran sequentially in some unspecified order.
##### TPM: Transaction Processing Monitor
In the early days of enterprise middleware systems, the component that handled distributed (or nested) transactions formed the core for integrating applications at the server or database level. 

In many cases, _the data involved in a transaction is distributed across several servers_. 
A TP Monitor is responsible for coordinating the execution of a transaction and the commitment of subtransactions following a standard protocol known as **distributed

Nested transactions are important in DS, naturally providing a way of distributing a transaction across multiple machines, following a logical division of the work of the original transaction. 

For example, a transaction for planning a trip by which three different flights need to be reserved can be logically split up into three subtransactions. 
- Each of these subtransactions can be managed separately and independently of the other two.
![[tpm-in-a-ds.png]]
An important observation is that applications wanting to coordinate several subtransactions into a single transaction did not have to implement this coordination themselves. 

By simply making use of a TP monitor, this coordination was done for them. 
This is exactly where middleware comes into play: 
- it implements services that are useful for many applications avoiding that such services have to be reimplemented over and over again by application developers.
##### Middleware and EAI
Several types of communication middleware exist. 

With remote procedure calls (RPC), an application component can effectively send a request to another application component by doing a local procedure call, which results in the request being packaged as a message and sent to the callee. 

Likewise, the result will be sent back and returned to the application as the result of the procedure call. 
As the popularity of object technology increased, techniques were developed to allow calls to remote objects, leading to what is known as **remote method invocations (RMI)**. An RMI is _essentially the same as an RPC, except that it operates on objects instead of functions_.

Middleware offers communication facilities for application integration (EAIs)
![[middleware-in-eai.png]]

**Remote Procedure Call (RPC):** Requests are sent through local procedure call, packaged as message, processed, responded through message, and result returned as return from call.

RPC and RMI have the _disadvantage_ that the caller and callee both need to be up and running at the time of communication. 

In addition, they need to know **exactly** how to refer to each other. This tight coupling is often experienced as a serious drawback, and has lead to what is known as **message-oriented middleware (MOM)**. 

In this case, applications send messages to logical contact points, often described by means of a subject. 
- Likewise, applications can indicate their interest for a specific type of message, after which the communication middleware will take care that those messages are delivered to those applications. 
- These so-called **publish/subscribe systems** form an important and expanding class of distributed systems.
- Messages are sent to logical contact point (published), and forwarded to subscribed applications.
### 3. Distributed Pervasive Systems (DPS)
Emerging next-generation of distributed systems in which nodes are small, mobile, and often embedded in a larger system, characterised by the fact that the system naturally blends into the user's environment

What makes them unique in comparison to the computing and information systems described so far, is that the separation between users and system components is much more blurred. 

There is often no single dedicated interface, such as a screen/keyboard combination. 
Instead, a pervasive system is often equipped with many **sensors** that pick up various aspects of a user’s behavior. Likewise, it may have a myriad of **actuators** to provide information and feedback, often even purposefully aiming to _steer_ behavior.


- Often coined as the Internet of Things (IoT)
- We often need to deal with the intricacies of wireless and mobile communication, will require special solutions to make a pervasive system as transparent or unobtrusive as possible.
##### Three (overlapping) sub-types:
1. **Ubiquitous computing systems**: pervasive and continuously present, i.e., there is a continuous interaction between system and user.
2. **Mobile computing systems**: pervasive, but emphasis is on the fact that devices are inherently mobile.
3. **Sensor (and actuator) networks**: pervasive, with emphasis on the actual (collaborative) sensing and actuation of the environment.
#### Ubiquitous computing systems
This DPS system is pervasive and continuously present. 
- The latter means that a user will be continuously interacting with the system, often not even being aware that interaction is taking place. 
- Poslad [2009] describes the core requirements for a ubiquitous computing system roughly as follows: 
	1. (**Distribution**) Devices are networked, distributed, and accessible in a transparent manner 
	2. (**Interaction**) Interaction between users and devices is highly unobtrusive 
	3. (**Context awareness**) The system is aware of a user’s context in order to optimize interaction 
	4. (**Autonomy**) Devices operate autonomously without human interven- tion, and are thus highly self-managed 
	5. (**Intelligence**) The system as a whole can handle a wide range of dy- namic actions and interactions 

Let us briefly consider these requirements from a distributed-systems perspective.
###### Distribution
As mentioned, a ubiquitous computing system is an example of a distributed system: the devices and other computers forming the nodes of a system are simply networked and work together to form the illusion of a single coherent system. 

Distribution also comes naturally: 
- there will be devices close to users (such as sensors and actuators), connected to computers hidden from view and perhaps even operating remotely in a cloud. 
- Most, if not all, of the requirements regarding distribution transparency mentioned, should therefore hold.
###### Interaction
When it comes to interaction with users, ubiquitous computing systems differ a lot in comparison to the systems we have been discussing so far; much of the interaction by humans will be **implicit**, with an implicit action being defined as _one that is not primarily aimed to interact with a computerized system but which such a system understands as input_ [Schmidt, 2000]. 

In other words, a user could be mostly unaware of the fact that input is being provided to a computer system, seemingly _hiding interfaces_.

A simple example is where the settings of a car’s driver’s seat, steering wheel, and mirrors is fully personalized. 
- If Bob takes a seat, the system will recognize that it is dealing with Bob and subsequently makes the appropriate adjustments. 
- The same happens when Alice uses the car, while an unknown user will be steered toward making his or her own adjustments (to be remembered for later). 

This example already illustrates an important role of sensors in ubiquitous computing, namely as input devices that are used to identify a situation (a specific person apparently wanting to drive), whose input analysis leads to actions (making adjustments). 

In turn, the actions may lead to natural reactions, for example that Bob slightly changes the seat settings. The system will have to take all (implicit and explicit) actions by the user into account and react accordingly.
###### Context awareness
Reacting to the sensory input, but also the explicit input from users by taking the context in which interactions take place into account. 

Context awareness is described by Dey and Abowd [2000] as _any information that can be used to characterize the situation of entities (i.e., whether a person, place or object) that are considered relevant to the interaction between a user and an application, including the user and the application themselves_. 

In practice, context is often characterized by location, identity, time, and activity: 
- the where, who, when, and what. 
- A system will need to have the necessary (sensory) input to determine one or several of these context types. 
- Raw data as collected by various sensors is lifted to a level of abstraction that can be used by applications. 

A concrete example is detecting where a person is, for example in terms of GPS coordinates, and subsequently mapping that information to an actual location, such as the corner of a street, or a specific shop or other known facility. 

The question is where this processing of sensory input takes place: 
- is all data collected at a central server connected to a database with detailed information on a city, or is it the user’s smartphone where the mapping is done? 
- Clearly, there are trade-offs to be considered.

When it comes to combining flexibility and potential distribution, so-called shared data spaces in which processes are decoupled in time and space are attractive, yet, suffer from scalability problems. 
###### Autonomy
An important aspect of most ubiquitous computing systems is that explicit systems management has been reduced to a minimum. 

In a ubiquitous computing environment there is simply no room for a systems administrator to keep everything up and running. 
- As a consequence, the system as a whole should be able to act autonomously, and automatically react to changes. 

This requires a myriad of techniques; to give a few simple examples, think of the following:
- **Address allocation**
	- In order for networked devices to communicate, they need an IP address. Addresses can be allocated automatically using protocols like the Dynamic Host Configuration Protocol (DHCP) [Droms, 1997] (which requires a server) or Zeroconf [Guttman, 2001]. 
- **Adding devices**
	- It should be easy to add devices to an existing system. A step towards automatic configuration is realized by the Universal Plug and Play Protocol (UPnP) [UPnP Forum, 2008].
	- Using UPnP, devices can discover each other and make sure that they can set up communication channels between them. 
- **Automatic updates
	- Many devices in a ubiquitous computing system should be able to regularly check through the Internet if their software should be updated. 
	- If so, they can download new versions of their components and ideally continue where they left off.
Manual intervention is to be kept to a minimum.
###### Intelligence
FinallyPoslad [2009] mentions that ubiquitous computing systems often use methods and techniques from the field of artificial intelligence. 

In many cases, a wide range of advanced algorithms and models need to be deployed to handle incomplete input, quickly react to a changing environment, handle unexpected events, and so on. 

The extent to which this can or should be done in a distributed fashion is crucial from the perspective of distributed systems. Unfortunately, distributed solutions for many problems in the field of artificial intelligence are yet to be found, meaning that there may be a natural tension between the first requirement of networked and distributed devices, and advanced distributed information processing.
#### Mobile Computing Systems
Mobility often forms an important component of pervasive systems, and many, if not all aspects that we have just discussed also apply to mobile computing. There are several issues that set mobile computing aside to pervasive systems in general (see also Adelstein et al. [2005] and Tarkoma and Kangasharju [2009]). 

First, the devices that form part of a (distributed) mobile system may vary widely. Typically, mobile computing is now done with devices such as smartphones and tablet computers. 

However, completely different types of devices are now using the Internet Protocol (IP) to communicate, placing mobile computing in a different perspective. 
- Such devices include remote controls, pagers, active badges, car equi ment, various GPS-enabled devices, and so on. 
- A characteristic feature of al  these devices is that they use wireless communication. Mobile implies wireless so it seems (although there are exceptions to the rules).

Second, in mobile computing the location of a device is assumed to change over time. 
A changing location has its effects on many issues. For example, if the location of a device changes regularly, so will perhaps the services that are locally available. 
- As a consequence, we may need to pay special attention to dynamically discovering services, but also letting services announce their presence. 
- In a similar vein, we often also want to know where a device actually is and may need the actual geographical coordinates of a device such as in tracking and tracing applications, but it may also require that we are able to simply detect its network position (as in mobile IP [Perkins, 2010; Perkins et al., 2011]. 

Changing locations also has a profound effect on communication. To illustrate, consider a (wireless) mobile ad hoc network, generally abbreviated as a MANET. 
- Suppose that two devices in a MANET have discovered each other in the sense that they know each other’s network address. 
- How do we route messages between the two? 
	- Static routes are generally not sustainable as nodes along the routing path can easily move out of their neighbor’s range, invalidating the path. 
- For large MANETs, using a priority set-up paths is not a viable option. 

What we are dealing with here are so-called disruption-tolerant networks: 
- networks in which connectivity between two nodes can simply not be guaranteed. 
- Getting a message from one node to another may then be problematic, to say the least.

The trick in such cases, is not to attempt to set up a communication path from the source to the destination, but to rely on two principles. 
- First, using special flooding-based techniques will allow a message to gradually spread through a part of the network, to eventually reach the destination. 
	- Obviously, any type of flooding will impose redundant communication, but this may be the price we have to pay. 
- Second, in a disruption-tolerant network, we let an intermediate node store a received message until it encounters another node to which it can pass it on. 
	- In other words, a node becomes a temporary carrier of a message, as sketched in (See Figure). Eventually, the message should reach its destination.

_Passing messages in a (mobile) disruption-tolerant network_
![[passing-messages-disruption-tolerant-network.png]]

It is not difficult to imagine that selectively passing messages to encountered nodes may help to ensure efficient delivery. For example, if nodes are known to belong to a certain class, and the source and destination belong to the same class, we may decide to pass messages only among nodes in that class. Likewise, it may prove efficient to pass messages only to well-connected nodes, that is, nodes who have been in range of many other nodes in the recent past. An overview is provided by Spyropoulos et al. [2010].
#### Sensor networks 
They are more than just a collection of input devices; instead, sensor nodes often collaborate to efficiently process the sensed data in an application-specific manner, making them very different from, for example, traditional computer networks. 

Akyildiz et al. [2002] and Akyildiz et al. [2005] provide an overview from a networking perspective. 
A more systems-oriented introduction to sensor networks is given by Zhao and Guibas [2004], but also Karl and Willig [2005] will show to be useful. 

A sensor network generally consists of tens to hundreds or thousands of relatively small nodes, each equipped with one or more sensing devices. In addition, nodes can often act as actuators [Akyildiz and Kasimoglu, 2004], a typical example being the automatic activation of sprinklers when a fire has been detected. 

Many sensor networks use wireless communication, and the nodes are often battery powered. 
- Their limited resources, restricted communication capabilities, and constrained power consumption demand that efficiency is high on the list of design criteria. 
- When zooming into an individual node, we see that, conceptually, they do not differ a lot from “normal” computers: 
	- above the hardware there is a software layer akin to what traditional operating systems offer, including low-level network access, access to sensors and actuators, memory management, and so on. 
- Normally, support for specific services is included, such as localization, local storage (think of additional flash devices), and convenient communication facilities such as messaging and routing. 
- However, similar to other networked computer systems, additional support is needed to effectively deploy sensor network applications. In distributed systems, this takes the form of middleware. 

For sensor networks, instead of looking at middleware, it is better to see what kind of programming support is provided, which has been extensively surveyed by Mottola and Picco [2011]. 
- One typical aspect in programming support is the scope provided by communication primitives. 
- This scope can vary between addressing the physical neighborhood of a node, and providing primitives for systemwide communication. In addition, it may also be possible to address a specific group of nodes. 
	- Likewise, computations may be restricted to an individual node, a group of nodes, or affect all nodes. To illustrate, Welsh and Mainland [2004] use so-called abstract regions allowing a node to identify a neighborhood from where it can, for example, gather information:
	```cpp
	region = k_nearest_region.create(8);
	reading = get_sensor_reading();
	region.putvar(reading_key, reading);
	max_id = region.reduce(OP_MAXID, reading_key);
	```
In line 1, a node first creates a region of its eight nearest neighbors, after which it fetches a value from its sensor(s). This reading is subsequently written to the previously defined region to be defined using the key `reading_key`. In line 4, the node checks whose sensor reading in the defined region was the largest, which is returned in the variable `max_id`.

As another related example, consider a sensor network as implementing a distributed database, which is, according to Mottola and Picco [2011], one of four possible ways of accessing data. 
- This database view is quite common and easy to understand when realizing that many sensor networks are deployed for measurement and surveillance applications [Bonnet et al., 2002]. 
- In these cases, an operator would like to extract information from (a part of) the network by simply issuing queries 

To organize a sensor network as a distributed database, there are essentially two extremes:
- First, sensors do not cooperate but simply send their data to a centralized database located at the operator’s site. 
- The other extreme is to forward queries to relevant sensors and to let each compute an answer, requiring the operator to aggregate the responses. 
- Neither of these solutions is very attractive. 
##### Organizing a sensor network database, while storing and processing data (a) only at the operator’s site or (b) only at the sensors.
![[sensor-network-db-on-site-vs-at-sensors.png]]

- The first one requires that sensors send all their measured data through the network, which may waste network resources and energy. 
- The second solution may also be wasteful as it discards the aggregation capabilities of sensors which would allow much less data to be returned to the operator. 

What is needed are facilities for in-network data processing, similar to the previous example of abstract regions. In-network processing can be done in numerous ways. 
- One obvious one is to forward a query to all sensor nodes along a tree encompassing all nodes and to subsequently aggregate the results as they are propagated back to the root, where the initiator is located. 
- Aggregation will take place where two or more branches of the tree come together. As simple as this scheme may sound, it introduces difficult questions: 
	- How do we (dynamically) set up an efficient tree in a sensor network?
	- How does aggregation of results take place? Can it be controlled?
	- What happens when network links fail? 
- These questions have been partly addressed in TinyDB, which implements a declarative (database) interface to wireless sensor networks [Madden et al., 2005]. 
- In essence, TinyDB can use any tree-based routing algorithm.

An intermediate node will collect and aggregate the results from its children, along with its own findings, and send that toward the root. 
- To make matters efficient, queries span a period of time allowing for careful scheduling of operations so that network resources and energy are optimally consumed. 

However, when queries can be initiated from different points in the net- work, using single-rooted trees such as in TinyDB may not be efficient enough. 
- As an alternative, sensor networks may be equipped with special nodes where results are forwarded to, as well as the queries related to those results. 

To give a simple example, queries and results related to temperature readings may be collected at a different location than those related to humidity measurements. 
- This approach corresponds directly to the notion of publish/subscribe systems.

**Features**
- A myriad of different mobile devices (smartphones, tablets, GPS devices, remote controls)
- Mobile implies that a device's location is expected to change over time, change of local services, reachability

Keyword: **discovery**
- Communication may become more difficult: no stable route, (possibly) no guaranteed connectivity 
- disruption-tolerant networking.

**Bottom line**
Mobile devices set up connections to stationary servers, essentially bringing mobile computing in the position of clients of cloud-based services.
- Mobile cloud computing
- Mobile edge computing

