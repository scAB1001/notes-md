Thursday 02/10/2025

---
#### Transparency 

| Transparency  | Description                                                           |
| ------------- | --------------------------------------------------------------------- |
| _Access_      | Hide differences in data representation and how an object is accessed |
| _Location_    | Hide where an object is physically located in the system              |
| _Migration_   | Hide that an object may move to another location                      |
| _Relocation_  | Hide that an object may be moved to another location while in use     |
| _Replication_ | Hide that an object is replicated                                     |
| _Concurrency_ | Hide that an object may be shared by several competitive users        |
| _Failure_     | Hide the failure and recovery of an object                            |
  
**Middleware and Openness**
**Open distributed system**: a system that offers components that can easily be
used by, or integrated into other systems. An open distributed system itself will
often consist of components that originate from elsewhere.

They share the same interface and communicate with the same common protocol. Be able to interact with services from other open systems, irrespective of the underlying environment:

Systems should conform to well-defined interfaces, easily interoperate, support portability of applications and be easily extensible.

### Scalability
We need to consider whether a DS scales in
- Size: number of users and/or processes
- Geographically: maximum distance between nodes
- Administratively: number of administrative domains, e.g. Google data centres worldwide

DS is scalable in size if it remains effective after a significant increase in the number of users/resources
- Example: Internet
- Poor scalability if cost of supporting n users is worse than O(n)
- Scalability improves if information is organised hierarchically rather than linearly; Cost becomes O(log(n))
#### Scalability Issues
##### **Geographically** – Synchronisation and Communication
One of the main reasons why it is still difficult to scale existing distributed systems that were designed for local-area networks is that many of them are based on synchronous communication.
- In this form of communication, a party requesting service, generally referred to as a client, blocks until a reply is sent back from the server implementing the service. More specifically, we often see a communication pattern consisting of many client-server interactions as may be the case with database transactions. 
	- This approach generally works fine in LANs where communication between two machines is often at worst a few hundred microseconds.
	- However, in a wide-area system, we need to take into account that interprocess communication may be hundreds of milliseconds, three orders of magnitude slower. 
	- A latency problem.
	- Building applications using synchronous communication in wide-area systems requires a great deal of care (and not just a little patience), notably with a rich interaction pattern between client and server. 

Another problem that hinders geographical scalability is that communication in wide-area networks is inherently much less reliable than in local-area networks. 
- In addition, we also need to deal with limited bandwidth. 
- The effect is that solutions developed for local-area networks cannot always be easily ported to a wide-area system. 
- A typical example is streaming video. In a home network, even when having only wireless links, ensuring a stable, fast stream of high-quality video frames from a media server to a display is quite simple. Simply placing that same server far away and using a standard TCP connection to the display will surely fail: bandwidth limitations will instantly surface, but also maintaining the same level of reliability can easily cause headaches.

Yet another issue that pops up when components lie far apart is the fact that wide-area systems generally have only very limited facilities for multipoint communication. 
- In contrast, local-area networks often support efficient broadcasting mechanisms. Such mechanisms have proven to be extremely useful for discovering components and services, which is essential from a management point of view. 
- In wide-area systems, we need to develop separate services, such as naming and directory services to which queries can be sent. 
- These support services, in turn, need to be scalable as well and in many cases no obvious solutions exist (as we will encounter in later chapters).
#### Administratively
- Dependent/independent administrative domains
- Possible conflicting policies
	- Resource usage, management, security
How to scale a distributed system across multiple, independent adminis-
trative domains. A major problem that needs to be solved is that of conflicting
policies with respect to resource usage (and payment), management, and
security.
To illustrate, for many years scientists have been looking for solutions to
share their (often expensive) equipment in what is known as a computational
grid. In these grids, a global distributed system is constructed as a federation
of local distributed systems, allowing a program running on a computer at
organization A to directly access resources at organization B.
For example, many components of a distributed system that reside within
a single domain can often be trusted by users that operate within that same
domain. In such cases, system administration may have tested and certified
applications, and may have taken special measures to ensure that such com-
ponents cannot be tampered with. In essence, the users trust their system
administrators. However, this trust does not expand naturally across domain
boundaries.

(Example: A modern radio telescope)
As an example, consider developing a modern radio telescope, such as the Pierre
Auger Observatory [Abraham et al., 2004]. The final system can be considered as
a federated distributed system:
• The radio telescope itself may be a wireless distributed system developed
as a grid of a few thousand sensor nodes, each collecting radio signals
and collaborating with neighboring nodes to filter out relevant events. The
nodes dynamically maintain a sink tree by which selected events are routed
to a central point for further analysis.
• The central point needs to be a reasonably powerful system, capable of
storing and processing the events sent to it by the sensor nodes. This system
is necessarily placed in proximity of the sensor nodes, but is otherwise to
be considered to operate independently. Depending on its functionality, it
may operate as a small local distributed system. In particular, it stores all
recorded events and offers access to remote systems owned by partners in
the consortium.
• Most partners have local distributed systems (often in the form of a cluster
of computers) that they use to further process the data collected by the
telescope. In this case, the local systems directly access the central point at
the telescope using a standard communication protocol. Naturally, many
results produced within the consortium are made available to each partner.
It is thus seen that the complete system will cross boundaries of several adminis-
trative domains, and that special measures are needed to ensure that data that
is supposed to be accessible only to (specific) consortium partners cannot be
disclosed to unauthorized parties. How to achieve administrative scalability is
not obvious.
 If a distributed system expands to another domain, two types of security measures need to be taken. First, the distributed system has to protect itself against malicious attacks from the new domain. For example, users from the new domain may have only read access to the file system in its original domain. Likewise, facilities such as expensive image setters or high- performance computers may not be made available to unauthorized users. Second, the new domain has to protect itself against malicious attacks from the distributed system. A typical example is that of downloading programs such as applets in Web browsers. Basically, the new domain does not know what to expect from such foreign code. The problem, as we shall see in Chapter 9, is how to enforce those limitations. As a counterexample of distributed systems spanning multiple adminis- trative domains that apparently do not suffer from administrative scalability problems, consider modern file-sharing peer-to-peer networks. In these cases, end users simply install a program implementing distributed search and download functions and within minutes can start downloading files. Other ex- amples include peer-to-peer applications for telephony over the Internet such as Skype [Baset and Schulzrinne, 2006], and peer-assisted audio-streaming applications such as Spotify [Kreitz and Niemelä, 2010]. What these dis- tributed systems have in common is that end users, and not administrative entities, collaborate to keep the system up and running. At best, underlying administrative organizations such as Internet Service Providers (ISPs) can police the network traffic that these peer-to-peer systems cause, but so far such efforts have not been very effective.
### Scaling Techniques
#### Hiding Communication latencies
The difference between letting:
	a) a server or
	b) a client check forms as they are being filled
#### Distribution & Domain Name Lookup and Addressing
- Name table for machines on the Internet was originally a single master file, held on one server
- Centralised approach works for a network consisting of a few hundred machines 
	Does not scale well
- Domain Name System (DNS) partitions name table between servers distributed across the Internet, administered locally
- Hierarchical nature of DNS means that name lookup does not take twice as long when number of machines on the Internet doubles
#### Replication
- Replicate components across a DS
	- Increases availability
	- Helps balance the load between components
	- Can hide communication latency problems
- Drawback
	- Having multiple copies (cached or replicated), leads to inconsistencies: modifying one copy makes that copy different from the rest.
	- Always keeping copies consistent and in a general way requires global synchronisation on each modification.
	- Global synchronisation precludes large-scale solutions.
#### Developing Distributed Systems: Pitfalls
Many distributed systems are needlessly complex caused by mistakes that required patching later
Many false assumptions are often made:
1. The network is reliable
2. The network is secure
3. The network is homogeneous
4. Topology doesn't change
5. Latency is zero
6. Bandwidth is infinite
7. Transport cost is zero
8. There is one administrator

Question: Is there a 9th fallacy?
#### Examples
Consider computational capacity. 
Imagine a service for computing optimal routes taking real-time traffic information into account. 
- This may be primarily a compute-bound service requiring several (tens of) seconds to complete a request. 
- If there is only a single machine available, then even a modern high-end system will eventually run into problems if the number of requests increases beyond a certain point.

Likewise, we will run into problems when having a service that is mainly I/O bound. 
A typical example is a poorly designed centralized search engine. 
- The problem with content-based search queries is that we essentially need to match a query against an entire data set. 
- Even with advanced indexing techniques, we may still face the problem of having to process a huge amount of data exceeding the main-memory capacity of the machine running the service. 
- As a consequence, much of the processing time will be determined by the relatively slow disk accesses and transfer of data between disk and main memory. 
- Simply adding more or higher-speed disks will prove not to be a sustainable solution as the number of requests continues to increase.

Finally, the network between the user and the service may also be the cause of poor scalability. Just imagine a video-on-demand service that needs to stream high-quality video to multiple users. 
- A video stream can easily require a bandwidth of 8 to 10 Mbps, meaning that if a service sets up point-to-point connections with its customers, it may soon hit the limits of the network capacity of its own outgoing transmission lines.


