Thursday 02/10/2025

---
#### Transparency 

| Transparency  | Description                                                           |
| ------------- | --------------------------------------------------------------------- |
| _Access_      | Hide differences in data representation and how an object is accessed |
| _Location_    | Hide where an object is physically located in the system              |
| _Migration_   | Hide that an object may move to another location                      |
| _Relocation_  | Hide that an object may be moved to another location while in use     |
| _Replication_ | Hide that an object is replicated                                     |
| _Concurrency_ | Hide that an object may be shared by several competitive users        |
| _Failure_     | Hide the failure and recovery of an object                            |
  
**Middleware and Openness**
**Open distributed system**: a system that offers components that can easily be
used by, or integrated into other systems. An open distributed system itself will
often consist of components that originate from elsewhere.

They share the same interface and communicate with the same common protocol. Be able to interact with services from other open systems, irrespective of the underlying environment:

Systems should conform to well-defined interfaces, easily interoperate, support portability of applications and be easily extensible.

### Scalability
We need to consider whether a DS scales in
- Size: number of users and/or processes
- Geographically: maximum distance between nodes
- Administratively: number of administrative domains, e.g. Google data centres worldwide

DS is scalable in size if it remains effective after a significant increase in the number of users/resources
- Example: Internet
- Poor scalability if cost of supporting n users is worse than O(n)
- Scalability improves if information is organised hierarchically rather than linearly; Cost becomes O(log(n))
#### Scalability Issues
##### Consider computational capacity. 
Imagine a service for computing optimal routes taking real-time traffic information into account. 
- This may be primarily a compute-bound service requiring several (tens of) seconds to complete a request. 
- If there is only a single machine available, then even a modern high-end system will eventually run into problems if the number of requests increases beyond a certain point.

Likewise, we will run into problems when having a service that is mainly I/O bound. 
A typical example is a poorly designed centralized search engine. 
- The problem with content-based search queries is that we essentially need to match a query against an entire data set. 
- Even with advanced indexing techniques, we may still face the problem of having to process a huge amount of data exceeding the main-memory capacity of the machine running the service. 
- As a consequence, much of the processing time will be determined by the relatively slow disk accesses and transfer of data between disk and main memory. 
- Simply adding more or higher-speed disks will prove not to be a sustainable solution as the number of requests continues to increase.

Finally, the network between the user and the service may also be the cause of poor scalability. Just imagine a video-on-demand service that needs to stream high-quality video to multiple users. 
- A video stream can easily require a bandwidth of 8 to 10 Mbps, meaning that if a service sets up point-to-point connections with its customers, it may soon hit the limits of the network capacity of its own outgoing transmission lines.
##### **Geographically** â€“ Synchronisation and Communication
One of the main reasons why it is still difficult to scale existing distributed systems that were designed for local-area networks is that many of them are based on synchronous communication.
- In this form of communication, a party requesting service, generally referred to as a client, blocks until a reply is sent back from the server implementing the service. More specifically, we often see a communication pattern consisting of many client-server interactions as may be the case with database transactions. 
	- This approach generally works fine in LANs where communication between two machines is often at worst a few hundred microseconds.
	- However, in a wide-area system, we need to take into account that interprocess communication may be hundreds of milliseconds, three orders of magnitude slower. 
	- A latency problem.
	- Building applications using synchronous communication in wide-area systems requires a great deal of care (and not just a little patience), notably with a rich interaction pattern between client and server. 

Another problem that hinders geographical scalability is that communication in wide-area networks is inherently much less reliable than in local-area networks. 
- In addition, we also need to deal with limited bandwidth. 
- The effect is that solutions developed for local-area networks cannot always be easily ported to a wide-area system. 
- A typical example is streaming video. In a home network, even when having only wireless links, ensuring a stable, fast stream of high-quality video frames from a media server to a display is quite simple. Simply placing that same server far away and using a standard TCP connection to the display will surely fail: bandwidth limitations will instantly surface, but also maintaining the same level of reliability can easily cause headaches.

Yet another issue that pops up when components lie far apart is the fact that wide-area systems generally have only very limited facilities for multipoint communication. 
- In contrast, local-area networks often support efficient broadcasting mechanisms. Such mechanisms have proven to be extremely useful for discovering components and services, which is essential from a management point of view. 
- In wide-area systems, we need to develop separate services, such as naming and directory services to which queries can be sent. 
- These support services, in turn, need to be scalable as well and in many cases no obvious solutions exist (as we will encounter in later chapters).
#### Administratively
- Dependent/independent administrative domains
- Possible conflicting policies
	- Resource usage, management, security

How do we scale a distributed system across multiple, independent administrative domains? 
A major problem that needs to be solved is that of conflicting policies with respect to resource usage (and payment), management, and security. 
- To illustrate, for many years scientists have been looking for solutions to share their (often expensive) equipment in what is known as a computational grid. 
- In these grids, a global distributed system is constructed as a federation of local distributed systems, allowing a program running on a computer at organization A to directly access resources at organization B. 
	- For example, many components of a DS that reside within a single domain can often be trusted by users that operate within that same domain. 
	- In such cases, system administration may have tested and certified applications, and may have taken special measures to ensure that such components cannot be tampered with.
	- In essence, the users trust their system administrators. However, this trust does not expand naturally across domain boundaries.

 If a distributed system expands to another domain, two types of security measures need to be taken. 
 - First, the distributed system has to protect itself against malicious attacks from the new domain. 
	 - For example, users from the new domain may have only read access to the file system in its original domain. 
	 - Likewise, facilities such as expensive image setters or high- performance computers may not be made available to unauthorized users. 
 - Second, the new domain has to protect itself against malicious attacks from the distributed system. 
	 - A typical example is that of downloading programs such as applets in Web browsers. Basically, the new domain does not know what to expect from such foreign code. 
	 - The problem, as we shall see in Chapter 9, is how to enforce those limitations. 
##### Example: A modern radio telescope
As an example, consider developing a modern radio telescope, such as the Pierre Auger Observatory [Abraham et al., 2004]. The final system can be considered as a federated DS: 
- The radio telescope itself may be a wireless distributed system developed as a grid of a few thousand sensor nodes, each collecting radio signals and collaborating with neighboring nodes to filter out relevant events. 
	- The nodes dynamically maintain a sink tree by which selected events are routed to a central point for further analysis. 
	- The central point needs to be a reasonably powerful system, capable of storing and processing the events sent to it by the sensor nodes. 
- This system is necessarily placed in proximity of the sensor nodes, but is otherwise to be considered to operate independently. 
	- Depending on its functionality, it may operate as a small local distributed system. 
	- In particular, it stores all recorded events and offers access to remote systems owned by partners in the consortium. 
- Most partners have local distributed systems (often in the form of a cluster of computers) that they use to further process the data collected by the telescope. 
	- In this case, the local systems directly access the central point at the telescope using a standard communication protocol. 
	- Naturally, many results produced within the consortium are made available to each partner. It is thus seen that the complete system will cross boundaries of several adminis- trative domains, and that special measures are needed to ensure that data that is supposed to be accessible only to (specific) consortium partners cannot be disclosed to unauthorized parties. 
- How to achieve administrative scalability is not obvious.

 ##### Counter example:  DSs spanning multiple administrative domains that do not suffer from administrative scalability problems
 Consider modern file-sharing peer-to-peer networks. 
 - In these cases, end users simply install a program implementing distributed search and download functions and within minutes can start downloading files. 
	 - Other ex- amples include peer-to-peer applications for telephony over the Internet such as Skype [Baset and Schulzrinne, 2006], and peer-assisted audio-streaming applications such as Spotify [Kreitz and NiemelÃ¤, 2010]. 
 - What these distributed systems have in common is that end users, and not administrative entities, collaborate to keep the system up and running. 
	 - At best, underlying administrative organizations such as Internet Service Providers (ISPs) can police the network traffic that these peer-to-peer systems cause, but so far such efforts have not been very effective.
### Scaling Techniques
In most cases, scalability problems in distributed systems appear as performance problems caused by limited capacity of servers and network. 
- Simply improving their capacity (e.g., by increasing memory, upgrading CPUs, or replacing network modules) is often a solution, referred to as **scaling up**. 
- When it comes to **scaling out**, that is, expanding the distributed system by essentially deploying more machines, there are basically only three techniques we can apply: 
	1. hiding communication latencies,
	2. distribution of work, and 
	3. replication (see also Neuman [1994]).
#### Hiding Communication latencies
Applicable in the case of geographical scalability.
- Try to avoid waiting for responses to remote-service requests as much as possible.
##### Example 
When a service has been requested at a remote machine, an alternative to waiting for a reply from the server is to do other useful work at the requesterâ€™s side. 
- Essentially, this means constructing the requesting application in such a way that it uses only **asynchronous** communication. 
- When a reply comes in, the application is interrupted and a special handler is called to complete the previously issued request. 
Asynchronous communication can often be used in batch-processing systems and parallel applications in which independent tasks can be scheduled for execution while another task is waiting for communication to complete. 

Alternatively, a new thread of control can be started to perform the request. 
- Although it blocks waiting for the reply, other threads in the process can continue.
##### Applications that cannot use asynchronous communication to hide communication latencies
However, there are many applications that cannot make effective use of asynchronous communication. 

For example, in interactive applications when a user sends a request he will generally have nothing better to do than to wait for the answer. 
- In such cases, a much better solution is to reduce the overall communication, for example, by moving part of the computation that is normally done at the server to the client process requesting the service. 
- A typical case where this approach works is accessing databases using forms. 
- Filling in forms can be done by sending a separate message for each field and waiting for an acknowledgment from the server. 
- For example, the server may check for syntactic errors before accepting an entry.

A much better solution is to ship the code for filling in the form, and possibly checking the entries, to the client, and have the client return a completed form. 
 - This approach of shipping code is widely supported by the Web by means of Java applets and Javascript.

The difference between letting:
	a) a server or
	b) a client check forms as they are being filled
#### Partitioning and Distribution (Domain Name Lookup & Addressing)
Involves taking a component, splitting it into smaller parts, and subsequently spreading those parts across the system.
- A good example of partitioning and distribution is the Internet Domain Name System (DNS). The DNS name space is hierarchically organized into a tree of domains, which are divided into nonoverlapping zones, as shown for the original DNS. 
	- The names in each zone are handled by a single name server. One can think of each path name being the name of a host in the Internet, and is thus associated with a network address of that host. 
	- Basically, resolving a name means returning the network address of the associated host.
- Consider, for example, the name `flits.cs.vu.nl`. 
	- To resolve this name, it is first passed to the server of zone Z1 which returns the address of the server for zone Z2, to which the rest of name, `flits.cs.vu`, can be handed. 
	- The server for Z2 will return the address of the server for zone Z3, which is capable of handling the last part of the name and will return the address of the associated host.
- This example illustrates how the naming service, given by DNS, is distributed across several machines, thus avoiding that a single server has to deal with all requests for name resolution. 

As another example, consider the World Wide Web. 
- To most users, the Web appears to be an enormous document-based information system in which each document has its own unique name in the form of a URL. 
- Conceptually, it may even appear as if there is only a single server. However, the Web is physically partitioned and distributed across a few hundred million servers, each handling a number of Web documents. 
	- The name of the server handling a document is encoded into that documentâ€™s URL. 
	- It is only because of this distribution of documents that the Web has been capable of scaling to its current size.
---
- Name table for machines on the Internet was originally a single master file, held on one server
- Centralised approach works for a network consisting of a few hundred machines 
	Does not scale well
- Domain Name System (DNS) partitions name table between servers distributed across the Internet, administered locally
- Hierarchical nature of DNS means that name lookup does not take twice as long when number of machines on the Internet doubles
#### Replication
- Replicate components across a DS
	- Increases availability
	- Helps balance the load between components
	- Can hide communication latency problems
- Drawback
	- Having multiple copies (cached or replicated), leads to inconsistencies: modifying one copy makes that copy different from the rest.
	- Always keeping copies consistent and in a general way requires global synchronisation on each modification.
	- Global synchronisation precludes large-scale solutions.
#### Caching 
A special form of replication, although the distinction between the two is often hard to make or even artificial. As in the case of replication, caching results in making a copy of a resource, generally in the proximity of the client accessing that resource. However, in contrast to replication, caching is a decision made by the client of a resource and not by the owner of a resource. 
There is one serious drawback to caching and replication that may ad- versely affect scalability. Because we now have multiple copies of a resource, modifying one copy makes that copy different from the others. Consequently, caching and replication leads to consistency problems.

To what extent inconsistencies can be tolerated depends highly on the usage of a resource. For example, many Web users find it acceptable that
their browser returns a cached document of which the validity has not been checked for the last few minutes. However, there are also many cases in which strong consistency guarantees need to be met, such as in the case of electronic
stock exchanges and auctions. The problem with strong consistency is that an update must be immediately propagated to all other copies. Moreover, if two updates happen concurrently, it is often also required that updates are processed in the same order everywhere, introducing an additional global ordering problem. To further aggravate problems, combining consistency with other desirable properties such as availability may simply be impossible, as we discuss in Chapter 8. Replication therefore often requires some global synchronization mecha- nism. Unfortunately, such mechanisms are extremely hard or even impossible to implement in a scalable way, if alone because network latencies have a nat- ural lower bound. Consequently, scaling by replication may introduce other, inherently nonscalable solutions.
#### Developing Distributed Systems: Pitfalls
Many distributed systems are needlessly complex caused by mistakes that required patching later
Many false assumptions are often made:
1. The network is reliable
2. The network is secure
3. The network is homogeneous
4. Topology doesn't change
5. Latency is zero
6. Bandwidth is infinite
7. Transport cost is zero
8. There is one administrator

Question: Is there a 9th fallacy?
