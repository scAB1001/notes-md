Wednesday 08/10/2025

---
### Objectives
To explore key issues relating to vulnerabilities:
- How are they discovered, categorised, published?
- How do we find them in existing code?
- How do we best avoid introducing them in the first place?
#### The Vulnerability Cycle  
![[the-vulnerability-cycle.png]]

**Standardisation**  
- ISO 29147 provides guidelines for vendors on receiving  vulnerability reports from external researchers and disclosing remediation information  
- ISO 30111 describes a standard for processes that vendors  can follow between receipt of a report and disclosure 

**Aids to Discussion/Analysis**  
- Common Vulnerabilities & Exposures (CVE)  
- CVE identifier scheme allows vulnerabilities to be uniquely numbered, simplifying tracking  
- Common Weakness Enumeration (CWE)  
	- Standard for classifying vulnerabilities by type  
	- Example: CWE-120 = ‘Buffer copy without checking size of input’ (classic buffer overrun)  
- Scoring systems  
	- Useful for prioritising vulnerabilities  
	- Competing standards: CVSS and CWSS

**Dissemination**  
- US-CERT  https://www.cisa.gov/uscert/  
- UK’s National Cyber Security Centre  https://www.ncsc.gov.uk  
- @CVEnew on Twitter  
- OS and application vendors  (ideally with accompanying patches!)  
#### Questions    
- How do we find vulnerabilities in existing code?  
- How do we minimise the risk of them being introduced into our software in the first place?
### **Source Code QA Techniques**  
- Code review  
- Checklists  
- Static analysis tools  
#### **Code Review**  
- Exploits the ‘Hawthorne Effect’  
- Various approaches  
	- Peer review  
	- Pair programming (in XP)  
- External review  
	- Independent reviewers are more objective  
	- Reviews can be tied to commits/pushes  
- VC tools can help – e.g., by highlighting diffs  

**The ‘Many Eyeballs’ Fallacy**  
- Lack of convincing evidence for this  
- Research shows that bug finding rates in Open Source  SW (OSS) do not scale linearly with number of  reviewers 
- Security caveat: you need the ‘right kind of eyeballs’ to uncover security-related bugs!

**Linus’ Law**  
“Given enough eyeballs, all bugs are shallow” (Eric Raymond, The Cathedral And The Bazaar, 1999)
#### Checklists
- Help to ensure proper consideration of security issues during programming or a code review
	- Also useful during design and security testing
- Can be signed off formally
- Cannot address every security issue
- Need to be maintained to remain useful
	- Put them under version control!

Static Analysis Tools
- Pattern matching / lexical analysis
	- [Flawfinder](https://www.dwheeler.com/flawfinder/) (C, C++)
	- [RATS](https://www.dwheeler.com/flawfinder/) (C, Perl, PHP, Python, Ruby, OpenSSL)
- Parsing / data flow analysis
	- [Splint](https://splint.org/) – ‘Secure Programming Lint’ (C only)
	- [FindSecBugs](https://find-sec-bugs.github.io/) – plug-in for [SpotBugs](https://spotbugs.github.io/) (Java only)
	- Meta’s [Pysa](https://engineering.fb.com/2020/08/07/security/pysa/) (Python only)
- Logical reasoning about program memory usage
	- Meta’s [Infer](https://fbinfer.com) (C, Objective-C, Java)
#### Examples
```cpp
#include <stdio.h>
#include <string.h>
int main(int argc, char* argv[])
{
	char buf[256];
	if (argc > 1) {
		strcpy(buf, argv[1]);
		printf(buf);
		printf("\n");
	}
	return 0;
}
```
What might a static analysis tool warn you about here?
```cpp
if (access(file, W_OK) == 0) {
	...
	fp = fopen(file, "wb+");
	writeToFile(fp);
}
```
```cpp
#include <iostream>
#include <cstdlib>
int main()
{
	for (int i = 0; i < 10; ++i) {
		std::cout << random() << '\n';
	}
	return 0;
}
```
**‘Time Of Check, Time Of Use’ (ToC ToU) vulnerability**
In the 2023 Pwn2Own competition in Vancouver, a team of hackers were able to compromise the gateway in an updated Tesla Model 3 using this bug.
Limitations of Static Analysis
- False positives reported
	- Danger of ‘flaw fatigue’
- False negatives
- Flaw database must be maintained
- Source code required

**Testing != Security Testing**
![[testing-ne-security-testing.png]]

**Whittaker’s Fault Model**
![[whittaker-fault-model.png]]

**Run-time** **Fault** **Injection**
- Can simulate faults using software that intercepts and modifies system calls
- Example: Holodeck (Windows systems)
	- System monitoring
	- Fault injection
- Insufficient memory, failure to lock memory
- No disk space, too many open files, no disk in drive
- Low bandwidth, network disconnected, no ports, missing libraries...

Testing Using Whittaker’s Model
● Attack environmental dependencies
○ Block access to libs; manipulate Windows registry;
corrupt config files; simulate lack of memory, disk, etc
● Attack user interfaces
○ Overrun buffers; use escape characters; inject code
● Attack the design
○ Find unprotected accounts; connect to all ports; fake
sources of data; explore alternate routes to functionality
● Attack the implementation
○ Exploit TOC-TOU; force all errors; uncover test APIs;
screen temporary files for sensitive information

Using Threat Models
● Threat model drives the testing process
● Each threat needs a test plan
● STRIDE tells us what types of test to perform
● Quantitative risk assessment (e.g., DREAD rating) can
be used to prioritise test plans 