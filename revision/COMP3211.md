# Structure
### Course Outline
#### Part 1
- Architectures
- Middleware
- Distributed object technology, communication
- Service Oriented Architectures and Web services (REST)
- Microservices and nanoservices
- Serverless architectures
#### Part 2
- Supporting services: naming, directory and discovery services, synchronisation, consistency, replication, fault- tolerance
#### Part 3
- Cloud computing, Virtualisation, Edge computing
## Part 1
### 1. Introduction to Distributed Systems Pt.1 - *Chapter 1*
- Definition of a DS
- Goals and challenges
- Sharing of resources
- Transparency
- Openness
- Scalability
### 2. Introduction to Distributed Systems Pt.2 - *Chapter 1* 
- Types of distributed systems
1. High performance distributed computing systems
2. Distributed information systems
3. Distributed systems for pervasive computing
- *Homework*: What is Google spanner? 
	- What consistency properties does it have?
	- How does it handle ACID transactions?
### 3.  Architectures - *Chapter 2*
- Understand the different ways on how to view the organisation of a distributed system
- Architectural styles
	- Layered
	- Object-based
	- Resource-centred
	- Event-based
- System architecture
	- Centralised
	- Decentralised
	- Hybrid
### 4. Communication - *Chapter 4*
- Foundations
	- Latency and Bandwidth
	- Layered Protocols
	- Types of communication
		- Synchronous vs asynchronous
		- Transience vs persistence
- Remote Procedure Call
- Message Oriented Middleware
	- Message oriented communication
	- Message Passing Interface
	- Message Queuing Model
### 5. Service Oriented Architectures
- Conceptual Design of Software Systems
- Architectures
	- 1-Tier
	- 2-Tier
	- 3-Tier
	- N-Tier
- Emergence of SOAs
- Vision
- Characteristics
### 6. Web Services and REST
- Why do we need Web services?
- What are web services?
- What is REST?
- What does it consist of?
- Claimed benefits
- HTTP
### 7. Programming RESTful Web Services
- REST: Quick Recap
- REST APIs: Examples
- Reference implementations:
	- Python (Flask Restful)
	- Java (Jersey)
- Data encoding and RPC
### 8. Microservices, Nanoservices and Serverless
- Recap: SOAs
- Microservices
- Nanoservices
- Serverless Computing
- Function as a Service
- Architectural Support
- Solutions
## Part 2
### 9. Naming Pt.1 - *Chapter 5*
- Fundamental concepts
- Classes of naming systems
- Namespaces
- Naming graphs
### 10. Naming Pt.2 - *Chapter 5*
- Structured naming
	- Namespaces
	- Name resolution
	- Implementation of a namespace
- Attribute-based naming
- Directory Services
### 11. Timing and Synchronisation - *Chapter 6*
- Synchronisation in a DS
- Internal and external physical clocks
- Clock synchronisation algorithms
- Election Algorithm
- Network time protocol (NTP)
### 12. Consistency and Replication Pt.1 - *Chapter 7*
- Data-centric consistency models
### 13. Consistency and Replication Pt.1 - *Chapter 7*
- Client-centric consistency models
- Replica management
- Consistency protocols
### 14. Fault Tolerance - *Chapter 8*
- Dependability, reliability and availability in a DS
- Terminology
- Failure models
- Process resilience
- Consensus with crash failures
- Consensus with arbitrary failures
- The Byzantine Generals Problem
- *Homework*: The Paxos consensus algorithm is a protocol used in distributed systems to allow a group of computers to agree on a single value despite failures. How does Paxos compare to Raft?
## Part 3
### 15. Cloud Computing
- Technology Landscape
- Towards a Definition of Cloud Computing
- Virtualised infrastructures
- Conceptual Cloud Architecture
- Taxonomy of cloud Models
- Virtual Infrastructure Managers
- Cloud services
- Types of Clouds
### 16. Distributed Systems Topics and Trends Pt.1
- IoT: the Internet of Things
- Edge Computing
- Revisiting the Cloud Computing Stack
- Vision for a (near) future
### 17. Distributed Systems Topics and Trends Pt.2
- Module themes
- Evolution of distributed computing
- Most Active Topics in Distributed Systems-
# Content 
## 1. Introduction to Distributed Systems Pt.1 - *Chapter 1*
### Definition of a DS
> (1) A collection of *autonomous computing elements* (nodes) that appears to its *users* as a *single coherent system*.

NODES: Hardware devices and software processes (e.g. computer, car, robot) that need to collaborate. An AUTONOMOUS node has its own *notion of time* as every node has its own clock. 
There is no GLOBAL clock which is needed for synchronisation.
An autonomous node also needs to communicate to other nodes, providing network support.

> (2) A system in which components located at *networked* computers *communicate* and coordinate their actions only by *passing messages*.

The collection of nodes as a whole operates the same –no matter *where, when or how* the interaction takes places between the user and that system.
For example: 
- An end-user cannot tell where the computation is taking place
- Where data is stored exactly should be irrelevant to an application
- Whether or not data has been replicated is completely unknown/hidden. (Distribution transparency)
#### Examples of Distributed Systems
- The internet, The World Wide Web, A cellular mobile phone network
- The cloud
Applications built on top of DS are called Distributed Applications (DA): Netflix, Spotify, Instagram.
“You know you have a DS when the crash of a computer you’ve never heard of stops you from getting any work done” – Leslie Lamport
#### Distributed versus Decentralised Systems
There are two views of DS:
1. INTEGRATIVE view: connecting existing networked computer systems into a larger a system.
2. EXPANSIVE view: an existing networked computer system is extended with additional computers
![[centralised-decentralised-distributed-system.png]]
> A DISTRIBUTED system is a networked computer system in which processes and resources are **sufficiently** spread across multiple computers. (expansive view).

> A DECENTRALISED system is a networked computer system in which processes and resources are **necessarily** spread across multiple computers. (integrative view)

Here, data is normally brought to the high-performance computers that literally train models before they can be used. But when data needs to stay within the perimeter of an organisation (e.g. security reasons), training is brought to the data. The result is known as **federated learning**.
#### Examples of Decentralised and Distributed Systems
1. **Blockchain (distributed ledger)  decentralised system**
A distributed ledger, blockchain: we need to deal with the situation that participating parties do not trust each other enough to set up simple schemes for collaboration. 
	Instead, what they do is essentially make the transactions among each other fully public (and
 verifiable) by an extend-only ledger that keeps records of those transactions. The ledger itself is fully spread across the participants, and the participants are the ones who validate transactions (of others) before admitting them to the ledger. 
	The result is a decentralised system in which processes and resources are, indeed,
necessarily spread across multiple computers, in this case due to lack of trust.
2. **Geographically dispersed  decentralised system**
Consider systems that are naturally geographically dispersed. This occurs typically with systems in which an actual location needs to be monitored, for example, in the case of a power plant, a building, a specific natural environment, and so on. 
	The system, controlling the monitors and where decisions are made, may easily be placed
somewhere else than the location being monitored. 
	One obvious example is monitoring and controlling of satellites, but also more mundane 
situations as monitoring and controlling traffic, trains, etc. Here, the necessity for spreading processes and resources comes from a spatial argument.
3. **Content Delivery Networks (CDNs) DS**
The content of an actual Website, is copied and spread across various servers of the CDN. 
	When visiting a Website, the user is transparently redirected to a nearby server that holds all
or part of the content of that Website. A server is selected for which good performance in terms of latency and bandwidth can be guaranteed. 
	The CDN dynamically ensures that the selected server will have the required content readily 
available, as well as update that content when needed, or remove it from the server when there are no or very few users to service there. 
	Meanwhile, the user knows nothing about what is going on behind the scenes (which, again, 
is a form of distribution transparency). We also see that content is not copied to all servers, yet only to where it makes sense, that is, *sufficiently*, and for reasons of performance. CDNs also copy content to multiple servers to provide high levels of dependability.
4. **Network-Attached Storage (NAS) DS**
Consider a domestic-use setup based on a NAS, a typical NAS consists of 2–4 slots for internal hard disks. 
	The NAS operates as a file server: it is accessible through a (generally wireless) network for
any authorised device, and can offer services like shared storage, automated backups, streaming media, etc. 
	The NAS itself can best be seen as a single computer optimised for storing files, and offering 
the ability to easily share those files. The latter is important, and together with multiple users, we essentially have a setup of a distributed system. 
	The users will be working with a set of files that are locally (i.e., from their laptop) easily 
accessible (in fact, seemingly integrated into the local file system), while also directly accessible by and for other users. 
	Again, where and how the shared files are stored is hidden (i.e., the distribution is 
transparent). If file sharing is the goal, then we see that a NAS can provide *sufficient* spreading of processes and resources.
### Goals and challenges
A DS aims for: 1. Sharing of resources, 2. Distribution Transparency, 3. Openness, 4. Scalability,
A DS has many challenges:
• Architecture: common organisations, common styles
• Process: what kind of processes, and their relationships
• Communication: facilities for exchanging data
• Coordination: application-independent algorithms
• Naming: how do you identify resources?
• Consistency and replication: performance requires of data, which need to be the same
• Fault tolerance: keep running in the presence of partial failures
• Security: ensure authorised access to resources
### Sharing of resources
**Examples**: File sharing on P2P, shared web hosting, shared cloud-based storage
There are many reasons for wanting to share resources; its economically cheaper to have a single high-end reliable storage facility than having to buy and maintain storage for each user separately.
	Connecting users and resources also makes it easier to collaborate and exchange 
information, as is illustrated by the Internet with its simple protocols for exchanging files, mail, documents, audio, and video. 
	The connectivity of the Internet has allowed geographically widely dispersed groups of 
people to work together by all kinds of groupware, that is, software for collaborative editing, teleconferencing, and so on, as is illustrated by multinational software-development companies that have outsourced much of their code production to Asia.
### Transparency
> The phenomenon by which a DS attempts to *hide* the fact that its processes and resources are *physically distributed* across *multiple computers*, possibly separated by large distances.
	
This is handled through many different techniques in the MIDDLEWARE layer that sits between applications and OSs. E.g. Limited transparency: network services like sockets are directly visible to app dev.

Aiming for distribution transparency may be a nice goal when designing and implementing a DS, but that it should be considered together with other issues such as performance and comprehensibility. The price for achieving full transparency may be surprisingly high.
#### Middleware
![[middleware-layer-ex.png]]
Its the glue *between* apps and OSs, extending over multiple machines; contains commonly used components and functions that need not be implemented by applications separately.
The aim of the middleware is to hide heterogeneity of the underlying platforms from applications.
#### Types of Transparency
| Transparency  | Description                                                           |
| ------------- | --------------------------------------------------------------------- |
| _Access_      | Hide differences in data representation and how an object is accessed |
| _Location_    | Hide where an object is physically located in the system              |
| _Migration_   | Hide that an object may move to another location                      |
| _Relocation_  | Hide that an object may be moved to another location while in use     |
| _Replication_ | Hide that an object is replicated                                     |
| _Concurrency_ | Hide that an object may be shared by several competitive users        |
| _Failure_     | Hide the failure and recovery of an object                            |
### Openness
> An OPEN DS offers components that can easily be used by, or integrated into other systems. An open DS itself will often consist of components that originate from elsewhere.

![[middleware-openness-ex.png]]
They *share* the same *interface* and *communicate* with the same *common protocol* to be able to *interact with services from other open systems*, irrespective of the underlying environment.

Systems should conform to well-defined *interfaces*, easily *interoperate*, support *portability* of applications and be easily *extensible*.
### Scalability
A DS can be scaled in size, geographically or administratively if it remains effective after scaling.
#### Scale in Size (number of users and/or processes)
Scalability for the internet was effortless because information is organised hierarchically rather than linearly: $O(\log(n))$. Poor scalability is when the cost of supporting $n$ users is worse than $O(n)$.
#### Scale Geographically (maximum distance between nodes)
1. Difficult to scale existing DSs that were designed for LANs because they are based on *synchronous communication*.
In this form of communication, a party requesting service (client), blocks until a reply is sent back from the server implementing the service e.g., a database transaction. 
Communication between two machines in a LAN: ~few hundred microseconds()
	- However, in WANs, the *interprocess communication* may be hundreds of milliseconds, three orders of magnitude ($10^3$) slower; this is a LATENCY problem.
2. Communication in WANs is inherently much less reliable than in LANs. 
- In addition, we also need to deal with limited bandwidth. 
- The effect is that solutions developed for local-area networks cannot always be easily ported to a wide-area system. 
- A typical example is streaming video. In a home network, even when having only wireless links, ensuring a stable, fast stream of high-quality video frames from a media server to a display is quite simple. Simply placing that same server far away and using a standard TCP connection to the display will surely fail: bandwidth limitations will instantly surface, but also maintaining the same level of reliability can easily cause headaches.

Yet another issue that pops up when components lie far apart is the fact that wide-area systems generally have only very limited facilities for multipoint communication. 
- In contrast, local-area networks often support efficient broadcasting mechanisms. Such mechanisms have proven to be extremely useful for discovering components and services, which is essential from a management point of view. 
- In wide-area systems, we need to develop separate services, such as naming and directory services to which queries can be sent. 
- These support services, in turn, need to be scalable as well and in many cases no obvious solutions exist (as we will encounter in later chapters).
#### Scale Administratively
Scale the number of administrative domains, e.g. Google data centres worldwide

DS can be scaled in size if it remains effective after a significant increase in the number of users/resources
- Example: Internet
- Poor scalability if cost of supporting n users is worse than O(n)
- Scalability improves if 