# 01. Intro
## Security Goals & Properties
- Data confidentiality
- Data integrity: No modification, insertion, deletion or replay
- High availability: Amazon systems aer available 99.9% of the year
- Authenticity: Data sources and system users
- Access control
- Trustworthy system logs
## Attackers follow the M.O.M. acronym 
**Method**: They have the skills and tools to attack the systems and potentially have information about it.
**Opportunity**: They have a time/chance and the acces to carry out this attack e.g., systems can be accessed remotely.
**Motive**: They have a reason to attack e.g., Financial or Political.
### Assets and Adversaries 
To identify assets, you must analyse the system and the user themselves e.g., A photo of a celebrity is considered an asset, whereas a photo of a non-famous person might not be. Likewise, user data is considered an asset as it's exposure can lead to financial gain.

An adversary is the perpetrator with their eyes on the asset.
### Vulnerabilities
For attacks to be possible there must be vulnerabilities. These occur when system specifications or conditions are loosely defined e.g., buffer overflows (unspecified buffer size) and SQL Injection attacks.
### Threats
A threat is a set of circumstances that has the *potential* to cause *harm or loss*.
### Problem
A problem exists when there is both a threat and a vulnerability.
If the vulnerability can be controlled the then threat can be contained e.g., a *vulnerability* of unprotected data can be *mitigated* via the enabling of access control.
## Threats and Controls
Four main types of threats:
1. Interception: Gaining access to an asset.
2. Interruption: Preventing access to an asset.
3. Modification: Tampering of an asset.
4. Fabrication: Addition of nonexistent items.

Four main types of controls:
1. Prevention: Remove all vulnerabilities.
2. Deferral: Deal with the vulenrability.
3. Deflection: Change the nature of the asset e.g., data may be moved from on-site to cloud.
4. Detection: Controls to observe the attacks.
5. Recovery: Moving on from attacks.
## Why is security hard
- Humans make mistakes (**PEBKAC**: Problem Exists Between Keyboard and Chair)
- Assumptions are made incorrectly
- It is not easily quantified and there is no scoring system or real measure of secure.
- Emergent system properties are unpredictable.
## Hackers
- Originally defined as someone who enjoys understanding and tinkering with software or hardware.
- Different types:
	- White Hat: Uses skills ethically.
	- Black Hat: Uses skills unethically.
# 01. Threat Modelling pt. 1
Threat modelling is the *process* of *identifying* the *possible threats* to a system. 
It allows us to understand the capabilities of attackers and their threats which will endanger the security policies in place. This approach is cost-effective as it avoids mistakes/future threats that are alike.
##### Bellovin’s Threat Matrix → ![[bellovin-threat-matrix.png]]
#### Advanced Persistent Threats
- Highly skilled attackers
- Targeted and prolonged cyber-attack campaigns
- Complex, multidimensional attacks, often tightly focused and very difficult to deflect (e.g., **Stuxnet**)
- ‘Cyber-warfare’ involving ‘state actors’ (e.g., national intelligence agencies)
### Security Engineering
The design process for security follows threat modelling, security requirement building and security mechanism development.
The thread model allows security designers to estimate the stregnth of the attacker.
## Main steps for threat Modelling
### 1. System Characterisation 
Characterise the system into main modules to see the system's data flow.
To understand the system components and their interconnections, define:
- Usage scenarios
- Assumptions
- Dependencies

and model:
- Data flow diagrams
- The Network
- State machines
- At varying granularity e.g. APIs, classes or methods.
### 2. Asset and Access Point Identification 
Identify assets and access points to understand how a user would access the system.
- What are we trying to protect?
- How can we reach the system and asset?
### 3. Threat Identification 
Identify any threats. Threats to different components will differ.
Assets can be reached via access points through components and their interaconnections.
Develop a threat profile for each threat (classified as high or low risk).
#### Threat Enumeration
Threats can come from both outside and in.
For each asset, attack goals need to be made for the asset.
The adversary type can be discovered by correlating threats to assets.
#### Attack Trees
A conceptual tree structure used to show how an asset can be attacked (the root node).
Each node represents a condition/predicate/action. E.g., Pick lock (*Impossible*), Learn combination (*Possible*)->Get from staff->Blackmail, Learn combination (*P*)->Get from staff->Bribe.
## The STRIDE Threat Model Classification
Acting as a useful checklist of threats and their effects. It also assigns priority to threats
Six impact-based threat classifications:
### 1. Spoofing - masquerade e.g., unauthorised access.
E.g., email spoofing: fake sender address appears to come from a trusted source.
Website spoofing: fraudulent site masquerades as legitimate to steal credentials.
### 2. Tampering - violates data integrity.
E.g., Hacker disabling anti-virus on a machine.
**Man in the Middle Attack**: intercepts/alters communication between two parties.
### 3. Repudiation - Deny performing action.
E.g., user denies making an online transaction and the system lacks sufficient evidence, like a digital signature, to prove otherwise. This is the reason log files exist. Common in E-commerce.
### 4. Info disclosure - violate confidentiality.
E.g., Servers revealing directory structures, detailed messages exposing software/protocol versions.
### 5. Denial of Service
E.g., Mirai botnet: Consisted of large number of IoT devices such as IP cameras.
Instructed to send a large number of traffic to Dyn (DNS provider) servers. Prevent the system from providing the designated service.
### 6. Elevation of privilege - Gaining special status.
E.g., Flaw in OS (buffer overflow). Ultimately, get admin privileges.

We think of threats and attack in the terms of these classifications as well as terms of breaches of confidentiality, integrity or availability.
E.g., Data in transit from A to B, can be *tampered* with, violating *integrity*. 
To mitigate this, can we use a Secure Hashing Algorithm?
### STRIDE Per Element
Certain threats are more prevalent than others and should be focused.
## Specifying Security Requirements
These threats are translated into requirements and prioritsed (cannot handle all of them).
E.g., 
	**THREAT**: DoS attack on system
	**HOW**: Flood Network Interface or Disk Space
	**RISK**: High
	**REQUIREMENT**: DoS should not be allowed.
	**MECHANISMS**: Use firewall to drop certain packets and restrict resources used by anonymous users.
# 02. Threat Modelling pt. 2
## STRIDE Model Goals
Threat modelling can be considered from three different perspectives:
### 1. Assets
The valuables.
Tangible things which obvious for attackers e.g., user credentials, bank details.
Intangible things which need to be protected e.g., reputation, system availability.
### 2. Attackers
Consider human threat agents. Lacks structural detail to help identify an attacker's methodology.
Prrone to bias when creating an potential attacker list.
### 3. Software
Using scenario-based/user story problems to explore potential problems.
Can be highly structured by creating and using systems diagrams, making STRIDE calssifications and attack trees.
Software-focused approach is considered to be the best.
## Trust Boundaries
- These emerge when entities, with different levels of access, interact.
- TBs are drawn around user accounts, physical computers, VMs, Network segments, etc.
- They can be identified by:
	- Identify the *principals* (users)
	- Following the privelege spectrum of access e.g., User vs. Admin.
	- A new TB is added every time a principal talks to another
### Entry & Exit Points
- Places where control or data *cross* a *trust boundary*.
- Easy to overlook infrastructure entry points e.g., Config files, Windows registry, etc.
- Entry points can be layered.
### Importance
TBs delineate the attack surface between principals. 
Threats tend to cluster around the entry/exit points on TBs and can follow data flows.
So, diagramming mainly helps us to learn, in a systematic way, **where** we should look for threats.
## Attack Trees
- Root node, representing a threat
- Child nodes represent a condition that must be true for attack to succeed
- Arcs between parent and child nodes
- Path from a leaf node to root is an attack path
	- Dashed line can be used to indicate low likelihood
- Boolean relationships between siblings
	- OR is *implicit*
	- AND must be shown *explicitly*
##### Attack Tree Example ->
![[attack-tree-ex.png]]
### ### Risk Assessment: DREAD
For each threat, estimate
- **Damage** **potential**.
- **Reproducibility** (how often an attempt at exploiting a vulnerability actually works)
- **Exploitability** (effort required to exploit vulnerability).
- **Affected** **users** (proportion of install base that would be affected if an exploit became widely available).
- **Discoverability** (likelihood that a vulnerability will be found by external security researchers or black hats).
- (Use a 1–3 or 1–5 scale for each, compute *R* as a simple average)
#### Issues With DREAD as a scoring system
- Values are highly subjective
- Not all dimensions are useful – e.g., why assume that Discoverability is anything other than 100%?
- Dimensions are weighted equally but might not be considered equally.
### Common Vulnerability Scoring System (CVSS)
- Open standard: v2 and v3 in current use
- Scoring is more thorough and objective than **DREAD**
	- Uses a 0.0 – 10.0 scale
	- Provides a base score for severity, optionally modified to reflect risks in a specific environment
### Mitigation
Ideally, every threat is mitigated either by design or implementation of the system.
- Corollary: every security feature should address at least one threat from the threat model!
- Rank unmitigated threats by risk and prioritise.
![[attack-tree-paths-ex.png]]There are **four** attack paths because 1.1 and 1.2 must both be true.
1. 1.1 AND 1.2.1
2. 1.1 AND 1.2.2
3. 1.3.1
4. 1.3.2
How can we mitigate a specific condition e.g. 1.3.1. We now have three ways of attacking the system now instead of 4.
*Which condition should be mitigated first to best reduce the number of attack paths?*
**1.1** ! Because it means that we now have two attack paths.
# 03. Managing Vulnerabilities
## Exploits
Attacks that leverage a vulnerability are called *exploits* but not all vulnerabilities turn into realistic exploits.

Developers know that there will be vulnerabilities and potential exploits. After internal checks, the turn to the goodwill of the public to report on anything new, offering rewards as an incentive. It is essentially an arms race between security researchers and attackers. 
### Responsible Disclosure
Those with goodwill practise *responsible disclosure*, whereby they *inform* the software *vendor* of their find, receive their award and agree to *stay silence* for a given time.
A *Bug Bounty Program* is a structured environment where researchers investigated vulnerabilities.
### 0Day Attacks
Those who are more morally questionable, use the vulnerability to attack the system. *Exploits* that are *actively* in use *before* any responsible disclosure has taken place are called *0day attacks*.
## The Vulnerability Cycle
![[the-vulnerability-cycle.png]]
1. Vulnerability discovered and disclosed
2. Vulnerability used in an attack becoes an exploit and the search for fix begins.
3. The exploit has caught the attention of the media, bad publicity ensues.
4. Immediate diagnosis of the issue, search through logs, the patch begins development.
5. Discovery of similar vulnerability in related code.
6. If the attacker finds these first before they are patched, go to 2. Else, a tool is used to identify the exploit on unpatched systems and the cycle repeats.
### Discussion/Analysis
- Common Vulnerabilities & Exposures (**CVE**)  
	- CVE identifier scheme allows vulnerabilities to be uniquely numbered
- Common Weakness Enumeration (**CWE**)  
	- Standard for classifying vulnerabilities by type  
	- Example: CWE-120 = ‘Buffer copy without checking size of input’ 
- Scoring systems  
	- Useful for prioritising vulnerabilities  
	- Competing standards: CVSS and CWSS
### QA Techniques
- Code review
	- Hawthorne Effect (if someone's watching, you perform better)
	- Peer review, pair programming (XP)
	- External independants reviewers tied to version control (VC)
- Checklists  
	- Ensure proper consideration of security issues
	- Must be maintained to remain useful
- Static analysis tools  
#### The ‘Many Eyeballs’ Fallacy  
- Bug finding rates in Open Source Software (OSS) do not scale linearly with number of  reviewers 
- Security caveat: you need the ‘right kind of eyeballs’ to uncover security-related bugs!
#### Static Analysis Tools
Often designed for C as the language is notorious for its exploits.
- Pattern matching / lexical analysis
	- [Flawfinder](https://www.dwheeler.com/flawfinder/) (C, C++)
	- [RATS](https://www.dwheeler.com/flawfinder/) (C, Perl, PHP, Python, Ruby, OpenSSL)
- Parsing / data flow analysis
	- [Splint](https://splint.org/) – ‘Secure Programming Lint’ (C only)
	- [FindSecBugs](https://find-sec-bugs.github.io/) – plug-in for [SpotBugs](https://spotbugs.github.io/) (Java only)
	- Meta’s [Pysa](https://engineering.fb.com/2020/08/07/security/pysa/) (Python only)
- Logical reasoning about program memory usage
	- Meta’s [Infer](https://fbinfer.com) (C, Objective-C, Java)
#### Limitations of Static Analysis
- False positives reported
	- Danger of ‘flaw fatigue’
- False negatives
- Flaw database must be maintained
- Source code required
##### Testing != Security Testing
![[testing-ne-security-testing.png]]
### Whittaker’s Fault Model
##### Diagram
![[whittaker-fault-model.png]]
#### Testing
When you are left final bugs, how can you prove that the piece of software is now secure?
- Attack environmental dependencies
	- Block access to libs; manipulate Windows registry; corrupt config files; simulate lack of memory, disk, etc.
- Attack user interfaces
	- Overrun buffers; use escape characters; inject code.
- Attack the design
	- Find unprotected accounts; connect to all ports; fake sources of data; explore alternate routes to functionality.
- Attack the implementation
	- Exploit TOC (Time of Compilation)-TOU (Time of Use); force all errors; uncover test APIs; screen temporary files for sensitive information.
#### Using Threat Models
- Threat model drives the testing process.
- Each threat needs a test plan (made with STRIDE, organised by DREAD).
- STRIDE tells us what types of test to perform.
- Quantitative risk assessment (e.g., DREAD rating) can be used to prioritise test plans .
#### ‘Secure From Day One’
- Security (re)training for team members
- Threat model starts at first stage, when product is in planning; refined thereafter.
- Design process is driven by threat model and adopts standard principles such as reluctance to trust, granting of minimal privilege, etc.
- Designs undergo security reviews.
- Code QA and testing as described earlier.
- ‘Security push’ in later stages.
- Full security audit before shipping.
### Run-time Fault Injection
Behaves as a stress-test the system in the wrong states. For the system into these states.
- Can simulate faults using software that intercepts and modifies system calls e.g., *Holodeck* (Windows)
- System monitoring
- Fault injection
	- Insufficient memory, failure to lock memory
	- No disk space, too many open files, no disk in drive
	- Low bandwidth, network disconnected, no ports, missing libraries...
# 04. Security Policy Models
The overall protection of the system is made up of the Policy, Middleware and Mechanisms. These work hand-in-hand as follows:
- **Policy**: The concise, formalised set of goals.
- **Mechanisms**: The basics components needed to satisfy the policy.
- **Middleware**: How the mechanisms are enforced to satisfy the policy
#### Example
Imagine we want to protect a system from unauthorised access.
The policy here would be to set up a entry point that verifies each person on entry.
The mechanism to achieve this could be a biometric fingerprint scanner.
The middleware would be a component that enables the function of the scanner.
## Security Policy
A security policy is a high-level specificaction of security properties a system should possess. These specifications clarify the security requiremets of the system.

A policy is a set of high-level documents that state precisely what goals the protection mechanism aim to achieve.
### Policy Language
The security policy can be expressed in different ways depending on the level of granularity needed.
High-level languages are used on the outset:
- Policy constraints expressed abstractly.
- Constraints expressed independent of enforcement mechanism.
- Constraints restrict entities and actions.
- Constraints expressed unambiguously.
- Requires a precise language, usually a mathematical, logical or programming-like language.

Low-level languages are used for precision:
- Low-level of abstraction.
- Policy constraints are expressed in terms of program options, input or specific system entity characteristics.
- Set of inputs or arguments to commands.
- Check or set constraints on a system.
- Need details of system, commands.
## Policy Models
A security model represents a particular policy or set of policies.

When defining your security policies, an existing model is often followed and used as a guideline. When building a house, you do not tend to start from scratch, instead, you follow a guide. This is because many of the problems that arise have been solved before and you would only re-design something in a unique situation.

There are several existing models and you need to pick the correct one e.g. *Bell-LaPadula*, *Biba*. You cant pick a bedroom model for the kitchen.
#### Access Control
Documents (objects) are classified according to labels.
### BELL-LaPADULA (BLP) Model
This is an example of multi-level security (*MLS*). 
#### Property: SImple Security
No process can read data at a higher level (*no read up*)

Subject *s* can read object *o*, $$iff \ \ L(o) \le L(s)$$ and *s* has permission to write *o* .
This also has the *no write down* star property. Thanks to mandatory access control, information can only flow upwards. Protects against trojans.
#### Formal BLP
Subjects/objects are assigned a security label comprising a classification level and category.
We represent this as a tuple: `security_label = (class, category level)`

There is a binary relation, D (Dominates) over this set of security labels.
D is a *partial order* i.e. it is reflexive, antisymmetric and transitive

For a relation to be *reflexive*, every element must be related to itself such that every a in a relation, (a,a) exists.
For a relation to be *antisymmetric*, every element must belong to the relation and each element (a,b) must have a (b,a).
For a relation to be *transitive*, elements (a,b,c) in a relation must connect such that a connects to b and b connects to say, giving the transitive property that a connects to c as well.

This partial order is important because it provides a higher privilege to those without any but does not clear those who share classification level, regardless of category.
#### Lattices
Given an appropriate set of security labels and the auxiliary functions:
- **join()**, which returns the Lowest Upper Bound (LUB)
- **meet()**, which returns Greatest Lower Bound (GLB)

This relation forms a lattice structure for data flow.
![[img-lattice-security-model.png]]
This is useful because it allows us to identify the minimum clearances need to allow data flow within a system.

**Given two labels, *(Secret, {Crypto, Foregin})* and *(Top Secret, {Crypto})*, get the LUB and GLB.**
GLB from meet() is *(Secret, {Crypto})* because that's where their two edges meet at the bottom.
LUB from join() is *(Top Secret, {Crypto, Foregin})* because their two edges meet at the top.

**What point can be removed from the set to no longer make this a lattice, i.e., not all pair of points have a LUB and GLB?**
If we remove *(Top Secret, {Crypto, Foregin})*, then there will not be a LUB  for the two labels connected.
#### Reference Monitor
Using these definitions and data flow structure, a predicate called "exec" can be defined.
It takes a Subject s, an Object o and an Action a as arguments, i.e., $$\bra s,o,a\ket \ \in exec$$
States that a Subject can perfrom an Action on the Object. The predicate will evaluate to a boolean value based on if the security requirements are met.
### BIBA Model
BLP enforces some Mandatory Access Control (MAC), whereas BIBA is deployed more to preserve integrity, i.e., BLP upside-down.
Confidentiality is about who can **read** data; integrity is about who can **write** it.
### Chinese Wall Model
A weakness of MAC is that we have no record of the history.
Designed to prevent conflicts of interest or insider dealings.
They define three levels of abstraction:
**Objects**: Contain information about only one company.
**Company Groups**: Collect all objects concering a particular company.
**Conflict Classes**: Cluster the groups of objects for competing companies e.g., {Shell, BP}. These are who you cannot work with multiple of.

The key is to keep track of state. To do this, a 2D matrix is kept e.g., The contamination of Object o by Subject s is either true or false e.g., C[s,o] = 1 if s has accessed o.
#### Property: SImple Security
Each subject can access objects from at most one company at any time. E.g. Subject s can only acess object o if s has never dealt with a company of type o (t(o)). If s servers multiple companies of the same type, then they are all the same company.
#### Star property
s can write to o if all other objects p, that s has written to, are the same type and object or p is a sanitised object.

*Sanitsation* is the process through which conflict is removed via a trusted party. You can only have one trusted party. Similar to anonymising data.
### Resurrecting Duckling Model
Not all models can be specified through permanent access control. Here, the security policy is transient. This is a kind of "on-the-go" temporary security.
E.g. To connect some speakers with bluetooth, you need to undergo authentication for them to have a transient connection and then restart (resurrect). Followed by a clean slate (duckling).

These states are imprintable and imprinted:
1. **imprantable**: ready to trust another system.
2. **imprinted**: committed to trust that system.

To transition between them:
- 1->2, send a secret key and trust the first system.
- 2->1, death via time out, reset or end of transaction.
### Other
- Capabilities of the 2D matrix.
- Access Control Lists (ACLs)
- Role Based Access.
# 05. Command Injecton and Input Validation
## Input Validation
Use prepared statements instead of filtering input data. Parameterised and reusable SQL queries are better for the developer.
### Tust Boundaries and Choke Points
![[choke-points-ex.png]]
Testing at choke points validates data throughout the structure flow.
### Phishing via Homograph Attacks
Letters used from different but seemingly identical alphabets can be used to hide false websites.
Malicious URLs often have null bytes between the user-readable part of the URL and the @ symbol.
### Malicious URLs e.g., Directory Traversal
Replacing the file dir of a dynamic page's GET req to retrieve the directory of the password file.
The solution is to use canonicalisation (aliases). User input is converted into canonical form before being used e.g.,```
File file = new File(BASE_DIR, userIn)
if ( file.getCanonicalPath().startsWith(BASE_DIR) )  { // Process file. }```
# 06. Web App Vulnerabilities
Web apps are often developed in high-level applications like Python or Java. Thanks to this, low-level vulnerabilities like buffer overflows are better protected. 
Due to the fact that web apps are accessible by absolutely anyone, the *attack surface* is very large. Again, input validation is often the 
