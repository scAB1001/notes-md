# Lecture 1: Introduction to Data Science
## Question 1 (20 marks)
# Lecture 2: Data Understanding & Profiling
# Lecture 3: Data Science Roadmap & Exploratory Data Analysis (EDA)
# Lecture 4: Machine Learning Overview
# Lecture 5: Clustering & Similarity
# Lecture 6: Classification, k-NN, & Decision Trees
# Lecture 7: Regression, Overfitting, and Random Forests
# Lecture 8: Model Evaluation
# Lecture 9: Dimensionality Reduction
# Lecture 10: Principal Component Analysis (PCA)
# Lecture 11: Ethics and Data Governance

# MCQ
Question 1
What is the purpose of a confusion matrix in classification problems?
a) To determine the importance of each feature in the model
b) To summarise regression model performance
c) To calculate the overall accuracy of the model
d) To visualise the performance of a classification model by showing true vs predicted classifications

Question 2
What is the main advantage of using ensemble methods in machine learning?
a) They are simpler to interpret
b) They require less data
c) They improve predictive performance by combining multiple models
d) They speed up the training process

Question 3
What is the principle benefit of using the k-fold cross-validation technique in model evaluation?
a) It guarantees that the model will have no bias
b) It helps to mitigate overfitting by providing a better assessment of model performance
c) It allows for the use of more complex models without any data
d) It reduces the size of the training dataset

Question 4
Which type of learning uses labelled datasets to make predictions?
a) Reinforcement learning
b) Semi-supervised learning
c) Unsupervised learning
d) Supervised learning

Question 5
What is the main purpose of performing feature scaling in data preprocessing?
a) To reduce the number of features
b) To ensure that all features contribute equally to the distance calculations
c) To increase the size of the dataset
d) To eliminate missing values

Question 6
Which evaluation metric is best suited for imbalanced classification problems?
a) Accuracy
b) Mean Squared Error
c) R-squared
d) F1 Score

Question 7
What does the term 'overfitting' refer to in machine learning?
a) When data is lost during the training process
b) When a model is too simple to capture the underlying patterns
c) When a model performs equally well on both training and test data
d) When a model learns the training data too well, including its noise and outliers

Question 8
What is the significance of outlier detection in data preprocessing?
a) To ensure all data points are equally represented
b) To enhance data visualisation capabilities
c) To reduce the dimensionality of the dataset
d) To identify and handle anomalies that can skew model performance

Question 9
What is the primary purpose of the 'train-test split' in model evaluation?
a) To optimise hyperparameters
b) To assess the performance of a model on unseen data
c) To reduce dimensionality
d) To improve training speed

Question 10
What is an important advantage of using random forests in machine learning?
a) They require fewer training samples to achieve high accuracy
b) They can only be used for classification tasks
c) They provide linear relationships between features and outcomes
d) They reduce overfitting compared to a single decision tree

Question 11
What is the role of feature engineering in machine learning?
a) To create new input features from existing data to improve model performance
b) To handle missing values in the dataset
c) To select the best machine learning algorithm
d) To optimise hyperparameters

Question 12
Which of the following statements about clustering algorithms is true?
a) They are used exclusively for time series analysis
b) They predict outcomes based on labelled data
c) They group similar data points together based on features
d) They require a predefined target variable

Question 13
Which of the following is a key characteristic of time series data?
a) It consists of random data points that are independent of each other
b) It can only be analysed using classification techniques
c) It is sequential and often dependent on time-related factors
d) It does not exhibit any trends or seasonality

Question 14
Which of the following Python libraries is primarily used for numerical calculations and data manipulation?
a) Beautiful Soup
b) NumPy
c) TensorFlow
d) Flask

Question 15
What does 'hyperparameter tuning' refer to in machine learning?
a) Adjusting the number of features
b) Selecting the training algorithm
c) Scaling the input data
d) The process of optimising the settings of a machine learning model

Question 16
Which of the following metrics is used to evaluate the performance of a regression model?
a) Mean Absolute Error (MAE)
b) F1 Score
c) Accuracy
d) Precision

Question 17
What does PCA stand for, and what is its primary purpose?
a) Probabilistic Classification Algorithm; classification
b) Partial Correlation Analysis; feature selection
c) Predictive Component Assessment; model evaluation
d) Principal Component Analysis; dimensionality reduction

Question 18
In machine learning, which of the following methods is typically used for classification tasks?
a) K-means Clustering
b) Linear Regression
c) Principal Component Analysis
d) Support Vector Machines

Question 19
Which algorithm is commonly used for unsupervised learning tasks?
a) k-Means clustering
b) Logistic Regression
c) Random Forest
d) Naive Bayes

Question 20
What does the term 'ensemble learning' refer to in machine learning?
a) Enhancing a single model's performance through hyperparameter tuning
b) Implementing unsupervised techniques to classify data
c) Combining multiple models to produce improved predictions
d) Using a hierarchical structure to manage data processing

Question 21
Which of the following is a common data visualisation tool used in Data Science?
a) Microsoft Word
b) Tableau
c) Notepad
d) Photoshop

Question 22
What is cross-validation primarily used for in building machine learning models?
a) To replace the need for a validation set
b) To increase the number of training examples
c) To assess how well the model generalises to an independent dataset
d) To refine the selection of hyperparameters only

Question 23
Which of the following techniques is used to improve the performance of a machine learning model by reducing complexity?
a) Feature scaling
b) Regularisation
c) Cross-validation
d) Hyperparameter tuning

Question 24
In the context of machine learning, what is 'bagging'?
a) A technique for performance improvement in unsupervised learning
b) A technique to reduce variance by training multiple models on random subsets
c) A method to increase bias by consolidating model predictions
d) An approach to feature selection

Question 25
In which situation would you use a decision tree algorithm?
a) For text analysis only
b) For classification or regression tasks where interpretability is important
c) For time-series forecasting
d) For images only

Question 26
In the context of clustering algorithms, what does the term 'centroid' refer to?
a) A random point selected from the dataset
b) The farthest point in the cluster
c) The central point of a cluster, calculated as the mean of all points in the cluster
d) The first point added to the cluster

Question 26
In the context of clustering algorithms, what does the term 'centroid' refer to?
a) A random point selected from the dataset
b) The farthest point in the cluster
c) The central point of a cluster, calculated as the mean of all points in the cluster
d) The first point added to the cluster

Question 27
In the context of data science, what is 'feature selection'?
a) The method of combining multiple features into one
b) The process of scaling features to the same range
c) The technique of generating new features from existing ones
d) The process of selecting a subset of relevant features for model training

Question 28
What is the main function of a loss function in machine learning?
a) To quantify how well the model's predictions match the actual outcomes
b) To track the number of model iterations
c) To optimise data preprocessing
d) To visualize model performance

Question 29
What is the primary goal of data normalisation in machine learning?
a) To eliminate missing values
b) To reduce the size of the dataset
c) To enhance the complexity of the features
d) To scale features to a similar range for effective training

Question 30
What is the purpose of data preprocessing in machine learning?
a) To clean and prepare data for analysis and model training
b) To select the best machine learning algorithm
c) To fine-tune hyperparameters
d) To analyse model performance

Question 31
Which measure is commonly used to assess the accuracy of a classification model?
a) Mean Squared Error
b) R-squared
c) Silhouette Score
d) F1 Score

Question 32
Which type of data visualisation is best for showing the distribution of a numerical variable?
a) Histogram
b) Bar chart
c) Scatter plot
d) Line chart

Question 33
What is the purpose of using a test set in machine learning?
a) To evaluate the model's performance on unseen data
b) To perform feature selection
c) To optimise hyperparameters
d) To train the model on the entire dataset

Question 34
What is the main purpose of using a validation set in machine learning?
a) To create a holdout set for future predictions
b) To train the model on all available data
c) To tune hyperparameters and avoid overfitting
d) To assess the model's performance after training

Question 35
In which scenario would you most likely use a recommender system?
a) To suggest products to users based on their preferences
b) To detect anomalies in transaction data
c) To predict future stock prices
d) To classify images into categories

Question 36
What is the purpose of applying one-hot encoding in data preprocessing?
a) To normalise numerical values
b) To reduce the dimensionality of data
c) To convert categorical variables into a numerical format
d) To remove duplicates in data

Question 37
In ensemble learning, what is the key idea behind 'boosting'?
a) To sequentially combine weak learners to create a strong learner
b) To combine models in parallel to reduce variance
c) To enhance models by adding noise to the training data
d) To train a single model with different initial conditions

Question 38
What is the purpose of regularisation in machine learning?
a) To improve the computation speed of the algorithm
b) To enhance the complexity of the model
c) To increase the number of features used
d) To prevent overfitting by adding a penalty for larger weights

Question 39
Which of the following is a common assumption made by linear regression techniques?
a) The data must be normally distributed
b) The input variables are categorical
c) The relationship between the input variables and the target is linear
d) The target variable is continuous only

Question 40
Which of the following scenarios would be best suited for unsupervised learning?
a) Predicting disease outcomes based on patient history
b) Grouping customers based on purchasing behaviour
c) Identifying spam emails
d) Forecasting stock prices

Question 41
Which Python library is widely used for data manipulation and analysis, offering data structures like DataFrame?
a) Pandas
b) Matplotlib
c) Scikit-learn
d) Seaborn

Question 42
What does 'dimensionality reduction' aim to accomplish in data analysis?
a) To reduce the number of features while preserving important information
b) To increase the number of features in the dataset
c) To eliminate all outliers completely
d) To change the data distribution

Question 43
What does 'recall' measure in the context of classification?
a) The ability of a model to find all relevant instances in a dataset
b) The capacity of the model to produce true negatives
c) The trade-off between precision and false positives
d) The overall accuracy of the model

Question 44
Which of the following scenarios is most suitable for a supervised learning approach?
a) Finding patterns in customer purchasing behaviour
b) Dimensionality reduction of high-dimensional data
c) Clustering similar documents together
d) Predicting house prices based on historical data

Question 45
Which technique can be used to evaluate the effectiveness of a machine learning model while preventing overfitting?
a) Cross-validation
b) Random forest
c) Grid search
d) Support vector machine

Question 46
Suppose you are developing a music streaming platform where artists can upload their music and listeners can stream the music collection uploaded on the platform. You can assume that a sound analysis algorithm extracts different features from each uploaded song such as tempo, sound level, pitch, and instrument, and there is a list of possible genres defined which are currently entered manually by the artists for each song. The system you will develop should be able to automatically predict the genre of a song when an artist uploads their music. What is the task described as predicting the genre of a song an example of? Select one correct answer.
a) Dimensionality Reduction
b) Regression
c) Classification
d) Clustering
e) Reinforcement Learning

Question 47
Which of the following statements are correct regarding the task described in Q1? Select two correct answers.
It is an Unsupervised Learning task.
PCA can be used directly to predict the genre of a song.
It is a Supervised Learning task.
The task requires labeled training data.
K-Means Clustering can be used for this task.
Select up to 5 options

Question 48
Working for the same platform described in Q1, you are also asked to develop a recommendation system
which recommends to a user the playlists created by another user who listens to the most similar music to the
user. Which specific machine learning algorithm is appropriate for this, and how can we use this algorithm
for this task? Explain. (Note that deep learning algorithms are out of the scope of this course)

Question 49
Suppose you are developing a face recognition system for a company with 40 employees. You collect 10
different images of each person and for each image, you have information about who is in the photo. You
can assume that a computer vision algorithm extracts five different numeric features from each of these
images. This system will identify the employee by taking a photo of their face when they enter the building.
Which machine learning algorithm that we have learned about in class is not appropriate for the task
described?
a) Decision Tree
b) Naive Bayes
c) K-Nearest Neighbours
d) Random Forests
e) K-Means Clustering

Question 50
Which of the following statements are correct regarding the task described in Q4? Select three correct answers. Select up to 5 options
a) It is a Supervised Learning task.
b) It is an Unsupervised Learning task.
c) The task requires labeled training data.
d) The visual features extracted from the image are the labels for each image.
e) The employee identity is the label for each image.

Question 51
Suppose you are developing a self-driving autonomous vehicle system. You collect video data recordings
that show the road ahead and the kinematic data of the angle of the wheel. This system will learn to
automatically adjust the angle of the wheel according to the visual features extracted from the video data
for each time frame.  What is the task described as predicting the degree of the wheel task to adjust it an example of? Select one correct answer.
a) Clustering
b) Reinforcement Learning
c) Regression
d) Classification
e) Dimensionality Reduction

Question 52
Which of the following can be said for the initial step of the agglomerative clustering algorithm? Select one correct answer.
a) Each data point is determined as a cluster center.
b) The median value of the data points is calculated and a cluster center with these values is assigned.
c) Randomly determined values are assigned as cluster centers.
d) A randomly determined number of K cluster centers are assigned at the beginning.
e) The data point closest to the middle value of the data points is selected and determined as the cluster center.

Question 53
Given the training dataset below and a test instance with attributes (M, 0.80), which of the following
ship types would a 1-Nearest Neighbour classifier predict, using Euclidean distance? Select one correct answer.
Training dataset:
Instance 1: (L, 1.00) - Cargo Ship
Instance 2: (L, 0.10) - Cargo Ship
Instance 3: (M, 0.15) - Cruise Ship
Instance 4: (M, 0.45) - Tanker Ship
Instance 5: (H, 0.30) - Tanker Ship
Instance 6: (H, 0.45) - Container Ship
Instance 7: (M, 0.11) - Cruise Ship
a) Cruise Ship
b) No ship type can be predicted
c) Container Ship
d) Tanker Ship
e) Cargo ship

Question 54
Imagine you are given a high dimensional dataset with thousands of features but limited training examples. What challenges might this pose for building a machine learning model, and what strategies could you apply to address them? Name two strategies and explain how they would address the challenges.

Question 55
Age: [22.0, 38.0, 26.0, 35.0, 35.0]
Survived: [0, 1, 1, 1, 0]
Female: [0, 1, 1, 1, 0]
Table: The first 5 rows of the Titanic dataset
Suppose we want to build a classifier to predict whether a person survived the sinking of the Titanic. The
first 5 rows of our dataset are given above in Table.
For a given classifier, suppose the first 10 predictions of our classifier and 10 true observations (ground
truth) are as follows:
Prediction: [1,1,1,1,1,0,1,1,1,1]
Label: [0,1,1,1,0,0,0,1,1,1]
What is the accuracy of our classifier on these 10 predictions? Select one correct answer.
a) %60
b) %80
c) %50
d) %90
e) %70
