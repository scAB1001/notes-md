Thursday 20/11/2025

---
Mostly relates to the vertex processing stage, shaders too (also extra metadata relatead to input data)

 Code highlighted in yellow has changed (now using 4x4 matrix and vector of 4 too)
 What does `uModelViewProjection` represent?

### Relevant topics
- Handedness of coordinate systems
- Constructing matrices
- Hierarchical transformations
## Spaces
### Model space
Chair example in model (local) space, give it (0, 0, 0) vertex positions (v_model)

### World space
Now put it into world space: positions for each vertex. 
v_world = m_world * v_model

Instancing:
Single object (e.g., this chair) placed multiple times in the scene.
Each instance has a different transformation, but only store one copy of the objectâ€™s data.
v_world = m'_world * v_model

### Camera space
View/eye/camera space. Position relative to camera using a transformation.
v_camera = m_camera * v_modelworld

**NEGATIVE COORDINATES ARE IN FRONT OF YOU.**

You are moving the world not the camera.

### Clip space
Unit/clip space: 
We have 3D coordinates but need to fit in space. We go from 3D to 2D but keeping depth along the way to identify objects in the space (which space??)
X TO 1?

Clip space: Clipping takes place here
- Anything outside of the view is discarded
- Fixed function (hardware)
#### OPENGL WILL DO THIS FOR YOU!
Homogenization:
v_ndc = v_clip / v_clip.w

We want pixel coordinates - normalise the ... coordinates and so we perfrom perspective division and are now in 3D again

### Normalized Device Coordinates (NDC) 
E.g. convert (-1, -1, z) to screen coordinates (0, 0, z) - bottom left
#### OPENGL WILL DO THIS FOR YOU!
Viewport transform (scale from NDC to window size) glViewport
## Overview
You can choose to not have some spaces, typically no camera space.

Old OpenGL compresses these into a single MODELVIEW
transform.
(We will also prefer to combine them into a single matrix
when possible.)
- Model space: defined by us
- World space: defined by us
- Camera space: defined by us
- Perspective camera: position, forward, up; field of view; near and far
- Clip space: defined by OpenGL (homogeneous coordinates)

Most of OpenGL is right-handed coordinates system so will have to change the clip space/NDC.
- NDC: defined by OpenGL
	- Always from (-1, -1, -1) to (+1, +1, +1). *Unit cube*, Left-handed
	- Vulkan: (-1, -1, **0**) to (+1, +1, +1). Right-handed
### Left-handed vs. Right-handed
- Determines orientation of axes relative to each other
- RH: Default coordinate system in e.g. physics
- (Except when torturing students with mirrorsâ€¦)
- Most of OpenGL, all(?) of Vulkan
- DirectX: left handed :-)
- Less important in modern APIs
(adjust in vertex shader/projection)
![[right-hand-rule.png]]
### Screen space: scaled + translated version of NDC
- To â€œpixelâ€ coordinates
- (0,0) to (w,h)
- For 1920 x 1080: (0,0) to (1920, 1080) exclusive
Defined by viewport:
```cpp
glViewport x, y, width, height )
	x_window = x_ndc + 1 * width/2 + x
	y_window = y_ndc + 1 * width/2 + y
```
### Summary â€“ Vertex processing
- Define models in model space: ğ’—ğ‘šğ‘œğ‘‘ğ‘’ğ‘™ (vertex positions)
- Transform to world space: ğ’—ğ‘¤ğ‘œğ‘Ÿğ‘™ğ‘‘ = ğ‘€ğ‘¤ğ‘œğ‘Ÿğ‘™ğ‘‘ ğ’—ğ‘šğ‘œğ‘‘ğ‘’ğ‘™
- Instancing: multiple copies of the same object with different transformations
- Transform to camera space: ğ’—ğ‘ğ‘ğ‘šğ‘’ğ‘Ÿğ‘ = ğ‘€ ğ‘ğ‘ğ‘šğ‘’ğ‘Ÿğ‘ ğ’—ğ‘¤ğ‘œğ‘Ÿğ‘™ğ‘‘
- Relative to camera
- Projection gets us to clip space: ğ’—ğ‘ğ‘™ğ‘–ğ‘ = ğ‘€ ğ‘ğ‘Ÿğ‘œğ‘— ğ’—ğ‘ğ‘ğ‘šğ‘’ğ‘Ÿğ‘
- ğ’—ğ‘ğ‘™ğ‘–ğ‘ = ğ‘€ ğ‘ğ‘Ÿğ‘œğ‘— ğ‘€ ğ‘ğ‘ğ‘šğ‘’ğ‘Ÿğ‘ ğ‘€ğ‘¤ğ‘œğ‘Ÿğ‘™ğ‘‘ ğ’—ğ‘šğ‘œğ‘‘ğ‘’ğ‘™
- ğ’—ğ’„ğ’ğ’Šğ’‘ = ğ‘´ ğ’‘ğ’“ğ’ğ’‹ğ‘ªğ’‚ğ’ğ’†ğ’“ğ’‚ğ‘¾ğ’ğ’“ğ’ğ’… ğ’—ğ’ğ’ğ’…ğ’†ğ’
with ğ‘´ ğ’‘ğ’“ğ’ğ’‹ğ‘ªğ’‚ğ’ğ’†ğ’“ğ’‚ğ‘¾ğ’ğ’“ğ’ğ’… = ğ‘€ ğ‘ğ‘Ÿğ‘œğ‘— ğ‘€ ğ‘ğ‘ğ‘šğ‘’ğ‘Ÿğ‘ ğ‘€ ğ‘¤ğ‘œğ‘Ÿğ‘™ğ‘‘

**PRECOMPUTE THIS MATRIX AND USE IN UR VERTEX SHADER**

#### Key takeaway:
- Can do vertex transforms with a single 4x4 matrix mult per vertex
- Combination of various matrices
- Next up: Rotation, translation, scaling
- Then: 4x4 matrices, projection
### Vertex shader sample
```cpp
#version 430
// Input data
layout( location = 0 ) in vec3 iPosition;

// Uniforms
layout( location = 0 ) uniform mat4 uModelViewProjection;
void main()
{
	gl_Position = uModelViewProjection * vec4( iPosition, 1.0 );
}
```
`ModelViewProjection`: traditional name
I tend to prefer e.g. `ProjCameraWorld` or similar. Up to you.
### Recap: translation
- Vertex position ğ’— = (v_x, v_y, v_z) (a point)
- Translation vector ğ’• = (t_x, t_y, t_z) (a vector)
- Translation: ğ’—â€² = ğ’— + ğ’•
- Same as in 2D, except with one more coordinate
### Recap: scaling
- Vertex position ğ’— = vx, vy, vz (a point)
- Scaling matrix ğ‘† =
ğ‘ ğ‘¥ 0 0
0 ğ‘ ğ‘¦ 0
0 0 ğ‘ ğ‘§
- Scaling: ğ’—â€² = ğ‘† ğ’—
- Again, same as in 2D, except with one more coordinate
### Rotation
- Bit more complicated.
- 2D: rotation with a single angle
R2D(ğœƒ) = cos ğœƒ âˆ’ sin ğœƒ
sin ğœƒ cos ğœƒ
3D: rotation around each axis possibleâ€¦
- Three different rotation matrices:
Rz(ğœƒ) =
cos ğœƒ âˆ’ sin ğœƒ 0
sin ğœƒ cos ğœƒ 0
0 0 1 (same as 2D, but with extra coordinate)

Rx(ğœƒ) =
1 0 0
0 cos ğœƒ âˆ’ sin ğœƒ
0 sin ğœƒ cos ğœƒ

Ry(ğœƒ) =
cos ğœƒ 0 sin ğœƒ
0 1 0
âˆ’ sin ğœƒ 0 cos ğœƒ

- Compose arbitrary rotations from these three
- Warning: Gimbal lock (when you look up and left then right but you just rotate instead)
- Create rotations around an arbitrary axis rx, ry, rz (unit vector)
	- See e.g. https://learnopengl.com/Getting-started/Transformations
	- (I almost never use this)
- Can also use quaternions
### Scaling/Rotation and Translation
- Two options:
	- â€œSeparateâ€
	- Single 4x4 matrix (second half)
#### Separate
- Affine transform: ğ‘‡ ğ’— = ğ‘€ ğ’— + ğ’•
- Two affine transforms:
ğ‘‡ ğ’— = ğ‘€0 ğ’— + ğ’•0
ğ‘„ ğ’— = ğ‘€1 ğ’— + ğ’•1

- We can combine them.
	- Start with ğ’—
	- First, transform by ğ‘‡: ğ’—â€™ = ğ‘‡ ğ’—
	- Then, transform by Q: ğ’—â€™â€™ = ğ‘„ ğ’—â€² = ğ‘„(ğ‘‡(ğ’—))

- Combined:
ğ‘„ ğ‘‡ ğ’— = ğ‘€1ğ‘‡ ğ’— + ğ’•1 = ğ‘€1 (ğ‘€0 ğ’— + ğ’•0) + ğ’•1
= ğ‘€1ğ‘€0 ğ’— + ğ‘€1ğ’•0 + ğ’•1
= ğ‘€10 ğ’— + ğ’•10
(where ğ‘€10 = ğ‘€1 ğ‘€0 (matrix) and ğ’•10 = ğ‘€1ğ’•0 + ğ’•1 (vector)
##### Ordering
- In general: T(Q(v)) != Q(T(v)) !
- ğ‘„ ğ‘‡ ğ’— = ğ‘€1ğ‘€0 ğ’— + ğ‘€1ğ’•0 + ğ’•1 = ğ‘€10 ğ’— + ğ’•10
- ğ‘‡ ğ‘„ ğ’— = ğ‘€0ğ‘€1 ğ’— + ğ‘€0ğ’•1 + ğ’•0 = ğ‘€01 ğ’— + ğ’•01
ğ‘€10 â‰  ğ‘€01
ğ’•10 â‰  ğ’•01
#### 4x4 matrix
- Decent option:
	- 4x4 matrix: 16 floats
	- Separate: 3x3 matrix + 3D vector: 9+3 = 12 floats
- Also a bit cheaper to compute
- But no projections
##### As operators?
- Functions: a bit awkward to write / manipulate
ğ‘ˆ (ğ’—) = ğ‘„( ğ‘‡( ğ’—))
- Operator-like notation: Q^ = Q(.)
- So, U^ = Q^ *T^* *v (Basically: skip parentheses)
- Same rules as for matrices (associative but not commutative)

							Block equation of maths
### Hierarchical transforms
![[arm-claw-clip-art.png]]
Claw can rotate independently
Claw is relative to arm!
							Block equation of maths
### Affine transformations
- Introduced an affine transformation as
ğ‘‡ ğ’— = ğ‘€0 ğ’— + ğ’•0
where ğ‘€0 is a 3x3 matrix, ğ’•0 is a 3D vector (displacement), and
ğ’— is a 3D point (position) that we wish to transform.
- Recall: point/position vs. vector
### Camera Space
Camera is a chain of transformations
- Camera transformation typically
	- Rotation
	- Translation
- Could include others (e.g., scaling) but letâ€™s assume for the moment it does not
	- Intuitively: Camera has a position (translation component) and an orientation (rotation component) in/relative to the world
- How do we construct a camera matrix?
	- Two main ways of thinking about this
	
- 1. Consider the camera to be a sequence of transformations
	- Translations and rotations
- 2. â€œFall backâ€ to our change of coordinate systems
#### 1. Sequence of transformations
- Given u = (8,2) in xy,
what are the coordinates in
xâ€™yâ€™?
- Construct basis vectors
xâ€™ and yâ€™ (in xy coordinates)
- Compute
ğ’– â‹… ğ’™â€² and ğ’– â‹… ğ’šâ€²
ğ’– â‰ˆ (6.5, 4.9) in xâ€™yâ€™
![[coord-sys-3d-chain-ex.png]]
#### 2. Matrix
- Equivalent operation with a matrix
ğ‘¥ğ‘¥
â€² ğ‘¥ğ‘¦
â€²
ğ‘¦ğ‘¥
â€² ğ‘¦ğ‘¦
â€²
ğ‘¢ğ‘¥
ğ‘¢ğ‘¦ = ğ‘¢ğ‘¥ğ‘¥ğ‘¥
â€² + ğ‘¢ğ‘¦ğ‘¥ğ‘¦
â€²
ğ‘¢ğ‘¥ğ‘¦ğ‘¥
â€² + ğ‘¢ğ‘¦ğ‘¦ğ‘¦
â€² = ğ’– â‹… ğ’™â€²
ğ’– â‹… ğ’šâ€²
- Rows of the matrix seem to be the basis vectorsâ€¦

Take the three basis vectors x, y and z (directions!) and express them in world space:
	ğ’™ğ‘¤ğ‘œğ‘Ÿğ‘™ğ‘‘, ğ’šğ‘¤ğ‘œğ‘Ÿğ‘™ğ‘‘, ğ’›ğ‘¤ğ‘œğ‘Ÿğ‘™ğ‘‘
Construct matrix
	ğ‘¥ğ‘¤ğ‘œğ‘Ÿğ‘™ğ‘‘,ğ‘¥ ğ‘¥ğ‘¤ğ‘œğ‘Ÿğ‘™ğ‘‘,ğ‘¦ ğ‘¥ğ‘¤ğ‘œğ‘Ÿğ‘™ğ‘‘,ğ‘§
	ğ‘¦ğ‘¤ğ‘œğ‘Ÿğ‘™ğ‘‘,ğ‘¥ ğ‘¦ğ‘¤ğ‘œğ‘Ÿğ‘™ğ‘‘,ğ‘¦ ğ‘¦ğ‘¤ğ‘œğ‘Ÿğ‘™ğ‘‘,ğ‘§
	ğ‘§ğ‘¤ğ‘œğ‘Ÿğ‘™ğ‘‘,ğ‘¥ ğ‘§ğ‘¤ğ‘œğ‘Ÿğ‘™ğ‘‘,ğ‘¦ ğ‘§ğ‘¤ğ‘œğ‘Ÿğ‘™ğ‘‘,ğ‘§
This gives us a rotation. Translation based on position p: t =-p

â€œLook at matrixâ€
ğ‘¥ğ‘¤ğ‘œğ‘Ÿğ‘™ğ‘‘,ğ‘¥ ğ‘¥ğ‘¤ğ‘œğ‘Ÿğ‘™ğ‘‘,ğ‘¦ ğ‘¥ğ‘¤ğ‘œğ‘Ÿğ‘™ğ‘‘,ğ‘§
ğ‘¦ğ‘¤ğ‘œğ‘Ÿğ‘™ğ‘‘,ğ‘¥ ğ‘¦ğ‘¤ğ‘œğ‘Ÿğ‘™ğ‘‘,ğ‘¦ ğ‘¦ğ‘¤ğ‘œğ‘Ÿğ‘™ğ‘‘,ğ‘§
ğ‘§ğ‘¤ğ‘œğ‘Ÿğ‘™ğ‘‘,ğ‘¥ ğ‘§ğ‘¤ğ‘œğ‘Ÿğ‘™ğ‘‘,ğ‘¦ ğ‘§ğ‘¤ğ‘œğ‘Ÿğ‘™ğ‘‘,ğ‘§

â€œLook at matrixâ€
ğ‘Ÿğ‘–ğ‘”â„ğ‘¡ğ‘¤ğ‘œğ‘Ÿğ‘™ğ‘‘,ğ‘¥ ğ‘Ÿğ‘–ğ‘”â„ğ‘¡ğ‘¤ğ‘œğ‘Ÿğ‘™ğ‘‘,ğ‘¦ ğ‘Ÿğ‘–ğ‘”â„ğ‘¡ğ‘¤ğ‘œğ‘Ÿğ‘™ğ‘‘,ğ‘§
ğ‘¢ğ‘ğ‘¤ğ‘œğ‘Ÿğ‘™ğ‘‘,ğ‘¥ ğ‘¢ğ‘ğ‘¤ğ‘œğ‘Ÿğ‘™ğ‘‘,ğ‘¦ ğ‘¢ğ‘ğ‘¤ğ‘œğ‘Ÿğ‘™ğ‘‘,ğ‘§
âˆ’ğ‘“ğ‘œğ‘Ÿğ‘¤ğ‘ğ‘Ÿğ‘‘ğ‘¤ğ‘œğ‘Ÿğ‘™ğ‘‘,ğ‘¥ âˆ’ğ‘“ğ‘œğ‘Ÿğ‘¤ğ‘ğ‘Ÿğ‘‘ğ‘¤ğ‘œğ‘Ÿğ‘™ğ‘‘,ğ‘¦ âˆ’ğ‘“ğ‘œğ‘Ÿğ‘¤ğ‘ğ‘Ÿğ‘‘ğ‘¤ğ‘œğ‘Ÿğ‘™ğ‘‘,ğ‘§

The extra row+column include the translation. We will look at those in a second (homogeneous coordinates)
M = 
ğ‘Ÿğ‘–ğ‘”â„ğ‘¡ğ‘¤ğ‘œğ‘Ÿğ‘™ğ‘‘,ğ‘¥ ğ‘Ÿğ‘–ğ‘”â„ğ‘¡ğ‘¤ğ‘œğ‘Ÿğ‘™ğ‘‘,ğ‘¦ ğ‘Ÿğ‘–ğ‘”â„ğ‘¡ğ‘¤ğ‘œğ‘Ÿğ‘™ğ‘‘,ğ‘§ ğ‘¡ğ‘¥
ğ‘¢ğ‘ğ‘¤ğ‘œğ‘Ÿğ‘™ğ‘‘,ğ‘¥ ğ‘¢ğ‘ğ‘¤ğ‘œğ‘Ÿğ‘™ğ‘‘,ğ‘¦ ğ‘¢ğ‘ğ‘¤ğ‘œğ‘Ÿğ‘™ğ‘‘,ğ‘§ ğ‘¡ğ‘¦
âˆ’ğ‘“ğ‘œğ‘Ÿğ‘¤ğ‘ğ‘Ÿğ‘‘ğ‘¤ğ‘œğ‘Ÿğ‘™ğ‘‘,ğ‘¥ âˆ’ğ‘“ğ‘œğ‘Ÿğ‘¤ğ‘ğ‘Ÿğ‘‘ğ‘¤ğ‘œğ‘Ÿğ‘™ğ‘‘,ğ‘¦ âˆ’ğ‘“ğ‘œğ‘Ÿğ‘¤ğ‘ğ‘Ÿğ‘‘ğ‘¤ğ‘œğ‘Ÿğ‘™ğ‘‘,ğ‘§ ğ‘¡ğ‘§
0 0 0 1

ğ‘‡ğ‘ğ‘ğ‘šğ‘’ğ‘Ÿğ‘ ğ’— = ğ‘€ (ğ’— + ğ’•ğ‘¤ğ‘œğ‘Ÿğ‘™ğ‘‘) = ğ‘€ğ’— + ğ’•ğ‘ğ‘ğ‘šğ‘’ğ‘Ÿğ‘
where ğ’•ğ‘ğ‘ğ‘šğ‘’ğ‘Ÿğ‘ = âˆ’ğ‘·ğ‘ğ‘ğ‘šğ‘’ğ‘Ÿğ‘

- Common â€œtricksâ€
- Forward vector as
- ğ’‡ğ’ğ’“ğ’˜ğ’‚ğ’“ğ’… = ğ’•ğ’‚ğ’“ğ’ˆğ’†ğ’•âˆ’ğ’‘ğ’ğ’”ğ’Šğ’•ğ’Šğ’ğ’ / |ğ’•ğ’‚ğ’“ğ’ˆğ’†ğ’•âˆ’ğ’‘ğ’ğ’”ğ’Šğ’•ğ’Šğ’ğ’| 
	- (all in the same space, e.g., world)
- ğ’–ğ’‘ and ğ’“ğ’Šğ’ˆğ’‰ğ’• ? All three should be orthogonal to each other!
=> Cross product

- Start with ğ’–ğ’‘'ğ‘¤ğ‘œğ‘Ÿğ‘™ğ‘‘ = (0,1,0). Then
ğ’“ğ’Šğ’ˆğ’‰ğ’• = ğ’–ğ’‘â€² Ã— ğ’‡ğ’ğ’“ğ’˜ğ’‚ğ’“ğ’…
ğ’–ğ’‘ = ğ’‡ğ’ğ’“ğ’˜ğ’‚ğ’“ğ’… Ã— ğ’“ğ’Šğ’ˆğ’‰ğ’•
### Sequence of transformations
- Pose that somebody asks you to design a first person cameraâ€¦
- Model as
ğ‘‡ğ‘ğ‘ğ‘šğ‘’ğ‘Ÿğ‘ ğ’— = ğ‘€ğ’— + ğ’•
- Examples: How do we move forward? How do we rotate left?

#### Moving forward
- Moving forward in camera space is easy
ğ’‡ğ’ğ’“ğ’˜ğ’‚ğ’“ğ’…camera = (0,0, âˆ’1)

- ğ‘‡ğ‘ğ‘ğ‘šğ‘’ğ‘Ÿğ‘ ğ’— = ğ‘€ ğ’— + ğ’•
- Move by position forward by distance ğ‘‘ (recall ğ’• = âˆ’ğ‘·)
ğ· ğ’— = ğ¼ ğ’— + ğ’… = ğ’— + 0,0, âˆ’ğ‘‘ ğ‘‡
- â€œChainâ€ translation
ğ‘‡â€²ğ‘ğ‘ğ‘šğ‘’ğ‘Ÿğ‘ ğ’— = ğ· ğ‘‡ğ‘ğ‘ğ‘šğ‘’ğ‘Ÿğ‘ ğ’—
= ğ· ğ‘€ ğ’— + ğ’•
= ğ¼ ğ‘€ ğ’— + ğ’• + ğ’…
= ğ‘€ ğ’— + ğ’• + ğ = ğ‘€ ğ’— + ğ­â€²
#### Rotating the camera
- ğ‘‡ğ‘ğ‘ğ‘šğ‘’ğ‘Ÿğ‘ ğ’— = ğ‘€ ğ’— + ğ’•
- Rotation
ğ‘… ğ’— = ğ‘€ğ‘Ÿ ğ’— + ğŸ (no translation)
- â€œChainâ€ rotation, so
ğ‘‡â€²ğ‘ğ‘ğ‘šğ‘’ğ‘Ÿğ‘ ğ’— = ğ‘… ğ‘‡ğ‘ğ‘ğ‘šğ‘’ğ‘Ÿğ‘ ğ’—
= ğ‘… ğ‘€ ğ’— + ğ’•
= ğ‘…ğ‘€ ğ’— + ğ‘…ğ’•
= ğ‘€â€²ğ’— + ğ’•â€²

Alternative camera model
- We can therefore model a simple camera with just a 3x3 matrix (ğ‘€) and a 3D vector (ğ’•).
-  Conceptually:
	- A change of coordinates
	- A chain of transformations
- Store rotation and translation
	- Rotation: matrix or angles (ğœ™ and ğœƒ).
	- Translation: just a 3D vector (displacement)
## Homogeneous coordinates
- Practical view first
- Recommended:
	- *Math for Game Programmers: Understanding Homogeneous Coordinatesâ€ (GDC 2015)*
	- https://youtu.be/o1n02xKP138
- Practical change: extend 3-vectors to 4-vectors
- Before: (x,y,z)
- After: (x,y,z,w)
- Why? What is â€˜wâ€™?
	- First attempt: â€œThe â€˜wâ€™ stands for witchcraft.â€ (see GDC talk)
	- 
 - â€œNormalâ€ points: (x, y, z, 1)
- Directions: (x, y, z, 0)
- We now have a way to distinguish between the two!
	- From before:
			- Point â€“ Point = Vector (x,y,z,1) - (u,v,w,1) = (x-u, y-v, z-w, 0)
		- Vector Â± Vector = Vector (x,y,z,0) Â± (u,v,w,0) = (xÂ±u,yÂ±v,zÂ±w, 0) 
		- Point Â± Vector = Point (x,y,z,1) Â± (u,v,w,0) = (xÂ±u,yÂ±v,zÂ±w, 1)
		- Point + Point = :( (x,y,z,1) + (u,v,w,1) = (x+u, y+v, z+w, **2**) <- 2 is wrong

#### Transforms
- Similarly: extend 3x3 matrices to 4x4 matrices
m_1 = 
ğ‘ ğ‘ ğ‘
ğ‘‘ ğ‘’ ğ‘“
ğ‘” â„ ğ‘–
 into
ğ‘ ğ‘ ğ‘ 0
ğ‘‘ ğ‘’ ğ‘“ 0
ğ‘” â„ ğ‘– 0
0 0 0 1
- Verify that things havenâ€™t changed
	- Transforming a point should make a point
	- Vector to vector
- Compute m_1 * vector (x,y,z) =
ğ‘ğ‘¥ + ğ‘ğ‘¦ + ğ‘ğ‘§
ğ‘‘ğ‘¥ + ğ‘’ğ‘¦ + ğ‘“ğ‘§
ğ‘”ğ‘¥ + â„ğ‘¦ + ğ‘–ğ‘§

into
ğ‘ğ‘¥ + ğ‘ğ‘¦ + ğ‘ğ‘§ + 0ğ‘¤
ğ‘‘ğ‘¥ + ğ‘’ğ‘¦ + ğ‘“ğ‘§ + 0ğ‘¤
ğ‘”ğ‘¥ + â„ğ‘¦ + ğ‘–ğ‘§ + 0ğ‘¤
0ğ‘¥ + 0ğ‘¦ + 0ğ‘§ + 1ğ‘¤
w unchanged! Point remains point, vector stays vector.
#### Transforms
- Linear transforms (rotation, scaling, â€¦) are unchanged
- We just change the 3x3 matrix into a 4x4 one as shown
#### Translation
ğ‘ğ‘¥ + ğ‘ğ‘¦ + ğ‘ğ‘§ + **0ğ‘¤**
ğ‘‘ğ‘¥ + ğ‘’ğ‘¦ + ğ‘“ğ‘§ + **0ğ‘¤**
ğ‘”ğ‘¥ + â„ğ‘¦ + ğ‘–ğ‘§ + **0ğ‘¤**
0ğ‘¥ + 0ğ‘¦ + 0ğ‘§ + 1ğ‘¤

e.g.
1 0 0 ğ‘¡ğ‘¥
0 1 0 ğ‘¡ğ‘¦
0 0 1 ğ‘¡ğ‘§
0 0 0 1
*
ğ‘¥
ğ‘¦
ğ‘§
ğ‘¤
becomes
ğ‘¥ + ğ‘¡ğ‘¥ğ‘¤
ğ‘¦ + ğ‘¡ğ‘¦ğ‘¤
ğ‘§ + ğ‘¡ğ‘§ğ‘¤
ğ‘¤
- If w = 1, then this becomes a translation: (x + ğ‘¡ğ‘¥, y + ğ‘¡ğ‘¦, z + ğ‘¡ğ‘§, 1)
	- Afterwards: w = 1, so the point is still a point
- If w = 0, then nothing happens, and w = 0.
	- Vectors are not translated! Nice

![[vec-change-3d-translation.png]]
Vectors are not translated!
- Point A moves to C
- Point B moves to D
- But the vector u remains unchanged
#### Single representation
- 4x4 matrices can represent â€œallâ€ transformations
	- Rotation, scaling, â€¦ (as before)
	- Translations
- â€œChainâ€ rule still applies:
	- Translate a point P by T, then rotate the result by R
	- Pâ€™ = T P, where T = translation matrix, P = (x, y, z, 1)
	- Pâ€™â€™ = R Pâ€™ = R T P = Q P with 4x4 matrix Q = R T
- Convenient
- But we could already do this.
	- Technically, 3x3 matrix + 3 vector: more compact
#### Projection
- Different types of projection
- Orthographic
- **Perspective**
- Oblique
#### Perspective projection
- What is perspective projection?
- â€œForeshorteningâ€ / vanishing point
- An object that is further away appears smaller
- (And closer to the center of vision.)
![[perspective-projection.png]]
 What is happening?
- ğ‘Ÿ = ğ‘‘ tan ğ›¼
- ğ‘ = 1 tan ğ›¼
- ğ‘/ğ‘Ÿ = 1 tan ğ›¼ / ğ‘‘ tan ğ›¼ = 1 / ğ‘‘
	- Smaller proportional to factor 1/d (where d is distance)
#### Back to homogeneous coordinates for a secondâ€¦
- We were left with a question
(x, y, z, 1) is a point
(x, y, z, 0) is a vector
(x, y, z, w) with (w != 1 and w != 0) is a???
Rule:
- (x, y, z, w) is the same point as (cx, cy, cz, cw).
- Rephrase:
- (x, y, z, w) is the same point as (x/w, y/w, z/w, 1)
- We â€œhomogenizeâ€ coordinates by dividing with w
#### Continue with perspective projection
1 0 0 0
0 1 0 0
0 0 1 0
0 0 **âˆ’1 0**
ğ‘¥
ğ‘¦
ğ‘§
1
becomes
ğ‘¥
ğ‘¦
ğ‘§
âˆ’**ğ‘§**
Homogenize:
ğ‘¥
ğ‘¦
ğ‘§
âˆ’**ğ‘§**
=>
ğ‘¥/âˆ’ğ‘§
ğ‘¦/âˆ’ğ‘§
ğ‘§/âˆ’ğ‘§
âˆ’ğ‘§/âˆ’ğ‘§
=>
ğ‘¥/âˆ’ğ‘§
ğ‘¦/âˆ’ğ‘§
âˆ’1
1
New point (w = 1). x and y are scaled with the perspective factor.
Z is negative in the forward direction, hence the minus.
Nice! All done? NO
##### Problem 1
- We lost all information on depth
- Canâ€™t tell how far a point is from the camera
- Consequently, canâ€™t tell if a triangle is in front of another.
ğ‘¥/âˆ’ğ‘§
ğ‘¦/âˆ’ğ‘§
**âˆ’1**
**1**
#### Try again
1 0 0 0
0 1 0 0
0 0 1 **1**
0 0 **âˆ’1 0**
ğ‘¥
ğ‘¦
ğ‘§
1
becomes
ğ‘¥
ğ‘¦
ğ‘§ **+ 1**
âˆ’**ğ‘§**
Now homogenize
ğ‘¥
ğ‘¦
ğ‘§ **+ 1**
âˆ’**ğ‘§**
=>
ğ‘¥/âˆ’ğ‘§
ğ‘¦/âˆ’ğ‘§
(ğ‘§ **+ 1**)/âˆ’ğ‘§
âˆ’ğ‘§/âˆ’ğ‘§
=>
ğ‘¥/âˆ’ğ‘§
ğ‘¦/âˆ’ğ‘§
âˆ’1 âˆ’ 1/ğ‘§
1
- Minus sign since â€“z is into the screen.
Z = -1: -1 + 1/1 = 0
Z = -100: -1 + 1/100 = -0.99
Resulting depth: 0 = nearest, -1 = furthest
Not yet quite what we wanted. But retained depth.
##### Problem 2
- What about z = 0?
	- 1/0 ...
- Near plane: Donâ€™t draw anything closer than it
- For numeric reasons: also a far plane (normally)
	- Can have it at infinity, but probably want to **use ReverseZ** in that case
	- 0 to 1 as opposed to -1 to 1
#### Near and far planes (the fix)
- Near + far planes
	- Visible region from near to far
	- Usually given as distances (near distance, far distance)
	- e.g. near distance at 0.1 means coordinates -0.1
![[near-far-plane-ex.png]]
With near plane at z = -n & far plane at z = -f, we want to map
- ğ’—ğ‘› = (ğ‘¥, ğ‘¦, âˆ’ğ‘›, 1) to (ğ‘¥, ğ‘¦, âˆ’1,1) in clip space
- ğ’—ğ‘“ = (ğ‘¥, ğ‘¦, âˆ’ğ‘“, 1) to (ğ‘¥, ğ‘¦, +1,1) in clip spac

- Modified projection:
ğ‘ƒ =
1 0 0 0
0 1 0 0
0 0 ğ‘ ğ‘
0 0 âˆ’1 0

ğ‘ = âˆ’ ğ‘“+ğ‘› / ğ‘“âˆ’ğ‘›
ğ‘ = âˆ’ 2ğ‘“ğ‘› / ğ‘“âˆ’ğ‘›

Try this out! Compute (on paper) P ğ’—ğ‘› and P ğ’—ğ‘“ and verify that these end up at the correct positions in clip space! **THIS IS THE SOLUTION**
#### Scale X and Y
- Similarly x and y should be in (-1, 1) both
##### Field of view and aspect ratio
- Field of view (fov): angle
- Aspect ratio: dependent on size of window/viewport
- Ratio between width and height
- Gives us size of plane at distance z = -1
**DO NOT USE VIRTUAL FOV**
![[fov-on-plane-ex.png]]
ğ‘£ = tan ğ‘“ğ‘œğ‘£/ 2 , vx = ğ‘£/ğ‘ğ‘ ğ‘ğ‘’ğ‘ğ‘¡
![[fov-labelled-plane.png]]
 - Note: I use a vertical field of view
	- Not everybody does, horizontal is fairly common
- Why vertical?
	- Screens tend to vary more in width than in height
	- E.g. 4:3, 16:9, 16:10, 21:9 vs 32:9 aspect ratios
	- So define vertical fov, compute horizontal based on screen/window dimensions
- Aspect ratio = width / height
- Projection matrix:
	- Add another scaling, this time to x and y
ğ‘ƒ =
ğ‘ ğ‘¥ 0 0 0
0 ğ‘  0 0
0 0 ğ‘ ğ‘
0 0 âˆ’1 0 

S = 1 / tan(ğ‘“ğ‘œğ‘£/2 )
ğ‘ ğ‘¥ = ğ‘  / ğ‘ğ‘ ğ‘ğ‘’ğ‘ğ‘¡ = s â„ğ‘’ğ‘–ğ‘”â„ğ‘¡ / ğ‘¤ğ‘–ğ‘‘ğ‘¡â„

ğ‘ = âˆ’ ğ‘“+ğ‘› / ğ‘“âˆ’ğ‘›
ğ‘ = âˆ’ 2ğ‘› / ğ‘“âˆ’ğ‘›

- aspect: aspect ratio (width/height)
- fov: field of view (angle, e.g. 60 degrees)
- f: far distance (e.g. 100)
- n: near distance (e.g., 0.1)
**This is covered in G.3**

1 / ğ‘ğ‘ ğ‘ğ‘’ğ‘ğ‘¡ tan(ğ‘“ğ‘œğ‘£/2 )
0 0 0
0 1 / tan(ğ‘“ğ‘œğ‘£/2 )
0 0
0 0 âˆ’ ğ‘“ + ğ‘›/ğ‘“ âˆ’ ğ‘› âˆ’2 ğ‘“ ğ‘›
ğ‘“ âˆ’ ğ‘›
0 0 âˆ’1 0