Thursday 06/11/2025

---
Is it useful to render 128 millionn triangles? No, there aren't even that many pixels.
#### 3D graphics
- Projective Pipeline
- Could do that with our primitives
- E.g., triangles with barycentric interpolation
- But slow, and few people use their own software renderers any more
- Want to utilize GPUs = Graphics Processing Units
	- (Why? Exercise 4: 8.5 GTris/sec <=> 130MTris @ 60+Hz on 3070 Ti)

Conceptual pieces:
- Graphics pipeline (will see it today already)
- Data: Triangles & Meshes
- Spaces: Model, World, Camera, Clip & Screen space
- Projection, Hidden surfaces (depth buffering)
- Texturing, Lighting & Materials
##### OpenGL New Exercises
- Exercise G.2 - G.6 available:
- G.2: Triangle
- G.3: 3D
- G.4: Meshes & Data
- G.5: Shading & Lighting
- G.6: Texturing.
#### GPU
- Ubiquitous these days
	- Wasn’t always the case
	- OpenGL: doesn’t really address it specifically
	- Vulkan: built around the idea of a “device” (=GPU)
- Integrated (iGPU) vs discrete (dGPU)
	- Separate device that executes asynchronously!
	- Massively parallel
- Separate device:
	- Communication costs, latency
	- PCIe 4.0 x1: ~2GB/s, x16: ~32GB/s; RAM: ~40GB/s (DDR4-2666, dual channel)
	- RTX 3070 Ti: ~600 GB/s (GDDR6X)
- Asynchronous:
	- Avoid waiting between CPU and GPU
- Massively parallel:
	- “Do many things”
- Programming model:
	- Queue jobs for it to process “later”
	- Each job should include many tasks
	- Each task does the same thing, but with different data
- Avoid waiting for results
#### So what is OpenGL?
- Graphics API
- Lets us draw stuff
	- Rasterization
	- Incidentally: one way to talk to a GPU
	- Compute stuff (compute shaders)
- Also: talk to GPU
	- But GPUs didn’t exist in their current form when OpenGL was released
	- GeForce 256 in 1999 vs. OpenGL in 1992. (3dfx Voodoo was 1994)
	- Modern GPUs look very different.
	- Original philosophy: precede hardware evolution
- Independent of OS, window system
	- Multi-platform (Windows, Linux, MacOS – originally)
	- OpenGL|ES for “embedded”/mobile
	- Extensible
##### OpenGL vs Vulkan
- OpenGL: focuses more on drawing things
- Vulkan: GPU management API
	- Drawing things is just a part of that (albeit a big part)
	- Planned for a long time (“glNext”)
	- Fixes many of the pain points of OpenGL, but has more complexity
	- But ends up being a different style of API
- Otherwise similar goals
##### OpenGL – Brief History
- 1.0: June 1992
	- Silicon Graphics (SGI), from IRIS GL
- Has changed significantly since then
	- But many old parts still hang around (and are still supported
##### OpenGL – Major Versions
- 1.1: Texture objects, CPU vertex arrays
- 2001: 1.3: Multitexturing
- 2002: 1.4: First shaders (ARB_vertex_program et al.)
- 2003: **1.5: Vertex buffer objects (VBOs)**, occlusion queries
- 2004: **2.0: GLSL shaders** in core! **Non-power-of-two (NPOT) textures**
- 2006: **2.1:** Pixel buffer objects (PBO), **sRGB textures**
- 2008: **3.0:** Framebuffer objects (FBOs), texture arrays (onion textures) **Vertex array objects (VAOs)**
- 2009: 3.1: Uniform buffer objects (UBOs), instancing
- 2009: 3.2: Geometry shaders, multi-sampled textures
- 2010: 4.0: GLSL 4.0 (before this versions were strange), tessellation shaders
- 64-bit variables in shades
- 2010: **4.1: Debug output (extension)**
- 2011: 4.2: Atomics in shaders
- 2012: 4.3: Compute shaders, shader storage buffer objects (SSBOs)
- 2013: 4.4: Bindless textures, sparse textures
- 2014: 4.5: More bindless (direct state access, DSA)
- 2017: 4.6: SPIR-V shaders, more efficient API usage (~AZDO)
##### OpenGL – Extensions
- OpenGL additionally has 100s of extensions
	- Examples: ARB_multitexture (1998), NV_timeline_semaphore (2020)
	- ARB: “Architecture Review Board”
		- Consortium that governed OpenGL, now Khronos
		- “Official extension”, probably supported by multiple vendors
	- NV: NVIDIA
		- Most likely NVIDIA GPUs only (few exceptions exist
- Used to expose new functionality early
	- Multi-vendor: ARB, EXT
	- Single vendor: NV, ATI/AMD, INTEL, APPLE, …
- Example: NV extensions for NVIDIA GPU technology
	- NV_shading_rate_image (2020)
	variable shading rate launched with Turing GPUs (20x0 series)
- Same mechanism has allowed OpenGL drivers to provide new versions even when the OS wouldn’t
	- Windows… :(
	- Typically use this mechanism on all platforms for simplicity
- New functions loaded via name => function pointers
	- wglGetProcAddress(), glXGetProcAddress(), …
	- Tedious
	- The GLAD loader does this for us. (Others: GLEW, GLEE, …)
#### Drawing things
Setup is most of the code, actually drawing takes very little code compartively.
- What goes into drawing something?
	- Resources (input and output data)
	- Description (how to draw)
	- Commands to perform the work
- Input: vertices, textures, uniform variables, …
- Output: surface/image to draw into
	- Sometimes: buffers
![[opengl-pipeline-gl-reference-card-3d.png]]

![[opengl-pipeline-gl-reference-card-3d-labelled.png]]

![[opengl-pipeline-simplified-labelled.png]]
#### What we need to do
- Allocate resources (input/output buffers and images)
- Define contents of buffers
- Define drawing state, including shader programs
- Submit draw commands (“draw calls”)
- Clean up resources
- Show the results on screen
	- Not OpenGL; instead OS/Window manager (we use GLFW)

==Use glEnable( GL_RASTERIZER_DISCARD )==