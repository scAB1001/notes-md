Thursday 02/10/25

---
“rendering”: process of generating an image

Images - World is defined by connected points that form triangles.
Points in 3D are transformed and projected to the 2D screen.
Multiple triangles cover a the same part of the screen
Textures add details to surfaces and light sources illuminate the scene

We draw only primitive shapes in part 1 of the module:
- Pixels, Points
- Lines (maybe curves)
- Triangles
- Images (maybe volumes)

3D rendering in part 2 of the module:
- Pipeline
- Meshes
- Materials
- Lighting (OpenGL, Shaders, …)

Need to think about shadows (cast and otherwise) as well as the glow of light sources not just a brighter screen

Triangle surfaces?
- Triangle surfaces by far the most common primitive for 3D
- But not the only one!
- Point-based graphics (e.g. 3D scans)
- Voxels & volumetric data (e.g., editing, simulation, …)
- Splats (a bit like points), NERFs (radiance fields), and so on
- Quads (e.g. model;ing)

- Drawing primitives (pixels, lines, triangles)
- Also “blitting” images
- Projective graphics pipeline
- From 3D model space to 2D screen space
- Shading: Texturing, Lighting, Materials
- Practically: C++, OpenGL & GLSL

Ray tracing uses the same primitives!
Rays <=> lines in 3D!
Texturing, lighting and materials apply in ray tracing as well.

Books are shoddy but can supplement with multiple to make up for it
- Check hardware reqs before installing on device
- Use linux for cwks

Coursework - Support
- When asking questions:
- Describe your problem
- Describe what you’ve attempted so far
- Email: Use whole English sentences with proper grammar, punctuation etc.
- Under no circumstances should you take screenshots/images of code!
- Post them as text
- Screenshots of your graphical results are OK
- Take proper screenshots (no photos of the screen)

Color, Pixels, Images
- Color spaces (sRGB, HDR)
- Manipulating images
![[pixels-and-subpixels.png]]
http://hyperphysics.phy-astr.gsu.edu/hbase/vision/colcon.html