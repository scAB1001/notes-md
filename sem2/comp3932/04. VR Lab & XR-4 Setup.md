### Outline
- Read XR Documentation
- Setup Unity software *base*
- Unity XR SDK
- Handtracking then Eye tracking
- Schedule lab times (contingent on machine availability and lab access)
# Theory
## Varjo Developer Guide
https://developer.varjo.com/docs/get-started/get-started

You can develop for Varjo headsets with the familiar 3D tools you use today to create immersive experiences. These tools can easily be adapted to work with Varjo headsets and human-eye resolution.
### Human Eye Resolution
https://developer.varjo.com/docs/get-started/human-eye-resolution
### Foveated Rendering
Foveated rendering uses eye tracking to render the image in full resolution only in those areas where the user is currently looking. 
- Similar to rendering for other HMDs. 
- The main difference is that applications must submit **four** views instead of two. 
	- Two displays for viewports per eye: a *human-eye-resolution focus* view and a *high-resolution peripheral* view.
- Demonstrates significantly improved performance and frame rate with minimal to no perceived loss in quality. 
- Mimics how the eyes functiom, digesting the greatest detail around the center of our gaze. 
- Foveated rendering is available for all Varjo headsets.
![](https://developer.varjo.com/assets/uploads/Foveation.png)
When using Varjo XR plugins for Unity or Unreal, these features are enabled by default.
To learn more about how the image is rendered to the Varjo HMD, see [Rendering to Varjo headsets](https://developer.varjo.com/docs/native/rendering-to-varjo-headsets).

Varjo XR-4 has no need for two displays per eye as the displays are high enough resolution across the full view.
## Video Pass-through (VPT) Technology
By using VPT instead of optical see-through (OST), Varjo’s [mixed reality device](https://varjo.com/products) completely and convincingly merges real and virtual, **making it the only device to achieve photorealism in mixed reality.**

Enables functionality that OST systems like *HoloLens* or *Magic Leap*.

**Virtual objects can be** **black or opaque and appear as solid as anything in the real world**. Colors are perfectly rendered and appear just as they should. You can also add, omit and adjust colors, shadows and light in the virtual world and the real world.

Furthermore, real-time camera data is used to calculate global illumination models that allow shadows and light to naturally interact with virtual objects in real time – just as they would with real-world objects. **Virtual objects can even illuminate, cast shadows over, or reflect the world around them**. They can also appear as transparent and refract the light from the real world behind them.

Importantly, **Varjo also allows you to see your own body as you interact with virtual objects**, the real world around you, and even your colleagues as you collaborate on mixed reality projects. 
### How does the technology work?
VPT uses cameras to digitize the world in real time. That data is then combined with virtual content inside our GPU and shown to users through our device – completely blurring the lines between real and virtual.

It follows the same general logic as our [Bionic Display™](https://varjo.com/blog/introducing-bionic-display-how-varjo-delivers-human-eye-resolution/). Visual quality and bandwidth are optimized by sampling video streams from each camera with different resolutions and using [eye tracking](https://varjo.com/blog/industrial-strength-eye-tracking-in-varjo) to determine which area of the sensor should be sampled in the highest resolution. So the highest resolution will always be wherever the user is looking at any given time.

Just as the human eye does, Varjo then samples the surrounding areas in lower resolution to make sure the transfer speed (below 10Gb/s) can be handled by modern computers. To put this into context, the human eye sends peripheral images to the brain at just 10 Mb/s.

All this means that **Varjo’s mixed reality runs at around 35 times the resolution of HTC Vive Pro mixed reality**, for example, and each individual pixel is of a much higher quality.
### How VPT mixed reality revolutionizes work in a range of fields
Professionals in engineering, [design](https://varjo.com/use-cases/design-and-visualization), [simulation](https://varjo.com/use-cases/training-and-simulation), and [research](https://varjo.com/use-cases/research) can use Varjo’s mixed reality to **develop and interact with photorealistic 3D models while collaborating with others in real life and real time**. 

We collaborated with [Volvo Cars](https://varjo.com/case-studies/xr-test-drive-with-volvo/) to create a truly ground-breaking demo of **a real car being safely driven while wearing a Varjo headset** and interacting with totally convincing virtual elements – including a virtual moose that the driver needs to avoid. Today, Volvo is using Varjo headsets to design and develop the world’s safest cars. With Varjo’s photorealistic mixed reality and eye tracking, Volvo is now able to do design and safety studies on cars that haven’t even been built yet.

We have also collaborated with [Bohemia Interactive Simulations](https://bisimulations.com/) and [many other simulation companies](https://varjo.com/blog/5-pioneering-virtual-and-mixed-reality-training-solutions/) to create **a hybrid cockpit simulator** where the world outside the cockpit is illustrated with VR and the cockpit is real and enhanced with VPT.
## Eye tracking
Varjo headsets feature the 20/20 Eye Tracker, our integrated eye tracking functionality. You can use eye tracking in your application and log gaze information for analytics. Eye tracking can also be used to interact with content; you can use it to select an object or prompt for additional information simply by looking at it.

For detailed instructions, refer to your engine’s documentation:
- [Native eye tracking documentation](https://developer.varjo.com/docs/native/eye-tracking)
- [Example of using eye tracking with Unity XR SDK](https://developer.varjo.com/docs/unity-xr-sdk/eye-tracking-with-varjo-xr-plugin)
- [Example of using eye tracking with Unreal](https://developer.varjo.com/docs/unreal/ue5/unreal5-examples)
### WHAT IS GAZE?
Gaze starts from the **gaze origin** (the eye) and follows the **gaze vector** (the direction of the gaze). A normalized gaze vector is calculated. It is important to understand this concept in order to process eye tracking data while developing for Varjo headsets.

You can also record gaze data together with a video feed from the headset. For instructions, see [Gaze data logging page](https://developer.varjo.com/docs/get-started/gaze-data-collection).
### Varjo XR-4  EYE TRACKER SPECIFICATIONS
Varjo headsets contain two eye tracking cameras, one for each eye. A combined gaze ray can be computed either using information from two eyes (both eyes tracked; the typical situation) or from one eye (e.g., if the other eye cannot be tracked). 

With the recommended computer configurations, you can expect a latency of about 20–30ms from pupil change to the eye tracking result being available.
- IPD range: 56–72mm
- Gaze camera resolution: 640 x 480 px per camera.
- Gaze tracking frequency: 100 Hz (default for native SDK) or 200 Hz (default for OpenXR and Unity XR SDK)
### DEVELOPING WITH THE 20/20 EYE TRACKER
Enable **Allow eye tracking** in the **System** tab in Varjo Base.
![](https://developer.varjo.com/assets/uploads/eye_tracking.png)
Keep in mind that eye tracking must be recalibrated whenever the headset is taken off and put back on, even if the same person is using it. This is necessary because the headset may not be positioned exactly the same way on a person’s head every time. You can manage the calibration directly from your application.
## Hand Tracking
Hand tracking lets you reach into the virtual world with your hands and without using a physical controller. Gestures such as pinching, grabbing, and interacting with objects allow for a new level of immersion in your applications.

Varjo has two hand tracking modes to choose from, operated from the Varjo Base.
See the platform-specific documentation for hand tracking:
- [Native hand tracking (Ultraleap only)](https://developer.varjo.com/docs/native/hand-tracking-native)
- [OpenXR hand tracking](https://developer.varjo.com/docs/openxr/user-input)
- [Unity hand tracking (Ultraleap recommended)](https://developer.varjo.com/docs/unity-xr-sdk/hand-tracking-with-varjo-xr-plugin)
- [Unreal hand tracking](https://developer.varjo.com/docs/unreal/ue5/hand-tracking-with-unreal5)
## Varjo hand tracking
Varjo hand tracking uses the headset’s VPT cameras only for XR-4 Series headsets.

Varjo hand tracking **does not require** any additional installations or SDKs when using or developing as the feature uses standard OpenXR hand tracking. Varjo native SDK is not available.
## Ultraleap hand tracking
> Note: Ultraleap Gemini software should not be installed.

Ultraleap provides optional hand tracking for Varjo. Varjo XR-4 has an **external** hand tracking module add-on.

With the XR-4 with Ultraleap hand tracking module, hand tracking is enabled by default and no additional software is required. If you have previously used standalone Ultraleap sensor, **please uninstall its drivers** as Varjo Base comes with necessary drivers for the sensors.

Refer to [Ultraleap’s documentation](https://docs.ultraleap.com/) for up-to-date guides on integration.

We also recommend that you get acquainted with Ultraleap’s [XR design guidelines](https://docs.ultraleap.com/xr-guidelines/) before you start to work on hand tracking interactions. The guidelines provide valuable information for using hand tracking successfully in your project.
### Ultraleap hand tracking offset
When you start to develop with XR-4 hand tracking **you do not need** to define an offset for the hand position. Use an offset of $(0,0,0)$ for XR-4.
![](https://developer.varjo.com/assets/uploads/HMD_front.jpg)![](https://developer.varjo.com/assets/uploads/HMD_side.jpg)
![[hand-tracking-xr-4.png]]

Use the following offset (X = right, Y = up, Z = forward, you may need to use a different scale and coordinate system depending on your engine of choice):
```C
Y:      -0.0112 m
Z:       0.0999 m
X tilt:  0°
```

Varjo Base is the software used to control your headset. You can observe what the headset viewer is seeing, quickly access settings and presentation tools, and analyze your project with real-time data. Read more about [Varjo Base](https://varjo.com/use-center/get-to-know-your-headset/using-varjo-base/).
# Unity XR SDK
This page will help you set up and use the Unity XR SDK development environment for Varjo headsets. The XR SDK is a plugin framework for Unity with numerous benefits for developers. Read more about the XR SDK in [Unity's blog article](https://blogs.unity3d.com/2020/01/24/unity-xr-platform-updates) and [XR SDK documentation](https://docs.unity3d.com/Manual/xr-sdk.html).  
  
To learn more about Unity XR development and practices, familiarize yourself with [Unity's XR documentation](https://docs.unity3d.com/Manual/XR.html). Varjo Unity XR SDK plugin is based on Varjo Native SDK.
### Requirements
You will need the following to set up the Unity environment:
- A computer that meets the [system requirements](https://support.varjo.com/hc/en-us/get-started-with-varjo-headsets#system-requirements)
- [Latest Varjo Base](https://developer.varjo.com/downloads#varjo-base)
- Unity 2021.3 LTS or newer with Windows build support
- Unity build set to Windows Standalone 64-bit
- A project using DirectX 11/12 (OpenGL/Vulkan are currently not supported)
- [Varjo Unity XR SDK Plugin](https://developer.varjo.com/downloads#unity-developer-assets)
- A Varjo headset (optional, simulator can be used for basic compatibility testing)
- For XR-4 compatibility use Varjo Unity XR SDK 3.6.0 or newer
## Getting started
The [Getting started](https://developer.varjo.com/docs/unity-xr-sdk/getting-started-with-varjo-xr-plugin-for-unity) section will help you download and install the Varjo XR plugin for Unity.
### Adding Varjo XR support to a Unity project
To add Varjo XR support to your Unity project, first open an existing project or create a new one using a render pipeline of your choice. See [XR Plugin Compatibility](https://developer.varjo.com/docs/unity-xr-sdk/compatibility) for compatible Unity editor and render pipeline versions.

From the Unity main menu, select **Window** > **Package Manager**.
![](https://developer.varjo.com/assets/uploads/unity-getting-started-1.png)

Click the **+** icon in the top left corner. Select **Add Package from git URL** and enter the URL for the Varjo XR plugin repository: _https://github.com/varjocom/VarjoUnityXRPlugin.git_. If you have a local copy of the XR plugin, you can select **Add Package from disk** instead.
![](https://developer.varjo.com/assets/uploads/unity-getting-started-2.png)

In the **Project Settings** dialog, select the **XR Plugin Management** tab and check **Varjo** in the **Plug-in Providers** list.
![](https://developer.varjo.com/assets/uploads/unity-getting-started-3.png)

The Varjo XR plugin is now enabled in your project. You can modify the plugin settings in the **Project Settings** dialog under the **XR Plug-in Management** tab and **Varjo**.

See [Rendering Settings](https://developer.varjo.com/docs/unity-xr-sdk/rendering-settings-in-varjo-xr-plugin) for a detailed description of the available settings.
![](https://developer.varjo.com/assets/uploads/unity-getting-started-4.png)

If there is only one Camera in the Scene, the Camera is tagged as the Main Camera, and it’s at the root of the hierarchy, you can enable HMD tracking simply by selecting **Game Object** > **XR** > **Convert Main Camera To XR Rig** from the Unity main menu.

For more complex scenes, follow [Unity’s documentation](https://docs.unity3d.com/Manual/configuring-project-for-xr.html) to set up tracking with the XR plug-in framework.
![](https://developer.varjo.com/assets/uploads/unity-getting-started-5.png)
#### HDRP Post Process Settings
Create a new **Volume Profile** and add it to the scene as a **global volume.** Add the following overrides:
- **Exposure** : mode = Fixed (fixed exposure value can be adjusted based on scene)
- **Bloom** : Intensity = 0
- **Ambient Occlusion** : Intensity = 0

![](https://developer.varjo.com/assets/uploads/PostProcessSettings.png)
For further reccommendations on post-processing effects, see [post-processing](https://developer.varjo.com/docs/get-started/Post-processing).
### Unity XR SDK Compatibility
#### Unity version compatibility
The Varjo XR plugin is compatible with Unity 2020.3 or later. All plugin features work with **Unity’s Built-in Render Pipeline**, **High Definition Render Pipeline** (HDRP), and **Universal Render Pipeline** (URP).
#### Cross-platform compatibility
Cross-platform compatibility with other Unity XR SDKs and plugins.

By default, Unity will initialize XR SDKs in alphabetical order. When using multiple XR SDKs, [change the order](https://docs.unity3d.com/Packages/com.unity.xr.management@4.2/manual/EndUser.html#example-modifying-the-loader-list) to prioritize Varjo so that the application does not launch in OpenXR or OpenVR compatibility mode.
##### Example: Modifying the loader list
By default, the XR Plug-in Management UI displays loaders in strict alphabetical order, based on their names. In most scenarios, you don't need to change this order. However, if you need the loaders in a different order, you can modify the loaders list from script like so:
``` java
var generalSettings = XRGeneralSettingsPerBuildTarget.XRGeneralSettingsForBuildTarget(BuildTarget.Standalone);
var settingsManager = generalSettings.Manager;

// Get example loaders as XRLoaders
var fooLoader = new FooLoader() as XRLoader;
var barLoader = new BarLoader() as XRLoader;

// Adding new loaders
// Append the new FooLoader
if (!settingsManager.TryAddLoader(fooLoader))
	Debug.Log("Adding new Foo Loader failed! Refer to the documentation for additional information!");

// Insert the new BarLoader at the start of the list
if (!settingsManager.TryAddLoader(barLoader, 0))
	Debug.Log("Adding new Bar Loader failed! Refer to the documentation for additional information!");

// Removing loaders
if (!settingsManager.TryRemoveLoader(fooLoader))
	Debug.Log("Failed to remove the fooLoader! Refer to the documentation for additional information!");

// Modifying the loader list order
var readonlyCurrentLoaders = settingsManager.activeLoaders;

// Copy the returned read only list
var currentLoaders = new List<XRLoader>(readonlyCurrentLoaders);

// Reverse the list
currentLoaders.Reverse();

if (!settingsManager.TrySetLoaders(currentLoaders))
	Debug.Log("Failed to set the reordered loader list! Refer to the documentation for additional information!");
```

You would most likely place this script in a custom build script, but that isn't required. Regardless of the script's location location, you **should do this as a setup step before you start a build** because the first thing that XR Plug-in Manager does at build time is serialize the loader list to the build target.

**Note:** A new loader that wasn't known at startup can't be added to the loader list at runtime, which causes the modification operation to fail. You can still modify the list during runtime, whether the app runs in Play mode or as a standalone build.

This means that you are able to do the following during runtime:
- Remove loaders from the list of loaders.
- Re-add loaders that were previously removed.
- Reorder the list of loaders.

**Note**: Any operation on the XR Plug-in Manager UI will reset the ordering to the original alphabetical ordering.
##### **OpenXR** (Generic, Oculus, Windows Mixed Reality)
While Unity OpenXR can be used with other headsets, we do not recommend that you use it with Varjo. Make sure to initialize Varjo XR SDK before OpenXR, otherwise the Unity project will run in OpenXR compatibility mode instead of native Varjo mode on Varjo headsets.

When Unity OpenXR is used with Varjo you only get standard OpenXR features. No Varjo extensions, such as quad view or foveated rendering.
##### **OpenVR Unity XR Plugin**
Works with Varjo, but openvr_api.dll must be removed either from Varjo or OpenVR plugin for builds. Note that the OpenVR plugin for Unity supports rendering but not motion controllers. Make sure to initialize Varjo XR SDK before OpenVR, otherwise the Unity project will run in OpenVR compatibility mode instead of native Varjo mode on Varjo headsets.
### Developing without the Varjo headset
On the [Developer tools in Varjo Base](https://developer.varjo.com/docs/get-started/developer-tools-in-varjo-base) page you can find information on how to test your build without the Varjo headset.
