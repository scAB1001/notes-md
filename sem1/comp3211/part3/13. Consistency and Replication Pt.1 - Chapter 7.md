Repeat. 
Goals: understand principles behind consistency and replication Outline:
Outline:
## 13. Consistency and Replication Pt.1 - Chapter 7
### Client-centric consistency models
#### Basic Architecture
#### Monotonic Reads
#### Monotonic Writes
#### Read Your Writes
### Replica management
#### Content Replication
#### Server-Initiated Replica Example
#### Consistency Protocols: Primary-backup Protocol with Remote Writes
#### Consistency Protocols: Primary-backup Protocol with Local Writes
Content:
### Client-centric consistency models
Consider a distrbuted db where only accessed by a notebook which is the front end to your db.
At location A you access the db doing reads and updates.
At location B you continue your work but unless you access the same server as location A, you may detect inconsistencies:
- updates at A may not have been propagated to B
- you may be reading new entries than the ones available at A
- updates may eventually conflict with A's
All you want is a db that appears consistent to you, where entries updated/read at A, are in B the way you left them in A.

Data-centric consistency models aim at providing a systemwide consistent
view on a data store. An important assumption is that concurrent processes
may be simultaneously updating the data store, and that it is necessary to
provide consistency in the face of such concurrency. For example, in the case
of object-based entry consistency, the data store guarantees that when an
object is called, the calling process is provided with a copy of the object that
reflects all changes to the object that have been made so far, possibly by other
processes. During the call, it is also guaranteed that no other process can
interfere, that is, mutual exclusive access is provided to the calling process.
Being able to handle concurrent operations on shared data while maintain-
ing strong consistency is fundamental to distributed systems. For performance
reasons, strong consistency may possibly be guaranteed only when processes
use mechanisms such as transactions or synchronization variables. Along the
same lines, it may be impossible to guarantee strong consistency, and weaker
forms need to be accepted, such as causal consistency in combination with
eventual consistency.
In this section, we take a look at a special class of distributed data stores.
The data stores we consider are characterized by the lack of simultaneous
updates, or when such updates happen, it is assumed that they can be
relatively easily resolved. Most operations involve reading data. These data
stores offer a weak consistency model, such as eventual consistency. By
introducing special client-centric consistency models, it turns out that many
inconsistencies can be hidden in a relatively cheap way
#### Basic Architecture
![[client-centric-arch.png]]
Provides guarantees for a single client concerning the consistency
of accesses to a data store by that client
• No guarantees are given concerning concurrent accesses by
different clients.
• If P1 modifies data that is shared with P2 but which is stored at a
different location, write-write conflicts may easily be created.

$x_i$ denotes the version of data item $x$, $L_k$ denotes the local store $k$.
$$\begin{align}
W_1(x_2) \text{ is the write op by } P_1 \text{, leads to version } x_2 \text{ of } x \\
W_1(x_i;x_j) \text{ indicates } P_1 \text{ produces version } x_j \text{ based on previous } x_i \\
W_1(x_i;x_j) \text{ indicates } P_1 \text{ produces version } x_j \text{ concurrently to } x_i
\end{align}$$
#### Monotonic Reads (MRs)
If a process reads the value of data item x, any successive read op on x by that process will always return that same or most recent value.

In other words, monotonic-read consistency guarantees that once a process
has seen a value of x, it will never see an older version of x.

The read ops performed by a single process P at two different local copies of the same data store. a) A monotonic read consistent data store b) A data store that does not provide monotonic reads.
(**Example1**) a distributed e-mail database
![[monotonic-read-ex-1.png]]
• W2(x1|x2) at L2 is known to produce a version that does not follow from x1
• Consequence, P1’s read operation at L2 is known not to include the effect of the
write operations when it performed R1(x1) at location L1.

(**Example2**) Automatically reading you personal calnedar updates from diff servers.
MRs guarantees that the user sees all updates, no matter which automatic read takes place. 

(**Example3**) Reading (no modification) incoming mail while you are mobile. Each time you connect to a diff e-mail server, that server fetches (at least) al the updates from the server you previously visited.
#### Monotonic Writes (MWs)
In many situations, it is important that write operations are propagated in
the correct order to all copies of the data store. This property is expressed
in monotonic-write consistency. In a monotonic-write consistent store, the
following condition holds:
A write op by a process on a data item x is completed before any successive write op on x by the same process.

**(EXAMPLE 1)**
![[monotonic-write-ex1.png]]
a) A MW consistent data store. b) A data store that is not MW consistent.
c) Non MW consistent as WS(x1|x2) and WS(x1|x3).
d) MW consistent as WS(x1;x3) although x1 has overwritten x2.

**(EXAMPLE 2)** Updating a program at server S2 and ensuring all compilation and link dependant components are also on S2.

**(EXAMPLE 3)** Maintaing versions of replicated files in the correct order everywhere (propagate the prev version to the server where the newest version is)
#### Read Your Writes (RYWs)
The effect of a write op by a process on data item x will always be seen by a successive read op on x by the same process.
In other words, a write operation is always completed before a successive read
operation by the same process, no matter where that read operation takes
place.
**(EXAMPLE 1)**
a) A data sttore that provides RYW consistency. b) A data store that doesn't.
![[read-your-write-consistency-1.png]]
(b) Effects of previous write operation by P1 have not been propagated to L2 at the
time x2 was produced
• P1 reads x2: will not see the effects of its own write operation at L1
**(EXAMPLE 2)** Updating your web page and guaranteeing that your web browser shows the newest version instead of its cached copy. READING the actual new one.
### Replica management
A key issue for any distributed system that supports replication is to decide
where, when, and by whom replicas should be placed, and subsequently
which mechanisms to use for keeping the replicas consistent. The placement
problem itself should be split into two subproblems: that of placing replica
servers, and that of placing content. The difference is a subtle one and the two
issues are often not clearly separated. Replica-server placement is concerned
with finding the best locations to place a server that can host (part of) a
data store. Content placement deals with finding the best servers for placing
content. Note that this often means that we are looking for the optimal
placement of only a single data item. Obviously, before content placement can
take place, replica servers will have to be placed first.

Figure out what the best K places are out of N locations.
- Select best out of N-K for which the **avg distance to clients is minimal** Then choose the next best server. The first choice minimised the avg distance to all clients. *Computationally expensive*.
- Select the Kth largest **autonomous system** and place a server at the best-connected host. *Computationally expensive*.
- Position nodes in a d-dimensional geometric space, where distance reflects latency. Identify the K regions with the highest density and place a server in every one. *Computationall cheap*!
#### Content Replication
(DISTINGUISH DIFFERENT PROCESS) A process is capable of hosting a replica of an obj/data.
- **Permanent replicas**: Process/machine always having a replica
- **Server-initiated replica**: Process that can dynamically host a replica on request of another server in the data store.
- **Client-initiated replica**: Process that can dynamically host a replica on request of a client (*client cache*).
![[replica-rings.png]]
*When it comes to content replication and placement, three different types of
replicas can be distinguished logically organized*
#### Server-Initiated Replicas
In contrast to permanent replicas, server-initiated replicas are copies of a data
store that exist to enhance performance, and created at the initiative of the
(owner of the) data store. 

To provide optimal facilities such hosting services can dynamically replicate files to servers where those files are needed to enhance performance, that is, close to demanding (groups of) clients. Given that the replica servers are already in place, deciding where to place content is not that difficult. 

The algorithm is designed to support Web pages for which reason it assumes that updates are relatively rare compared to read requests. Using files as the unit of data, the algorithm takes two issues into account. 
- First, replication can take place to reduce the load on a server. 
- Second, specific files on a server can be migrated or replicated to servers placed in the proximity of clients that issue many requests for those files. In the following, we concentrate only on this second issue. Each server keeps track of access counts per file, and where access requests come from. 

**(EXAMPLE)** Web server placed in New York can handle incoming requests easily,
but a sudden burst of requests come in from an unexpected location far from the server. In that case, it may be worthwhile to install a number of temporary replicas in regions where those requests are coming from.
A client C enters the service, it does so through a server close to it. If client C1 and client C2 share the same closest server P, all access requests for file F at server Q from C1 and C2 are jointly registered at Q as a single access count cntQ(P, F).
![[server-initiated-replica.png]]
- Keep track of access counts per file, aggregated by cosnidering server closest to requesting clients.
- If no. accesses drops below threshold D, drop the file,
- exceeds threshold R, replicate file, sits betweem D and R then migrate the file.
#### Consistency Protocols: Primary-backup Protocol with remote writes
Primary-based protocols
In practice, we see that distributed applications generally follow consistency
models that are relatively easy to understand. These models include those for
bounding staleness deviations, and to a lesser extent also those for bounding
numerical deviations. When it comes to models that handle consistent order-
ing of operations, sequential consistency, notably those in which operations
can be grouped through locking or transactions are popular.
As soon as consistency models become slightly difficult to understand for
application developers, we see that they are ignored even if performance could
be improved. The bottom line is that if the semantics of a consistency model
are not intuitively clear, application developers will have a hard time building
correct applications. Simplicity is appreciated (and perhaps justifiably so).
In the case of sequential consistency, it turns out that primary-based
protocols prevail. In these protocols, each data item x in the data store has
an associated primary, which is responsible for coordinating write operations
on x. A distinction can be made as to whether the primary is fixed at a
remote server or if write operations can be carried out locally after moving
the primary to the process where the write operation is initiated.

The simplest primary-based protocol that supports replication is the one in
which all write operations need to be forwarded to a fixed single server.
Read operations can be carried out locally. Such schemes are also known
as **primary-backup protocols** or **remote-write protocols**.
**(EXAMPLE1)** Applied in distributed dbs and file systems that require a high degree of fault tolerance. Replicas are often placed on the same LAN.

**(EXAMPLE2)** 
A process wanting to perform a write operation on data item x, forwards that operation to the primary server for x. The primary performs the update on its local copy of x, and subsequently forwards the update to the backup servers. Each backup server performs the update as well, and sends an acknowledgment back to the primary (not shown). When all backups have updated their local copy, the primary sends an acknowledgment back to the initial process.
![[primary-bakcup-remote-write-prot.png]]
##### Performance
A potential performance problem with this scheme is that it may take a relatively long time before the process that initiated the update is allowed to continue. In effect, an update is implemented as a blocking operation. An alternative is to use a nonblocking approach. As soon as the primary has updated its local copy of x, it returns an acknowledgment. After that, it tells the backup servers to perform the update as well. Nonblocking primary- backup protocols are discussed in [Budhiraja and Marzullo, 1992]. The main problem with nonblocking primary-backup protocols has to do with fault tolerance. In a blocking scheme, the client process knows for sure that the update operation is backed up by several other servers. This is not the case with a nonblocking solution. The advantage, of course, is that write operations may speed up considerably. Primary-backup protocols provide a straightforward implementation of sequential consistency, as the primary can order all incoming writes in a globally unique time order. Evidently, all processes see all write operations in the same order, no matter which backup server they use to perform read operations. Also, with blocking protocols, processes will always see the effects of their most recent write operation (note that this cannot be guaranteed with a nonblocking protocol without taking special measures).
#### Consistency Protocols: Primary-backup Protocol with Local Writes
A variant of primary-backup protocols is one in which the primary copy
migrates between processes that wish to perform a write operation. As before,
whenever a process wants to update data item x, it locates the primary copy of
x, and subsequently moves it to its own location.

**(EXAMPLE1)** Mobile computing in disconnected mode (ship all relevant files to user before disconnecting and update later).

**(EXAMPLE2)** 
![[primary-bakcup-local-write-prot.png]]
The main advantage of this approach is that multiple, successive write operations can be carried out locally, while reading processes can still access their local copy. However, such an improvement can be achieved only if a nonblocking protocol is followed by which updates are propagated to the replicas after the primary has finished with locally performing the updates. This primary-backup local-write protocol can also be applied to mobile computers that are able to operate in disconnected mode. Before disconnect- ing, the mobile computer becomes the primary server for each data item it expects to update. While being disconnected, all update operations are carried out locally, while other processes can still perform read operations (but no updates). Later, when connecting again, updates are propagated from the primary to the backups, bringing the data store in a consistent state again. As a last variant of this scheme, nonblocking local-write primary-based protocols are also used for distributed file systems in general. In this case, there may be a fixed central server through which normally all write operations take place, as in the case of remote-write primary backup. However, the server temporarily allows one of the replicas to perform a series of local updates, as this may considerably speed up performance. When the replica server is done, the updates are propagated to the central server, from where they are then distributed to the other replica servers.