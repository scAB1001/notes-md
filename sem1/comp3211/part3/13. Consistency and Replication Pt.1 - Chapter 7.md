Repeat. 
Goals: understand principles behind consistency and replication Outline:
Outline:
## 13. Consistency and Replication Pt.1 - Chapter 7
### Client-centric consistency models
#### Basic Architecture
#### Monotonic Reads
#### Monotonic Writes
#### Read Your Writes
### Replica management
#### Content Replication
#### Server-Initiated Replica Example
#### Consistency Protocols: Primary-backup Protocol Example
#### Consistency Protocols: Primary-backup Protocol with Local Writes
Content:
### Client-centric consistency models
Consider a distrbuted db where only accessed by a notebook which is the front end to your db.
At location A you access the db doing reads and updates.
At location B you continue your work but unless you access the same server as location A, you may detect inconsistencies:
- updates at A may not have been propagated to B
- you may be reading new entries than the ones available at A
- updates may eventually conflict with A's
All you want is a db that appears consistent to you, where entries updated/read at A, are in B the way you left them in A.

Data-centric consistency models aim at providing a systemwide consistent
view on a data store. An important assumption is that concurrent processes
may be simultaneously updating the data store, and that it is necessary to
provide consistency in the face of such concurrency. For example, in the case
of object-based entry consistency, the data store guarantees that when an
object is called, the calling process is provided with a copy of the object that
reflects all changes to the object that have been made so far, possibly by other
processes. During the call, it is also guaranteed that no other process can
interfere, that is, mutual exclusive access is provided to the calling process.
Being able to handle concurrent operations on shared data while maintain-
ing strong consistency is fundamental to distributed systems. For performance
reasons, strong consistency may possibly be guaranteed only when processes
use mechanisms such as transactions or synchronization variables. Along the
same lines, it may be impossible to guarantee strong consistency, and weaker
forms need to be accepted, such as causal consistency in combination with
eventual consistency.
In this section, we take a look at a special class of distributed data stores.
The data stores we consider are characterized by the lack of simultaneous
updates, or when such updates happen, it is assumed that they can be
relatively easily resolved. Most operations involve reading data. These data
stores offer a weak consistency model, such as eventual consistency. By
introducing special client-centric consistency models, it turns out that many
inconsistencies can be hidden in a relatively cheap way
#### Basic Architecture
![[client-centric-arch.png]]
Provides guarantees for a single client concerning the consistency
of accesses to a data store by that client
• No guarantees are given concerning concurrent accesses by
different clients.
• If P1 modifies data that is shared with P2 but which is stored at a
different location, write-write conflicts may easily be created.

$x_i$ denotes the version of data item $x$, $L_k$ denotes the local store $k$.
$$\begin{align}
W_1(x_2) \text{ is the write op by } P_1 \text{, leads to version } x_2 \text{ of } x \\
W_1(x_i;x_j) \text{ indicates } P_1 \text{ produces version } x_j \text{ based on previous } x_i \\
W_1(x_i;x_j) \text{ indicates } P_1 \text{ produces version } x_j \text{ concurrently to } x_i
\end{align}$$
#### Monotonic Reads (MRs)
If a process reads the value of data item x, any successive read op on x by that process will always return that same or most recent value.

In other words, monotonic-read consistency guarantees that once a process
has seen a value of x, it will never see an older version of x.

The read ops performed by a single process P at two different local copies of the same data store. a) A monotonic read consistent data store b) A data store that does not provide monotonic reads.
(**Example1**) a distributed e-mail database
![[monotonic-read-ex-1.png]]
• W2(x1|x2) at L2 is known to produce a version that does not follow from x1
• Consequence, P1’s read operation at L2 is known not to include the effect of the
write operations when it performed R1(x1) at location L1.

(**Example2**) Automatically reading you personal calnedar updates from diff servers.
MRs guarantees that the user sees all updates, no matter which automatic read takes place. 

(**Example3**) Reading (no modification) incoming mail while you are mobile. Each time you connect to a diff e-mail server, that server fetches (at least) al the updates from the server you previously visited.
#### Monotonic Writes (MWs)
In many situations, it is important that write operations are propagated in
the correct order to all copies of the data store. This property is expressed
in monotonic-write consistency. In a monotonic-write consistent store, the
following condition holds:
A write op by a process on a data item x is completed before any successive write op on x by the same process.

**(EXAMPLE 1)**
![[monotonic-write-ex1.png]]
a) A MW consistent data store. b) A data store that is not MW consistent.
c) Non MW consistent as WS(x1|x2) and WS(x1|x3).
d) MW consistent as WS(x1;x3) although x1 has overwritten x2.

**(EXAMPLE 2)** Updating a program at server S2 and ensuring all compilation and link dependant components are also on S2.

**(EXAMPLE 3)** Maintaing versions of replicated files in the correct order everywhere (propagate the prev version to the server where the newest version is)
#### Read Your Writes (RYWs)
The effect of a write op by a process on data item x will always be seen by a successive read op on x by the same process.
In other words, a write operation is always completed before a successive read
operation by the same process, no matter where that read operation takes
place.
**(EXAMPLE 1)**
a) A data sttore that provides RYW consistency. b) A data store that doesn't.
![[read-your-write-consistency-1.png]]
(b) Effects of previous write operation by P1 have not been propagated to L2 at the
time x2 was produced
• P1 reads x2: will not see the effects of its own write operation at L1
**(EXAMPLE 2)** Updating your web page and guaranteeing that your web browser shows the newest version instead of its cached copy. READING the actual new one.
### Replica management
A key issue for any distributed system that supports replication is to decide
where, when, and by whom replicas should be placed, and subsequently
which mechanisms to use for keeping the replicas consistent. The placement
problem itself should be split into two subproblems: that of placing replica
servers, and that of placing content. The difference is a subtle one and the two
issues are often not clearly separated. Replica-server placement is concerned
with finding the best locations to place a server that can host (part of) a
data store. Content placement deals with finding the best servers for placing
content. Note that this often means that we are looking for the optimal
placement of only a single data item. Obviously, before content placement can
take place, replica servers will have to be placed first.

Figure out what the best K places are out of N locations.
- Select best out of N-K for which the **avg distance to clients is minimal** Then choose the next best server. The first choice minimised the avg distance to all clients. *Computationally expensive*.
- Select the Kth largest **autonomous system** and place a server at the best-connected host. *Computationally expensive*.
- Position nodes in a d-dimensional geometric space, where distance reflects latency. Identify the K regions with the highest density and place a server in every one. *Computationall cheap*!
#### Content Replication
(DISTINGUISH DIFFERENT PROCESS) A process is capable of hosting a replica of an obj/data.
- **Permanent replicas**: Process/machine always having a replica
- **Server-initiated replica**: Process that can dynamically host a replica on request of another server in the data store.
- **Client-initiated replica**: Process that can dynamically host a replica on request of a client (*client cache*).
![[replica-rings.png]]
*When it comes to content replication and placement, three different types of
replicas can be distinguished logically organized*
#### Server-Initiated Replicas
In contrast to permanent replicas, server-initiated replicas are copies of a data
store that exist to enhance performance, and created at the initiative of the
(owner of the) data store. 

**(EXAMPLE)** Web server placed in New York can handle incoming requests easily,
but a sudden burst of requests come in from an unexpected location far from the server. In that case, it may be worthwhile to install a number of temporary replicas in regions where those requests are coming from.

To provide optimal facilities such hosting services
can dynamically replicate files to servers where those files are needed to enhance
performance, that is, close to demanding (groups of) clients.
Given that the replica servers are already in place, deciding where to place
content is not that difficult. An early case toward dynamic replication of files in
the case of a Web hosting service is described by Rabinovich et al. [1999]. The
algorithm is designed to support Web pages for which reason it assumes that
updates are relatively rare compared to read requests. Using files as the unit of
data, the algorithm works as follows.
The algorithm for dynamic replication takes two issues into account. First,
replication can take place to reduce the load on a server. Second, specific files on
a server can be migrated or replicated to servers placed in the proximity of clients
that issue many requests for those files. In the following, we concentrate only on
this second issue. We also leave out a number of details, which can be found in
[Rabinovich et al., 1999].
Each server keeps track of access counts per file, and where access requests
come from. In particular, when a client C enters the service, it does so through
a server close to it. If client C1 and client C2 share the same closest server P, all
access requests for file F at server Q from C1 and C2 are jointly registered at Q as
a single access count cntQ(P, F).
![[server-initiated-replica.png]]
- Keep track of access counts per file, aggregated by cosnidering server closest to requesting clients.
- If no. accesses drops below threshold D, drop the file,
- exceeds threshold R, replicate file, sits betweem D and R then migrate the file.

#### Consistency Protocols: Primary-backup Protocol Example
#### Consistency Protocols: Primary-backup Protocol with Local Writes