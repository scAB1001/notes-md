Monday 29/09/2025

---
# Old
#### Module Objectives
Ability to:
- identify the paradigms that determine the requirements, capabilities and performance of  distributed systems
- design a high-level framework of a distributed system based on the Internet architecture / advanced architectures
- use a range of middleware tools to implement a distributed system
- reason about the significance of the new directions that distributed systems are taking.

Use proscribed textbook and Computer Networking book (K. Ross). 
This is the module to get good at for job role next year. 

For this week, read the proscribed book and revise the following
1. Sockets programming
2. Multi-threading
3. Network programming
#### Course Outline
**Part 1**
– Architectures
– Middleware
– Distributed object technology, communication
– Service Oriented Architectures and Web services (REST)
– Micro-services and nano-services
– Server-less architectures

**Part 2**
– Supporting services: naming, directory and discovery services, synchronisation, consistency, replication, fault-tolerance

**Part 3**
– Cloud computing, Virtualisation, Edge computing

Goals
• Understand what a distributed system (DS) is
• Place distributed systems in a realistic context through examples
• Motivate the benefits of resource sharing
• Gain an understanding of some challenges as they apply to distributed systems

Overview:
• Definition of a DS
• Goals and challenges
• Sharing of resources
• Transparency
• Openness
• Scalability
• Summary
#### **Definition of a Distributed System** (1)
A distributed system is:
A collection of autonomous computing elements (nodes) that appears to its users as a single coherent system [TvS2024]

Nodes: Hardware devices and software processes (e.g. computer, car, robot). These nodes need to collaborate.
An autonomous node has its own notion of time. Every node has its own clock. 
There is no global clock: this is needed for synchronisation.

An autonomous node also needs to communicate to other nodes: this provides network support.
#### **Definition of a Distributed System** (2)
A system in which components located at networked computers communicate and coordinate their actions only by passing messages [CDKB2017]

The collection of nodes as a whole operates the same –no matter where, when or how the interaction takes places between the user and that system.

E.g. An end-user cannot tell where the computation is taking place
Where data is stored exactly should be irrelevant to an application
Whether or not data has been replicated is completely unknown/hidden. (Distribution transparency)

“You know you have a DS when the crash of a computer you’ve never heard of stops you from getting any work done” – Leslie Lamport
##### **What’s the difference between a distributed and decentralised system?**
Decentralised → Distributed
![[centralised-decentralised-distributed-system.png]]
Adding 1 link between 2 nodes? Adding k>0 nodes?

**Realising distributed systems: Two views**
•**Integrative** view: connecting existing networked computer systems into a larger a system
•**Expansive** view: an existing networked computer system is extended with additional computers

A **decentralised** system is a networked computer system in which processes and resources are **necessarily** spread across multiple computers. (typically integrative view)

A **distributed** system is a networked computer system in which processes and resources are **sufficiently** spread across multiple computers. (typically expansive view)

In a decentralised system, data is normally brought to the high-performance computers that literally train models before they can be used. But when data needs to stay within the perimeter of an organisation (e.g. security reasons), training is brought to the data. The result is known as **federated learning**.

#### Examples of decentralised systems:
**Blockchain (distributed ledger)**
A distributed ledger, blockchain. In this case, we need to deal with the situation that participating parties do not trust each other enough to set up simple schemes for collaboration. 

Instead, what they do is essentially make transactions among each other fully public (and verifiable) by an extend-only ledger that keeps records of those transactions. The ledger itself is fully spread across the participants, and the participants are the ones who validate transactions (of others) before admitting them to the ledger. 

The result is a decentralised system in which processes and resources are, indeed, necessarily spread across multiple computers, in this case due to lack of trust.

**Geographically dispersed  decentralised systems**
Consider systems that are naturally geographically dispersed. This occurs typically with systems in which an actual location needs to be monitored, for example, in the case of a power plant, a building, a specific natural environment, and so on. 

The system, controlling the monitors and where decisions are made, may easily be placed somewhere else than the location being monitored. 

One obvious example is monitoring and controlling of satellites, but also more mundane situations as monitoring and controlling traffic, trains, etc. 

Here, the necessity for spreading processes and resources comes from a spatial argument.

**Content Delivery Networks (CDNs)**
An entirely different type of distributed system is formed by the collection of CDNs. 
What it boils down to, is that the content of an actual Website, is copied and spread across various servers of the CDN. 

When visiting a Website, the user is transparently redirected to a nearby server that holds all or part of the content of that Website. 

The choice for which server to direct a user to may depend on many things, but surely when dealing with streaming content, a server is selected for which good performance in terms of latency and bandwidth can be guaranteed. 

The CDN dynamically ensures that the selected server will have the required content readily available, as well as update that content when needed, or remove it from the server when there are no or very few users to service there. 

Meanwhile, the user knows nothing about what is going on behind the scenes (which, again, is a form of distribution transparency). 

We also see in this example, that content is not copied to all servers, yet only to where it makes sense, that is, sufficiently, and for reasons of performance.

CDNs also copy content to multiple servers to provide high levels of dependability.

**Network-Attached Storage (NAS)**
As a final, much smaller distributed system, consider a setup based on a NAS. For domestic use, a typical NAS consists of 2–4 slots for internal hard disks. 

The NAS operates as a file server: it is accessible through a (generally wireless) network for any authorised device, and as such can offer services like shared storage, automated backups, streaming media, and so on. 

The NAS itself can best be seen as a single computer optimised for storing files, and offering the ability to easily share those files. The latter is important, and together with multiple users, we essentially have a setup of a distributed system. 

The users will be working with a set of files that are locally (i.e., from their laptop) easily accessible (in fact, seemingly integrated into the local file system), while also directly accessible by and for other users. 

Again, where and how the shared files are stored is hidden (i.e., the distribution is transparent). Assuming that sharing files is the goal, then we see that indeed a NAS can provide sufficient spreading of processes and resources.
#### Challenges for Distributed Systems
• Architecture: common organisations, common styles
• Process: what kind of processes, and their relationships
• Communication: facilities for exchanging data
• Coordination: application-independent algorithms
• Naming: how do you identify resources?
• Consistency and replication: performance requires of data, which need to be the same
• Fault tolerance: keep running in the presence of partial failures
• Security: ensure authorised access to resources

What Do We Want to Achieve?
• Support sharing of resources: File sharing on p2p, shared web hosting, shared cloud-based storage
• **Distribution transparency**
	The phenomenon by which a distributed system attempts to hide the fact that its processes and resources are physically distributed across multiple computers, possibly separated by large distances.
	This is handled through many different techniques in a layer between applications and operating systems: a middleware layer: Multiple computers with varying OS will access the same interface and will eventually arrive at the same network.

Distributed and decentralized systems suffer almost continuously from partial failures: some process or resource, somewhere at one of the participating computers, is not operating according to expectations.

Discovering that failure may actually take some time, while also such failures are preferably masked (i.e., they go unnoticed for users and applications), including the recovery from failures.

• Much related to partial failures is the fact that in many networked computer systems, participating nodes, processes, resources, and so on, come and go. This makes these systems highly dynamic, in turn requiring forms of automated management and maintenance, in turn
increasing the complexity.

• The fact that distributed and decentralized systems are networked, used by many users and applications, and often cross multiple administrative boundaries, makes them particularly vulnerable to security attacks.

Therefore, understanding these systems and their behaviour, requires that we understand how they can be, and are secured. Unfortunately, understanding security is not that easy.
#### Middleware is the OS of DS
Its the glue between apps and OS, extending over multiple machines; contains commonly used components and functions that need not be implemented by applications separately

Limited transparency: network services, e.g. sockets are directly visible to app dev
Significant amount of explicit code needed to establish comms between client and server (TCP/IP, UDP/IP)

Would be nice if …
– Client and server designed and implemented as if they were components of a centralised system
– Use of sockets could be hidden from programmer
• Openness
• Scalability

The process perspective is all about understanding the different forms of processes that occur in distributed systems, be they threads, their virtualisation of hardware processes, clients, servers, and so on. Processes form the software backbone of distributed systems, and their understanding is essential for understanding distributed systems.

Obviously, with multiple computers at stake, communication between processes is essential. The communication perspective concerns the facilities that distributed systems provide to exchange data between processes. It essentially entails mimicking procedure calls across multiple computers, high-level message passing with a wealth of semantic options, and various sorts of communication between sets of processes.

• To make distributed systems work, what happens under the hood on top of which applications are executed, is that processes coordinate things. They jointly coordinate, for example, to compensate for the lack of a global clock, for realising mutual exclusive access to shared resources, and so on. The coordination perspective describes a number of fundamental coordination tasks that need to be carried out as part of most distributed systems.

• To access processes and resources, we need naming. In particular, we need naming schemes that, when used, will lead to the process, resources, or whatever other type of entity that is being named. As simple as this may seem, naming not only turns out to be crucial in distributed systems, there are also many ways in which naming is supported. The naming perspective focuses entirely on resolving a name to the access point of the named entity.

• A critical aspect of distributed systems is that they perform well in terms of efficiency and in terms of dependability. The key instrument for both aspects is replicating resources. The only problem with replication is that updates may happen, implying that all copies of a resource need to be updated as well. It is here, that keeping up the appearance of a non-distributed system becomes challenging. The consistency and replication perspective essentially concentrates on the trade-offs between consistency, replication, and performance.

• We already mentioned that distributed systems are subject to partial failures. The perspective of fault tolerance dives into the means for masking failures and their recovery. It has proven to be one of the toughest perspectives for understanding distributed systems, mainly because there are so many trade-offs to be made, and also because completely masking failures and their recovery is provably impossible.

• As also mentioned, there is no such thing as a non-secured distributed system. The security perspective focuses on how to ensure authorised access to resources. To that end, we need to discuss trust in distributed systems, along with authentication, namely verifying a claimed identity. The security perspective comes last, yet later in this chapter we shall discuss a few basic instruments that are needed to understand the role of security in the previous perspectives.
 
**Resource sharing**
There are many reasons for wanting to share resources. One obvious reason is that of economics. For example, it is cheaper to have a single high-end reliable storage facility be cheaper than having to buy and maintain storage for each user separately.

Connecting users and resources also makes it easier to collaborate and exchange information, as is illustrated by the success of the Internet with its simple protocols for exchanging files, mail, documents, audio, and video. The connectivity of the Internet has allowed geographically widely dispersed groups of people to work together by all kinds of groupware, that is, software for collaborative editing, teleconferencing, and so on, as is illustrated by multinational software-development companies that have outsourced much of their code production to Asia.

**Degree of distribution transparency**
Aiming for distribution transparency may be a nice goal when designing and implementing distributed systems, but that it should be considered together with other issues such as performance and comprehensibility. The price for achieving full transparency may be surprisingly high.
# New
## 1. Introduction to Distributed Systems Pt.1 - *Chapter 1*
### Definition of a Distributed System (DS)
> (1) A collection of **autonomous computing elements (nodes)** that appears to its **users as a single coherent system**.

**Nodes** are hardware devices or software processes (computers, sensors) that collaborate. **Autonomy** means each node has its own **local clock**; there is no global clock, making synchronization a core challenge. Nodes must **communicate via a network**.

> (2) A system in which components located at **networked computers** **communicate** and coordinate their actions only by **passing messages**.

The collection operates uniformly regardless of *where, when, or how* the user interacts with it. This **hides distribution** from the user (e.g., they don't know where computation happens or data is stored).

**(EXAMPLEs) 
- The **Internet**, the **World Wide Web (WWW)**, **cloud computing** platforms, **cellular networks**.
- **Distributed Applications** built on top: Netflix, Spotify, online banking.
- *"You know you have a DS when the crash of a computer you’ve never heard of stops you from getting any work done" – Leslie Lamport*
#### Distributed versus Decentralised Systems
Two perspectives exist:
1.  **Integrative View:** Connecting existing systems into a larger one.
2.  **Expansive View:** Extending an existing system with more computers.
![[centralised-decentralised-distributed-system.png\|400]]
> A **Distributed System** is a networked computer system in which processes and resources are **sufficiently** spread across multiple computers (expansive view). The distribution is done for practical reasons like performance, but could theoretically be centralised.

> A **Decentralised System** is a networked computer system in which processes and resources are **necessarily** spread across multiple computers (integrative view). The distribution is fundamental to its operation.

When data needs to stay within the perimeter of an org (e.g. security reasons), training is brought to the data. The result is known as **federated learning**.

**(EXAMPLE 1) Blockchain (Decentralised System)**
A **blockchain** or distributed ledger is decentralised because participating parties **do not trust each other**. Instead of a central authority, transactions are validated by participants and recorded in a public ledger replicated across all nodes. The spread is **necessary** due to the lack of trust.

**(EXAMPLE 2) Geographically Dispersed Monitoring (Decentralised System)**
Systems monitoring power plants, satellites, or traffic are **necessarily geographically dispersed**. The sensors/controllers must be at the physical location, while decision-making systems may be elsewhere. The spread is dictated by **spatial requirements**.

**(EXAMPLE 3) Content Delivery Network (CDN) (Distributed System)**
A CDN **copies website content** to servers worldwide. A user is redirected to a nearby server for better performance. Content is replicated **sufficiently** (where it makes sense for latency/load), not necessarily everywhere. The distribution is for **performance and dependability**.

**(EXAMPLE 4) Network-Attached Storage (NAS) (Distributed System)**
A domestic NAS acts as a central file server for multiple users. Files are stored in one place but appear integrated into each user's local system. Resources are **sufficiently** spread to enable easy sharing, but could be more centralised. The distribution provides **transparent access**.

### Goals and challenges & Sharing of resources
A DS aims for four primary goals:
(1) **Sharing of Resources** (2) **Distribution Transparency** (3) **Openness** (4) **Scalability**

Key challenges to achieve these goals involve:
*   **Architecture:** Common organisational styles.
*   **Processes:** Their types and relationships.
*   **Communication:** Data exchange facilities (RPC, messaging).
*   **Coordination:** Synchronisation algorithms.
*   **Naming:** Identifying resources uniquely.
*   **Consistency & Replication:** Managing copies of data.
*   **Fault Tolerance:** Handling partial failures.
*   **Security:** Ensuring authorised access.
Sharing resources (storage, compute, data) is economically efficient and facilitates collaboration (e.g., cloud storage, groupware, the Internet itself). It allows geographically dispersed groups to work together seamlessly.
### Transparency
>The phenomenon by which a DS attempts to *hide* that its processes and resources are *physically distributed* across *multiple computers*, possibly separated by large distances.

This is primarily achieved by **middleware**, a software layer that sits between applications and operating systems, masking heterogeneity and distribution. Its the glue *between* apps and OSs, extending over multiple machines; contains commonly used components and functions that need not be implemented by apps separately.
![[middleware-layer-ex.png\|400]]
**(TYPES OF TRANSPARENCY)** Different aspects can be hidden:

| Transparency | Description |
| :--- | :--- |
| **Access** | Hide differences in data representation/access methods. |
| **Location** | Hide where an object is physically located. |
| **Migration** | Hide that an object may move. |
| **Relocation** | Hide that an object may move *while in use*. |
| **Replication** | Hide that multiple copies of an object exist. |
| **Concurrency** | Hide that an object is shared by multiple users. |
| **Failure** | Hide the failure and recovery of an object. |
**Note:** Achieving full transparency can be costly and may conflict with performance or simplicity.
### Openness
> An **open DS** is built from components with well-defined, standard interfaces, allowing them to easily interoperate with components from other systems, supporting extensibility and portability.
![[middleware-openness-ex.png\|200]]
 Open systems rely on agreed-upon **interfaces** and **communication protocols**, allowing services from different vendors or domains to interact.
### Scalability Issues
A DS is scalable if it remains effective when scaled in:
1.  **Size:** Number of users/processes.
2.  **Geography:** Distance between nodes.
3.  **Administrative Domains:** Number of independent managing organizations.

**(SCALING SIZE)** Scalability for the internet was effortless because information is organised hierarchically rather than linearly: $O(\log(n))$. Poor scalability is when the cost of supporting $n$ users is worse than $O(n)$.

**(SCALING GEOGRAPHICALLY - THE LATENCY & BANDWIDTH PROBLEM)**
Techniques that work in a Local Area Network (LAN) often fail in a Wide Area Network (WAN).
*   **Latency:** WAN communication (~100s ms) is **orders of magnitude slower** than LAN communication (~100s µs). Synchronous communication (client blocks for a reply) becomes a major bottleneck.
*   **Bandwidth & Reliability:** WANs have limited bandwidth and are less reliable. Solutions like efficient video streaming designed for LANs fail over WANs.
*   **Discovery:** LANs often use efficient **broadcasting** for service discovery. WANs lack this, requiring scalable, separate directory services.

**(SCALING ADMINISTRATIVELY - THE TRUST & POLICY PROBLEM)**
Expanding across administrative domains (e.g., different companies) introduces:
*   **Conflicting Policies:** Different rules for resource usage, payment, and management.
*   **Security Challenges:**
    *   The DS must **protect itself** from malicious attacks from the new domain.
    *   The new domain must **protect itself** from malicious code or actions originating from the DS (e.g., untrusted downloaded applets).

**Examples:** A scientific **computational grid** spanning universities must enforce access controls. A **peer-to-peer (P2P)** file-sharing network like BitTorrent bypasses administrative control, scaling easily because end-users, not administrators, collaborate to run the system.
### Scaling Techniques
Three fundamental techniques address scalability:
#### (SOLUTION 1) Hiding Communication Latencies
Improve perceived performance by avoiding blocking waits, especially important for **geographic scalability**.
![[hiding-comm-latencies-ex.png\|500]]
*   **Use Asynchronous Communication:** The client sends a request and continues other work, processing the reply later (via callbacks or separate threads).
*   **Move Computation to Client:** Instead of many client-server messages, ship code (e.g., a form-validation script) to the client. The client returns only the final result. This is widely used on the **Web (JavaScript, WebAssembly)**.

#### (SOLUTION 2) Partitioning and Distribution
Split a large component into smaller parts and distribute them across the system.

**(EXAMPLE - DOMAIN NAME SYSTEM (DNS))**
The DNS namespace is partitioned into hierarchical, non-overlapping **zones**. Each zone is managed by a separate **name server**. Resolving a name like `flits.cs.vu.nl` involves querying servers up the hierarchy.
![[zones-dns.png\|300]]
This **distribution** and **decentralised administration** allows DNS to scale to the entire Internet. Lookup time grows **logarithmically**, not linearly, with the number of hosts.

#### (SOLUTION 3) Replication
Create copies of components (data, services) across the DS.
*   **Benefits:** Improves **performance** (load balancing), **availability** (fault tolerance), and can **hide latency** (place copy near user).
*   **The Major Drawback: Consistency.** Keeping all replicas identical requires **global synchronisation** on every update, which is costly and hinders scalability. Often, consistency must be relaxed to achieve scale (e.g., eventual consistency).

### Pitfalls (9)
A common source of complexity in DS design comes from mistaken assumptions:
1.  The network is **reliable**.
2.  The network is **secure**.
3.  The network is **homogeneous**.
4.  The **topology doesn't change**.
5.  **Latency is zero**.
6.  **Bandwidth is infinite**.
7.  **Transport cost is zero**.
8.  There is **one administrator**.
9.  **All clocks are synchronised**.

These properties are **unique challenges of distributed systems** and must be explicitly considered; they do not appear in centralized system design.

**Check of Understanding**
> **Question:** The DNS is a critical, globally scalable distributed system. Explain how its design employs **two** of the three core scaling techniques (Hiding Latency, Partitioning, Replication) to achieve scalability. Provide a specific detail of how DNS implements each chosen technique.
>
> **Answer:**
> DNS employs **Partitioning** and **Replication**.
>
> 1.  **Partitioning (and Distribution):** The DNS namespace is **hierarchically partitioned** into zones (e.g., `.com`, `ac.uk`, `google.com`). Authority for each zone is **delegated** to different, independent name servers. This distributes the management and query load across countless servers worldwide, preventing any single server from becoming a bottleneck. A query for `www.example.ac.uk` is resolved by traversing this hierarchy, contacting different servers at each level.
>
> 2.  **Replication:** Within each zone, multiple **replica name servers** are typically deployed. For example, the `google.com` zone is served by many geographically dispersed servers. This **replication** provides **fault tolerance** (if one fails, others can answer) and **improves performance** via load balancing and reduced latency for users near a replica. DNS clients and intermediate resolvers also **cache** (a form of replication) responses to reduce load on authoritative servers and speed up subsequent lookups.