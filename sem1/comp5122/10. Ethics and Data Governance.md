# 10. ETHICS AND DATA GOVERNANCE 
LEARNING OBJECTIVES AND
To develop your understanding of:
•Why data analytics raises ethical issues (lecture 1)
•Data governance and the legal situation (lecture 2)
•Regulations and data, and the reasons for these
•The relationship between ethical issues and the laws
•Key ethical issues or risks in data science, processing, analysis
•Issues of data quality, bias, privacy, anonymisation
•Ethical issues in the use of data analysis
•Whether responsibility can go ‘backwards’
•“I just generate the knowledge, what others do with it us up to them”
•Depending on time: Q&A
Point of the lectures:
•To help with assessment (clear an immediate obstacle).
• Providing you with guidance to help complete the assessment
•To help your employability (clear future obstacles).
• Reflecting on your role in society as a data scientist; how you ‘add value’ with specialist
skills
• How these determine your wider responsibilities to employers/customers/society
• Employers will like this
•To hopefully offer interesting ideas for reflecting on your studies/practice
## 1. What is Ethics
Learning objectives:
•To gain a general understanding of the purpose of ethical thinking
•Begin to identify why data analytics is a practice that raises ethical
issues

WHAT IS ETHICS?
•As a starting point: ethics is a way of deciding what we should (and should not) do
•Evaluating our actions and choices
•Assessing ethical judgements
•Interrogating the reasoning behind those judgements
•Two goals:
1. Figure out what the right thing to do is (or, what is ok/permissible to do)
2. Figure out why it is right (or ok/permissible)
Hopefully… leading to us act accordingly (following through on that)

Trolley problem example
Seems like we have the following intuition:
-It’s better to pull the lever
Reasoning helps clarify why that seems the best
action:
-It’s morally better to save more lives than fewer
This seems like a good reason (hard to dispute)
When our intuitions and reasons are ‘in sync’:
no problem – what we sense is right also seems
most reasonable / rational to do
So might as well do it

HOW TO CAST DOUBT
Intuition:
-It’s better to pull the lever
Reasoning:
-It’s morally better to save more lives than fewer
Doubt method 1: Critique
the action. Highlight
reasons against
Doubt method 2:
Critique the
reason. Highlight
the problem
implications

What
Why
Q: Are these
reasons
enough to
sway our
intuitions?
Pull the leverDon’t pull the lever
Causing the death
of someone, killing them
Not up to us to intervene
More lives saved =
morally better
Different
reasoning
justifies
different
courses of
action
Doubt method 1: what about
the reasons against?

EXAMPLE 2: FAT
MAN BRIDGE What should you do
A: Push the fat man (kill 1)
B: Don’t push the fat man
(allow 5 to die)
C: Not sure (also allow 5 to
die)
18
EXAMPLE 2: FAT
MAN BRIDGE Push the fat man:
More lives saved = morally better
Don’t push the fat man:
We would be causing the death
of someone, killing them
Not up to us to intervene
19
From a 2006 BBC
Survey:
Push fat man:
26.88%
Don’t:
73.12%
Cross-culturally
consistent
INTUITIO
NS AND
REASONS
Most people have the following intuition:
-It’s better to not push the fat man
Justified by:
-It’s not our place to intervene / cause his death
But in the ‘split tracks’ case we thought that:
-It’s morally better to save more lives than fewer
Was the reason we should intervene (/ kill 1 to
save 5)
What’s going on? Are (most of us) inconsistent,
and therefore irrational?
20
Q: Should we act
against our
intuitions in the
‘split track’ case? Or
in the ‘fat man
bridge’ case?
What
Why
Pull the lever
More lives saved =
morally better
Push the fat man
Puzzle: conflict in intuitions and
reasons Context A: Split tracks Context B: Fat man over bridge
Puzzle: the same reason justifies opposed actions, depending
on contexts
So, why not push the fat man?
If saving lives is not most important…then why pull the lever?
If you are really acting on the
basis of this reason when
pulling the lever:
To be rational, you either:
1. Should push the fat man
2. Interrogate your reasoning
further (this is not enough to
justify pulling it)

Solution 1: Act against
intuitions
Context A Context B
Benefit: Consistency. You’re acting for the reason you judge
most justified, so are in one sense acting rationally
Problem 1: You’re doing things against your moral conscience
Problem 2: Debatable you’re really acting rationally, if you see
that your reasons also justify actions that are obviously wrong

Solution 2: Interrogate our
reasons
More lives saved =
morally better
Benefits of this approach:
- Do not act against our intuitions
(/conscience)
- We learn more about our ethical
processing
- Refine our ‘system’ of ethical
principles
Consider:
What does this capture that seemed reasonable?
What does it need qualifying with?
Does it need adding to? Do not expose others to harm\* UNLESS \*the man on the track is already in some way in harm’s way, whereas the fat man is a bystander, out of harms way
This approach is essentially what doing Ethics is 
End goal: arrive at a reliable set of principles, to guide us where when intuitions are murky Similar to refining a decision-making algorithm

This
approach is
essentially
what doing
Ethics is

### NAVIGATING MURKY ETHICAL ISSUES
Eventually: can reach
judgements on issues
where our intuitions are
murky

More lives saved =
morally better What does this capture that
seemed reasonable?
What does it need qualifying
with?
Does it need adding to?
Do not expose
others to harm/
violate their rights
UNLESS
UNLESS
Do not prolong
unnecessary
suffering
Eventually: can reach
judgements on issues
where our intuitions are
murky
AND/OR Respect others’
autonomous
decisions

### OVERVIEW OF ETHICS
•Basically: ethics is a way of looking at what we should and should not do
•Evaluating and assessing our actions, choices, for how they impact others
•Trying to reach consistency, sound principles for action
•Considers how to uphold people’s moral rights (distinct from legal)
•And their wellbeing (welfare, happiness, quality of life)
•Making sure we have good reasons to justify actions, where either of these are at issue
### ETHICAL CONCEPTS
Thinking through the ethical reasons behind our actions gives rise to
ethical concepts
•fairness (not taking advantage of/hoarding resources for yourself over
others)
•responsibility (living up to an entrusted role, recognising the impacts
your actions can have)
•duty (owing an action to others, based on contract/promise)
•harm / welfare (e.g. whether causing suffering to others)
•Rights (can restrict / require actions from others)
### TECHNOLOGY AND ETHICS
•Warren and Brandeis (1890) – Harvard law
professors made the case for new ‘right to
be let alone’, because of advances in the
printing press (sharing of information), and
photography
•At the time, photographs were slow – they
required someone to sit stock still in very
specific conditions, facing the photographer
(the camera being difficult to set up)

•Previously: unless you agree / are on board with the photo being taken, it’s very
easy to prevent it happening – you just move away
•‘Hit and run’ photographs now possible - taken without your knowledge or
consent, put to any use the photographer sees fit
•Depending on where they found you, could be embarrassing, even dangerous,
for you
Key Point:
Technological progress can impact people’s rights and wellbeing
So technology becomes an ethical issue: need ethical reasoning to navigate
### DATA AND ETHICS
•Being a data scientist, you are in the role of someone who can ‘extract
useful knowledge from data’ (Provost and Fawcett, p.2)
•Exhuming buried/hidden information, patterns, relationships between
variables in data sets
•These might be about particular people (indirectly), categories of people
•So you’re dealing with the knowledge of others
• Key point: with knowledge about others comes the power to affect
them
•New information be used to trace back to those individual people
•An early example of harm resulting from primitive use of datasets:
•Actress Rebecca Schaeffer, murdered by a fan stalker in 1989, Los
Angeles
•Murderer found her home address through motor vehicle licence
records
•Led to a change in the law
•Key point: unpredictable what others can do on the basis of information,
what they can cross reference it with
•Hindsight is a great teacher HTTPS://EN.WIKIPEDIA.ORG/WIKI/REBECCA_SCHAEFFER

•Sets of information about individual
people
•Could be used to trace back to those
individual people
•Could fall into the hands of certain
groups who want to oppress people /
categories of people
HTTPS://PRIVACYINAFRICA.COM/2017/09/06/AFRICAN-GOVERNMENTS-ARE-REQUESTING-MORE-
USER-DATA-FROM-FACEBOOK-GOOGLE-AND-TWITTER-THAN-EVER-BEFORE/
•So much information about all of us now generated. Stored on servers, in
the cloud
•Increasing exponentially; ‘internet of things’
•Is useful: better goods and services, we can generate new knowledge about
people’s behaviour
•Gives data scientists more raw material to analyse, increasing our
knowledge, increasing effectiveness of e.g. business, govt, accuracy of
research
•Also exponentially increasing the ethical risks, unpredictability of potential
harm
What are some of the ethical issues raised by data?
### ASSORTED ISSUES
Usage of data science issues (responsible usage)
Bias baked into toolsBias in interpretations Black box/opacity Control
“Harm to subjects” issues (’caught in the dredging net’)
Privacy Consent Breaches / lax handling
Externalities (what might be on the horizon)
Shaping preferences Sustainability Interpersonal relations Automation and work
## 2. DATA ETHICS AND THE LAW (/REGULATION)
Learning objectives:
•To understand…
•The relationship between ethics and the law (/regulations)
•Key roles in data governance (Data Processor, Controller, Subject)
•Principles of UK-GDPR (2020), DPA (2018)
•Definitions of Personal Data, Special Personal Data

Ethics and law ‘come apart’. Not the same thing
• Some legal obligations are not ethical obligations, eg. exact tax
regime, side of the road to drive on.
• The law is incomplete: not everything unethical should be illegal
(e.g. lying to a friend)
•It is difficult to ‘keep up’ with rapidly advancing technology. Laws
are updated through us realizing different things are right/wrong.
Can’t just look to the law to see what you should do:
•Laws contain ethical concepts: need interpreting via ethical
reasoning

UK-GDPR
Principles:
1. Personal data (PD) must be
processed fairly, lawfully and
transparently
2. Only collected/processed for
explicit and legitimate
purpose(s)
Fairly and
transparently
Legitimate purposes
“conduct that falls short of the
standards expected of a person
where a duty of care is owed and
which causes foreseeable damage
to another person.” Peter De Cruz,
Nutshells Medical Law.
Negligence = Falls short of
standards expected
Duty of care

‘Just following the law’ is
not a sensible policy:
- Some legal acts are still
unethical
- Sometimes laws are
unethical/incomplete/ne
ed updating
- To be able to follow laws
requires you think about
the ethics of situations
### ETHICS AND LAW
The function of ethics:
Determine what we should do, what moral (not legal) rights we have
Based on how our actions impact others’ moral rights and wellbeing
The function of law (ideally):
Provide guide rails to restrict behavior that could lead to harm
Clarify consequences of that behavior / contain the ‘fallout’ from it (no vengeance spirals)
Protect rights of individuals from powerful others (/the state)
Reassure citizens about participating in a society, accessing goods/services
Implement society’s ethical viewpoint, updated based on results of ethical reasoning
### DATA PROTECTION AND THE LAW
To track you/access your identity, what sources of data could someone
look at? •Search histories
•Automatic Number Plate Recognition
•CCTV
•Medical records
•RFID – in shops / cashpoints etc
•WiFi / Bluetooth / mobile towers
•Google and Apple location histori
With everyone leaving an extensive digital ‘exhaust trail’, this leaves
people open to harm and exploitation
•Data science: ‘extract[ing] useful knowledge from data’ (Provost and
Fawcett, p.2)
•Maybe about / or relating to people
Potentially harmful consequences for individuals and groups
#### A HISTORICAL EXAMPLE
•From primitive datasets:
•Actress Rebecca Schaeffer, murdered by a fan stalker in 1989, Los
Angeles
•Murderer hired PI who found her home address through vehicle licence
database
•Led to a change in US law (Driver’s Privacy Protection Act), preventing
such releases
•Key point: unpredictable what others will want to do with data
•and how they will ‘link’ information known with new information
#### CONTEMPORARY EXAMPLE
•Sets of information about individual
people
•Could be used to trace back to those
individual people
•Could fall into the hands of certain
groups who want to oppress people /
categories of people
#### MODERN data
Modern times, we have exponentially increased:
Ease of collection / generation (many more devices spilling out data)
Ease of storage (greater hard drive space, cloud storage)
Sophistication of processing (faster processors, ability to find out new information from
datasets)
Leading to…
Unforeseen uses (as we can learn more from data, the more we can use it for, for good or
bad)
The law’s functions (see earlier slide) seem to be needed
### Now, in the UK
UK DPA (2018) UK-GDPR (2020) is
based on the EU GDPR (2018)
Can’t give a thorough breakdown
of it, but there is an emphasis on:
Data controllers and data
processors need to respect
privacy and seek consent from
data subjects
…not assume consent.
Data subjects have more power:
e.g. the right to be forgotten
This Photo by Unknown Author is licensed under CC BY-SA
### SOME KEY DEFINITIONS
Data Controller: determines the purposes
and means of processing personal data
Data Processor: responsible for processing
personal data on behalf of a controller
Data Subject: an individual who is the
subject of personal data
Information Commissioner: The person or
group who is responsible for enforcing
the GDPR/DPA. In the UK that is ICO
(Information Commissioner's Office)
These two definitions are
distinguished so that the
right moral and legal
responsibilities can be
allocated. However, they
are not mutually exclusive.
That is, it is possible to be
both.
#### Examples
Q: IN THESE EXAMPLES, WHO IS THE CONTROLLER AND WHO THE PROCESSOR?
Definitions
- Data Controller: A person who determines the purposes for which and the manner in which any personal data are, or are to be, processed.
- Data Processor: Any person (other than an employee of the data controller) who processes the data on behalf of the data controller.

Example 1: A government department sets up a database of information about every child in the country. It does this in partnership with local councils. Each council provides personal data about children in its area, and is responsible for the accuracy of that data. Each council may access the data of the other councils (and must abide by data protection principles).
Answer:
E1: Government department and the councils are data controllers, in relation to the personal data on the database.

Example 2: Organisation O outsources its employee payroll to company A. O also engages a marketing company B to do a satisfaction survey of its customers. Company A will need information about O’s employees. Company B will need information about O’s customers. Company A and B have their own employees
Answer:
E2: Both A & B will be processing information on behalf of O, so they are both data processors, while O is the data controller. A & B also process personal data about their own employees and will also be the data controllers for that.
### DATA GOVERNANCE
Data governance concerns to the collection, availability,
usability, integrity and security of how data is managed in
a given enterprise.
What is data governance?
The control of data collection, processing and use
How does it work?
Through sets of processes that ensure certain standards
are maintained
What are the standards?
To uphold security and integrity
Why bother?
Protects both the data, and the well-being of the people
the data relates to
Data governance ties together
all other aspects of data
management – it is the core
component
### TYPES OF DATA ON GDPR UK-GDPR:
“Personal data”: relates to a person
“Special category data”: ‘sensitive’ data relating
to a person
Processing special category data requires you
offer extra legal justification / reason for doing
so
#### PERSONAL DATA
Definitions:
Personal data is data which relates to a living individual who can be identified: a) From that data or b) From that data and other information which is in the possession of, or is likely to come into the possession of, the data controller.

Q: LOOK AT THESE EXAMPLES. ARE THEY INSTANCES OF “PERSONAL DATA”?
Example 3: An organisation holds data on microfiche. The microfiche records do not identify individuals by name, but bear unique reference numbers which can be matched to a card index system to identify the individual concerned. Does this count as personal data?
Answer: E3: Yes – it can be linked

Example 4: A dataset involves the exact addresses and the prices of every house that was sold in Leeds in the year 2005. Does this count as personal data?
Answer: E4: It could be (see the notes below)
### SPECIAL CATEGORY DATA
The UK GDPR defines special category data as:
•personal data revealing racial or ethnic origin;
•personal data revealing political opinions;
•personal data revealing religious or philosophical beliefs;
•personal data revealing trade union membership;
•genetic data;
•biometric data (where used for identification purposes);
•data concerning health;
•data concerning a person’s sex life; and
•data concerning a person’s sexual orientation.
This does not include personal data about criminal allegations, proceedings or convictions, as separate
rules apply. For further information, please see our separate guidance on criminal offence data.
Q: WHY ARE THESE TYPES
OF PERSONAL DATA
TREATED MORE
SERIOUSLY BY THE LAW?
### GDPR: SEVEN PRINCIPLES
All data controllers/processors must follow the seven
principles of the GDPR, concerning how to collect,
process and store personal data:
1. Must be done lawfully, fairly and transparently
2. For explicit and legitimate purpose(s)
3. Limited to the purpose(s) (data minimization)
4. Accurate and up to date
5. Storage limitation (not stored for longer than
need for purpose(s))
6. Integrity and confidential (security)
7. Controller shows accountability
Research Exemption:
In certain cases, when it will not cause harm to subjects, data may be kept indefinitely for research purposes. The research purposes cannot go against the stated purpose for the collection of the data, and any publication of the research must be sure to adequately anonymise the data.
### GDPR: DATA SUBJECT RIGHTS
Subjects have the right to:
8. Be informed: how their data is used; how long stored; who shared with
9. Access: to see the data (make a ‘Subject Access Request’)
10. Rectify/correct anything wrong/incomplete
11. Right to erasure (to be forgotten: the right to have their data erased) (not absolute)
12. Restrict processing (not absolute)
13. Data portability: can take it with them
14. Object to processing of their data in certain circs. (they can stop direct marketing)
15. Re: any automated decisions; be informed (know); request human intervention; to
challenge
(https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/individual-rights/individual-rights/)
## 3. 
•Explore key ethical issues in the processing of data
• Privacy
• Consent
• Anonymisation
THE “LIFE CYCLE” OF
DATA
5
1. Collection
 Issues of consent
2. Processing
 Issues of privacy
3. Storage
 Issues of security
4. Use
 Issues of objectivity and responsibility
We can think of the
“lifecycle” of data as having
four main parts
Each part has its own
accompanying ethical
issues
### PRIVACY
Q1: How would you define something being ‘private’?
Private to you Known / visible to Examples of things that should be…
Q2: How should we decide what needs to be private?
Q3: Why is data privacy an issue?
•It seems like data privacy is an issue
because of risk of harm to data subjects
when data is accessible
•What if we know the data is ‘harmless’ – i.e.
can’t be used against someone?
•Does privacy still matter? Or irrelevant
without risk?
•Suppose everyone in this lecture was – unknown
to you – given secret access to a stream of
video/audio from your laptop camera and
microphone, and a feed of your desktop, for the
entire last week.
•Let’s suppose that nothing we saw could be used
to hurt you materially, financially, physically,
and that there wasn’t even anything potentially
embarrassing to you
•In that case, would you say after the fact:
A. I suffered no harm/wrong
B. I suffered some harm/wrong
•Point of the example: privacy matters not just because of risk to a subject’s
wellbeing
•Can matter because of a rights violation
•The right to ownership and control over facts about you
•In my example: I took control away from you when setting up the laptop
stream
•Why would this be wrong?
### CONSENT
Consent: the power to determine who can access, use,
affect something we have a right of control over
If others violate that consent, they can be blamed
Governing when someone can touch you, use your
belongings, and so on. Generally: access things you
may care about
We can shape the boundaries of our right to privacy by
consent: granting permission to others
#### VALID CONSENT: 3 CONDITIONS
1. INFORMED
subjects have to be able to understand what their data will be
used for
2. AUTONOMOUS
subjects have to freely decide (not forced, coerced) to give
data
3. ONGOING
subjects should be able to withdraw / reclaim their data at any
time

Q1: Is ‘implied’ consent ever
legitimate?
Q2: Are ‘terms and conditions’ a
good method of gaining
informed consent?
Q3: Do you do something wrong
when you use datasets without
checking consent was given by
the subjects?
### PRIVACY, CONSENT, AUTONOMY
•Privacy, consent and autonomy: important throughout
our lives
•Children exert autonomy by exerting privacy
•Older people lose this ability and require help
•Acting with autonomy is fundamental to wellbeing
•Collection, trade and processing of personal data can
undermine autonomy, because it takes some control
away
•Privacy recognized as a human right by the Universal
Declaration of Human Rights (1948) and the European
Convention on Human Rights (1950)
These connected with:
• Individuality: capacity to think/speak/act as we like
• Experimentation with new ideas or actions, without
fear of causing offence
• Innovation and progress: ideas to disrupt, change
• Reflection and independent thinking
• Intimacy: if everyone knows everything about
everyone, who counts as a close friend?
### THE VALUES PROTECTED BY PRIVACY
“The creation, collection, and storage of
personal data carries with it a moral
responsibility and a duty of care to protect
that data and minimize risk. If my analysis
about privacy duties is right, it is a violation
of people’s right to privacy to collect
personal data about them without their
meaningful consent or when there are no
outweighing considerations (2024: 184)”
The values that are protected by privacy:
control over self-presentation, reputation,
autonomy, creativity, security, freedom,
equality and fairness, well-being,
democracy
### PRIVATE VS. USEFUL
Just as Henrietta Lack’s cells have been
incredibly useful and valuable, so is data
•Accept that consent is a necessary
requirement
•A problem remains: no data, once given, is
completely safe from privacy being
undermined
The problem we saw with the definition of
personal data was this:
any data set could in theory become
personal data, depending on what other data
it could be linked to.
This makes the following question a difficult one:
•Can we balance the need for upholding privacy with
the need to do useful stuff with data?
•Key: ensure subject’s consent for how data is used
•The privacy trade-off can be agreed as justified
### ANONYMISATION / LINKAGE
•Steps should be taken to ensure that
data used is anonymized
•Personal data, and special category data:
•Can be embarrassing
•Can put people at risk of harm
•And: ethically important to respect
people’s autonomy / choice / consent
•(Also: even if they’ve provided
information willingly, you may be more
informed, able to understand the
riskiness of that information)
•Also to limit potential for data linkage
“Data linkage”: when two (or more) pieces of information from different sources are brought together, to reveal information that is not available in one dataset.
This means that even if data is anonymized within the context of its own data set, linkage may de- anonymize the data. Important to remove these
### DIRECT INDICATORS
Can be used to directly identify the data
subject. Includes:
•Name/initials
•Address, including full or partial post code
•Telephone numbers or email addresses
•Unique identifying numbers (NI number, NHS
number)
•Vehicle identifiers
•Medical device identifiers
•IP addresses
•Facial photographs
•Names of relatives
•Individual dates
### INDIRECT INDICATORS
Can be used in conjunction with other
information (direct or indirect) to identify the
data subject. Includes:
•Place of treatment or GP name
•Sex
•Place of birth
•Socio-economic data (income, etc.)
•Ethnicity
•Age
•Household or family constitution
•Illicit drug use, or other substance use
•Rare diseases and treatments
•Transcripts or verbatim responses
### QUESTION  
Definitions:  
Personal data is  
information that relates to  
an identified or  
identifiable individual:  
a) From that data or  
b) From that data in  
combination with  
other information  
Sensitive personal data  
involves matters of  
ethnicity, sexuality, and  
religion (among other  
things).  
Example 3: An organisation  
holds data on microfiche. The  
microfiche records do not  
identify individuals by name,  
but bear unique reference  
numbers which can be matched  
to a card index system to  
identify the individual  
concerned. Does this count as  
personal data?Example 4: A dataset involves  
the exact addresses and the  
prices of every house that was  
sold in Leeds in the year 2005.  
Does this count as personal  
data?  
Examples from ICO Guide to DPA:  
https://ico.org.uk/for-organisations/guide-to-  
data-protection/key-definitions/  
Q: LOOK AT THESE EXAMPLES.  
ARE THEY INSTANCES OF  
“PERSONAL DATA”?  
Answers:  
E3: The information held on the  
microfiche records is personal data, as  
the data subjects can be identified by  
them.  
E4: The data relates to houses not to  
individuals. However, we might question  
whether this data could be related to  
specific individuals through linkage with  
other publically available information.  
See notes.
## 4. 
RECAP AND STARTING POINT
OF TODAY
So this question (our overall concern in these lectures):
Is what I’m doing with data (processing it, storing it) ethically ok?
Answer depends on:
1. Does the subject know (has consented to) how their data is being
used?
2. Are you able to ensure that you can responsibly achieve that aim?
If you’re unsure on either (1) or (2), then you can not safely answer ‘yes’
Re 2:
Can fail to meet this if
you:
a. expose subjects
to harm / treat
them unfairly /
breach their
rights
b. undermine (1), by
‘drifting’ away
from the original
stated usage
they consented
to
3. Does the subject know (has consented to) how their
data is being used?
4. Are you able to ensure that you can responsibly
achieve that aim?
### PRIVACY, CONSENT, USE 
#### Target Example
In 2012 Target employed a data scientist called Andrew Pole to “figure out if a customer is pregnant, even if she didn’t want us to know” To better market pregnancy products Pole started by looking at the dataset of customers who told Target they were pregnant. Analyzed shopping habits, to discover patterns. Developed a “pregnancy prediction” score. He could estimate due dates, and send coupons timed for specific times in the pregnancy.
Source:
http://www.nytimes.com/2012/02/19/magazine/shopping-habits.html

A year later an angry customer demanded: “Are you encouraging my teenage daughter to get pregnant?” Target had been sending her coupons. The manager apologized profusely. A week later the manager contacted the man. This time it was the man’s turn to apologize. Daughter was actually pregnant, just hadn’t told him until this event had prompted it. Target knew before the father.

Which of these conditions does
this case pose a problem for…
1. Does the subject know (has
consented to) how their data is
being used?
2. Are you able to ensure that you
can responsibly (w/out causing
further harm or undermining 1)
achieve that aim?
#### Washington P