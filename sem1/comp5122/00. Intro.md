### What is Data Science?
- The purpose of computing
is insight, not numbers.
- – Richard W. Hamming

Kenneth Neil Cukier and Viktor Mayer-Schoenberger wrote an article
called “The Rise of Big Data”. In it, they discuss the concept of
datafication
- They define datafication as a process of “taking all aspects of life
and turning them into data.”
- Example: How we quantify “health and wellbeing” using a
smartwatch
- Take someone who wears a fitness tracker. Without really thinking
about it, parts of their daily life such as sleep, steps, heart rate, and
movement are turned into data they can see.
- Over time, that data helps them notice things they would’ve missed:
- Keep feeling tired in the mornings even when they thought they had
slept enough.
- When they check their sleep data, they notice they were waking up
several times a night without realising. That helped them connect
the problem to late-night screen time and caffeine.
- Their watch also tracks their resting heart rate.
- One month, they saw it slowly creeping up. They hadn’t noticed any
changes in how they felt, but that little number made them pay
attention. They realised they had been working longer hours and
skipping their evening walks.
- Once we datafy things, we can transform their purpose and turn the
information into new forms of value.
- The app shows gentle reminders and weekly trends. When they sit
for too long, it nudges them to move.
- When they go to their GP about feeling low-energy and stressed,
they didn’t just have to describe things vaguely. They could show
the doctor their sleep patterns and heart-rate trends over a few
months. That helped the doctor give more tailored advice, instead
of guessing.
### Data keeps growing with no signs of slowing
#### Profile of a Data Scientist
• Computer science
• Math
• Statistics
• Machine learning
• Domain expertise
• Communication and presentation skills
• Data visualization
#### Example1: The Internet Movie Database (IMDb)
• Crowdsourced and curated data about all aspects of the motion picture
industry, at www.imdb.com
• Data on over 3.3 million movies and TV programs
For each film, IMDb includes:
• its title, running time, genres, date of release, and a full list of cast and crew.
• financial data about each production, including the budget for making the film and
how well it did at the box office.
• ratings for each film from viewers and critics (scores on a zero to ten stars scale)
• written reviews
• links between films: for example, identifying which other films have been watched
most often by viewers of a film
What kind of questions can you answer with this data?
• Which actors appeared in the most films? Appeared in the lowest
rated films? Had the longest career or the shortest lifespan?
• What was the highest rated film each year, or the best in each
genre? Which movies lost the most money, had the highest-powered
casts, or got the least favorable reviews.
• How well does movie gross correlate with viewer ratings or awards?
• How do Hollywood movies compare to Korean movies, in terms of
ratings, budget, and gross? Are foreign movies better received than
American films, and how does this differ between U.S. and non-U.S.
reviewers?
• What is the age distribution of actors and actresses in films?
• How much younger is the actress playing the wife, on average,
than the actor playing the husband?
• Has this disparity been increasing or decreasing with time?
• In which movies did Tom Hanks played with Keanu Reeves?
1. Collecting
Curating
Cleaning
2. Visualize
Analyze
Model (Machine Learning)
3. Does the past represent the future?
What do I want to model?
How will the model be used?
What data do I need?
What data do I have?
How hard is it to get data?
#### Example2: Gapminder Wealth and Health of Nations
GDP per capita (Gross Domestic Product per person), which reflects a
country’s total economic output divided by its population.
• An indicator of a nation’s wealth
• Useful for cross-country comparisons of economic resources and their
effects on outcomes like life expectancy
### Objectives
The heart of data science lies in doing the simple things right:
understanding the application domain, cleaning and integrating
relevant data sources, and presenting your results clearly to others.
• It takes considerable insight and experience to ask the right
**questions**, and sense whether you are moving toward correct
answers and **actionable insights**.
### What is Data Science?
Ref: The Data Science Design Manual by Steven Skiena
• Data science encompasses a set of principles, problem definitions, algorithms, and
processes for extracting nonobvious and useful patterns from large data sets.
• Machine learning (ML) focuses on the design and evaluation of algorithms for
extracting patterns from data.
• Data mining generally deals with the analysis of structured data and data discovery
• Data science also takes up other challenges, such as the capturing, cleaning, and
transforming of unstructured social media and web data; the use of big-data
technologies to store and process big, unstructured data sets; and questions related to
data ethics and regulation.
• Data science rests on a foundation of mathematics, particularly statistics and linear
algebra. It is important to understand this material on an intuitive level: why these
concepts were developed, how they are useful, and when they work best.
• Approaches which come most naturally to computer scientists, particularly the
algorithmic manipulation of data, the use of machine learning, and the mastery of scale
• Core values of statistical reasoning: the need to understand the application domain,
proper appreciation of the small, the quest for significance, and a hunger for
exploration.
### 50 years of data science paper
This paper by David Donoho examines the historical and intellectual roots of data science, critiques its current commercial framing, and proposes a more substantive, academically rigorous future for the field.

### **Key Points:**

1.  **Historical Context:** The intellectual foundations for a "science of learning from data" were laid decades ago by statisticians like John Tukey (1962), John Chambers, and Bill Cleveland. They urged academic statistics to expand beyond theoretical modelling to encompass the full data analysis workflow.

2.  **The Current "Data Science Moment":** Contemporary university programmes and initiatives are often driven by commercial demand for "big data" skills (e.g., Hadoop, scaling). Donoho argues this "**Lesser Data Science (LDS)**" is a narrow, technology-focused superset of statistics and machine learning, missing deeper intellectual aims.

3.  **A Better Framework - "Greater Data Science (GDS)":** Donoho proposes a broader, scientifically-grounded vision with six divisions:
    *   Data Exploration & Preparation
    *   Data Representation & Transformation
    *   Computing with Data
    *   Data Modelling (encompassing both traditional inference *and* predictive modelling)
    *   Data Visualisation & Presentation
    *   **Science about Data Science** (the empirical study of data analysis itself)

4.  **The "Secret Sauce" of Prediction:** He highlights the underappreciated **Common Task Framework (CTF)**—public benchmarks with shared data and objective scoring—as the key driver behind many machine learning successes.

5.  **The Future (Next 50 Years):** The true revolution will come not from mere scaling, but from **"Science about Data Science."** As scientific research itself becomes fully computational, reproducible, and open, we will be able to empirically test and improve data analysis methods across entire scientific literatures, moving towards evidence-based methodology.

### **Conclusion:**
The paper argues for reclaiming data science as a genuine *science* of learning from data. Its core mission should be intellectual: to study and improve the methods of data analysis through evidence-based research, particularly by meta-analysing the growing corpus of scientific computation. This **Greater Data Science** offers a more lasting and academically coherent path than the commercially-driven "Lesser Data Science" of today.